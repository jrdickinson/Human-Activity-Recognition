{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/test\")\n",
    "x_test = pd.read_csv(\"X_test.txt\", \"\\s+\", header=None)\n",
    "y_test = pd.read_csv(\"y_test.txt\", \"\\s+\", header=None)\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/train\")\n",
    "x_train = pd.read_csv(\"X_train.txt\", \"\\s+\", header=None)\n",
    "y_train = pd.read_csv(\"y_train.txt\", \"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 561)\n",
      "(2947, 1)\n",
      "(7352, 561)\n",
      "(7352, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = x_train.min()\n",
    "xmax = x_train.max()\n",
    "x_train = x_train-xmin/(xmax-xmin)\n",
    "x_test = x_test-xmin/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/test\")\n",
    "text = pd.read_csv(\"subject_test.txt\")\n",
    "# text.iloc[617]\n",
    "# text[text[\"2\"]==4]\n",
    "text.iloc[0:301][\"2\"].unique()\n",
    "text.iloc[618:906][\"2\"].unique()\n",
    "text.iloc[301:618][\"2\"].unique()\n",
    "text.iloc[906:1200][\"2\"].unique()\n",
    "text.iloc[1200:1520][\"2\"].unique()\n",
    "text.iloc[1520:1847][\"2\"].unique()\n",
    "text.iloc[1847:2211][\"2\"].unique()\n",
    "text.iloc[2211:2565][\"2\"].unique()\n",
    "text.iloc[2565:2946][\"2\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Class Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1226\n",
      "1073\n",
      "986\n",
      "1286\n",
      "1374\n",
      "1407\n",
      "496\n",
      "471\n",
      "420\n",
      "491\n",
      "532\n",
      "537\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[y_train[0]==1]))\n",
    "print(len(y_train[y_train[0]==2]))\n",
    "print(len(y_train[y_train[0]==3]))\n",
    "print(len(y_train[y_train[0]==4]))\n",
    "print(len(y_train[y_train[0]==5]))\n",
    "print(len(y_train[y_train[0]==6]))\n",
    "print(len(y_test[y_test[0]==1]))\n",
    "print(len(y_test[y_test[0]==2]))\n",
    "print(len(y_test[y_test[0]==3]))\n",
    "print(len(y_test[y_test[0]==4]))\n",
    "print(len(y_test[y_test[0]==5]))\n",
    "print(len(y_test[y_test[0]==6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = x_test.iloc[0:1520]\n",
    "x_test = x_test.iloc[1520:2946]\n",
    "y_valid = y_test.iloc[0:1520]\n",
    "y_test = y_test.iloc[1520:2946]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively drop columns XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9382537711786788\n",
      "precision_full: [0.91304348 0.98636364 0.95022624 0.92307692 0.87681159 1.        ]\n",
      "recall_full: [0.99635036 0.87854251 0.96330275 0.86055777 0.93076923 1.        ]\n",
      "1.4232831001281738\n",
      "accuracy_full: 0.9406903056609882\n",
      "precision_full: [0.95759717 0.97826087 0.9380531  0.91416309 0.86330935 1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.97247706 0.84860558 0.92307692 1.        ]\n",
      "1.7290890216827393\n",
      "accuracy_full: 0.9385458021781071\n",
      "precision_full: [0.92542373 0.96902655 0.94954128 0.93859649 0.86925795 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.94954128 0.85258964 0.94615385 1.        ]\n",
      "1.7618274688720703\n",
      "accuracy_full: 0.9380426864359476\n",
      "precision_full: [0.93493151 0.96902655 0.94090909 0.91286307 0.88191882 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.94954128 0.87649402 0.91923077 1.        ]\n",
      "1.466092586517334\n",
      "accuracy_full: 0.9349750959385502\n",
      "precision_full: [0.93684211 0.97402597 0.9321267  0.91845494 0.86071429 1.        ]\n",
      "recall_full: [0.97445255 0.91093117 0.94495413 0.85258964 0.92692308 1.        ]\n",
      "1.8147242069244385\n",
      "accuracy_full: 0.9413049839789526\n",
      "precision_full: [0.93835616 0.97356828 0.95495495 0.89156627 0.89615385 1.        ]\n",
      "recall_full: [1.         0.89473684 0.97247706 0.88446215 0.89615385 1.        ]\n",
      "1.7846410274505615\n",
      "accuracy_full: 0.9403181183782746\n",
      "precision_full: [0.95789474 0.97854077 0.95022624 0.92792793 0.84429066 1.        ]\n",
      "recall_full: [0.99635036 0.92307692 0.96330275 0.82071713 0.93846154 1.        ]\n",
      "1.8838365077972412\n",
      "accuracy_full: 0.9359461516205861\n",
      "precision_full: [0.94097222 0.98206278 0.9254386  0.90376569 0.87132353 1.        ]\n",
      "recall_full: [0.98905109 0.88663968 0.96788991 0.86055777 0.91153846 1.        ]\n",
      "1.929394245147705\n",
      "accuracy_full: 0.9284447405086053\n",
      "precision_full: [0.92491468 0.97222222 0.90909091 0.90336134 0.87132353 1.        ]\n",
      "recall_full: [0.98905109 0.85020243 0.96330275 0.85657371 0.91153846 1.        ]\n",
      "1.4924311637878418\n",
      "accuracy_full: 0.9441226124167307\n",
      "precision_full: [0.95774648 0.97844828 0.95089286 0.91139241 0.87179487 1.        ]\n",
      "recall_full: [0.99270073 0.91902834 0.97706422 0.86055777 0.91538462 1.        ]\n",
      "1.9783072471618652\n",
      "1\n",
      "accuracy_full: 0.9427716081475106\n",
      "precision_full: [0.91496599 0.98214286 0.95515695 0.9279661  0.89010989 1.        ]\n",
      "recall_full: [0.98175182 0.89068826 0.97706422 0.87250996 0.93461538 1.        ]\n",
      "1.5253889560699463\n",
      "accuracy_full: 0.9464656563905955\n",
      "precision_full: [0.95438596 0.98672566 0.9254386  0.9214876  0.89591078 1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.96788991 0.88844622 0.92692308 1.        ]\n",
      "2.1529181003570557\n",
      "accuracy_full: 0.9267877524694779\n",
      "precision_full: [0.91864407 0.96428571 0.93665158 0.91555556 0.84561404 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94954128 0.82071713 0.92692308 1.        ]\n",
      "2.1534311771392822\n",
      "accuracy_full: 0.9333187679043276\n",
      "precision_full: [0.90939597 0.96428571 0.94907407 0.90612245 0.88764045 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94036697 0.88446215 0.91153846 1.        ]\n",
      "1.567293643951416\n",
      "accuracy_full: 0.93788959155462\n",
      "precision_full: [0.92708333 0.98706897 0.94520548 0.90082645 0.87732342 1.        ]\n",
      "recall_full: [0.97445255 0.92712551 0.94954128 0.8685259  0.90769231 1.        ]\n",
      "2.781255006790161\n",
      "accuracy_full: 0.9350520134595648\n",
      "precision_full: [0.91582492 0.97321429 0.94977169 0.88537549 0.89883268 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.95412844 0.89243028 0.88846154 1.        ]\n",
      "2.140507459640503\n",
      "accuracy_full: 0.9406787730915175\n",
      "precision_full: [0.95759717 0.98283262 0.94618834 0.90598291 0.85920578 1.        ]\n",
      "recall_full: [0.98905109 0.92712551 0.96788991 0.84462151 0.91538462 1.        ]\n",
      "2.5432918071746826\n",
      "accuracy_full: 0.9362191398258944\n",
      "precision_full: [0.93150685 0.98642534 0.92444444 0.90871369 0.87822878 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.95412844 0.87250996 0.91538462 1.        ]\n",
      "2.4966657161712646\n",
      "accuracy_full: 0.9327378605874158\n",
      "precision_full: [0.94405594 0.97747748 0.9137931  0.90598291 0.86231884 1.        ]\n",
      "recall_full: [0.98540146 0.87854251 0.97247706 0.84462151 0.91538462 1.        ]\n",
      "3.2907679080963135\n",
      "accuracy_full: 0.9427317561793341\n",
      "precision_full: [0.95789474 0.97826087 0.94642857 0.89112903 0.88593156 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.97247706 0.88047809 0.89615385 1.        ]\n",
      "2.4494869709014893\n",
      "2\n",
      "accuracy_full: 0.9390033159235447\n",
      "precision_full: [0.92808219 0.97356828 0.94594595 0.9339207  0.86879433 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.96330275 0.84462151 0.94230769 1.        ]\n",
      "4.217493772506714\n",
      "accuracy_full: 0.9438321053675828\n",
      "precision_full: [0.96126761 0.97413793 0.93777778 0.91176471 0.88191882 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.96788991 0.86454183 0.91923077 1.        ]\n",
      "3.518548011779785\n",
      "accuracy_full: 0.9255078789587787\n",
      "precision_full: [0.92176871 0.96444444 0.93636364 0.89361702 0.85144928 1.        ]\n",
      "recall_full: [0.98905109 0.87854251 0.94495413 0.83665339 0.90384615 1.        ]\n",
      "3.0375607013702393\n",
      "accuracy_full: 0.9402011533017371\n",
      "precision_full: [0.94076655 0.96137339 0.94495413 0.90688259 0.89433962 1.        ]\n",
      "recall_full: [0.98540146 0.90688259 0.94495413 0.89243028 0.91153846 1.        ]\n",
      "2.619313955307007\n",
      "accuracy_full: 0.9372705658400488\n",
      "precision_full: [0.94326241 0.97435897 0.92825112 0.90123457 0.88059701 1.        ]\n",
      "recall_full: [0.97080292 0.92307692 0.94954128 0.87250996 0.90769231 1.        ]\n",
      "2.94154691696167\n",
      "accuracy_full: 0.9337782517631451\n",
      "precision_full: [0.93127148 0.96491228 0.94117647 0.88709677 0.88549618 1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.95412844 0.87649402 0.89230769 1.        ]\n",
      "2.7899703979492188\n",
      "accuracy_full: 0.9397898398816183\n",
      "precision_full: [0.95121951 0.97844828 0.95045045 0.92410714 0.84912281 1.        ]\n",
      "recall_full: [0.99635036 0.91902834 0.96788991 0.8247012  0.93076923 1.        ]\n",
      "2.91377329826355\n",
      "accuracy_full: 0.9362406462428717\n",
      "precision_full: [0.93793103 0.98654709 0.92444444 0.90794979 0.87179487 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.95412844 0.86454183 0.91538462 1.        ]\n",
      "2.705782890319824\n",
      "accuracy_full: 0.9360808986914101\n",
      "precision_full: [0.9375     0.97747748 0.91774892 0.90456432 0.88432836 1.        ]\n",
      "recall_full: [0.98540146 0.87854251 0.97247706 0.8685259  0.91153846 1.        ]\n",
      "2.6894638538360596\n",
      "accuracy_full: 0.9427317561793341\n",
      "precision_full: [0.95789474 0.97826087 0.94642857 0.89112903 0.88593156 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.97247706 0.88047809 0.89615385 1.        ]\n",
      "2.8264315128326416\n",
      "3\n",
      "accuracy_full: 0.9307390630795549\n",
      "precision_full: [0.89768977 0.98181818 0.94954128 0.9137931  0.86642599 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.94954128 0.84462151 0.92307692 1.        ]\n",
      "2.8722729682922363\n",
      "accuracy_full: 0.9319841331861339\n",
      "precision_full: [0.92808219 0.96929825 0.9321267  0.92825112 0.85614035 0.99630996]\n",
      "recall_full: [0.98905109 0.89473684 0.94495413 0.8247012  0.93846154 1.        ]\n",
      "3.593630790710449\n",
      "accuracy_full: 0.9287098423736005\n",
      "precision_full: [0.93493151 0.96943231 0.94954128 0.91743119 0.82593857 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.94954128 0.79681275 0.93076923 1.        ]\n",
      "2.9016387462615967\n",
      "accuracy_full: 0.9342475491578744\n",
      "precision_full: [0.94425087 0.97008547 0.94495413 0.89495798 0.86397059 0.99630996]\n",
      "recall_full: [0.98905109 0.91902834 0.94495413 0.84860558 0.90384615 1.        ]\n",
      "2.7622616291046143\n",
      "accuracy_full: 0.9305493592138903\n",
      "precision_full: [0.94425087 0.97402597 0.93243243 0.86454183 0.87596899 0.99630996]\n",
      "recall_full: [0.98905109 0.91093117 0.94954128 0.86454183 0.86923077 1.        ]\n",
      "2.870182991027832\n",
      "accuracy_full: 0.9324248601023365\n",
      "precision_full: [0.9222973  0.98214286 0.95022624 0.90086207 0.85559567 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.96330275 0.83266932 0.91153846 1.        ]\n",
      "2.567140817642212\n",
      "accuracy_full: 0.9289482676421804\n",
      "precision_full: [0.92542373 0.97368421 0.95852535 0.89519651 0.83985765 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.95412844 0.81673307 0.90769231 1.        ]\n",
      "2.95696759223938\n",
      "accuracy_full: 0.9205851856526163\n",
      "precision_full: [0.91891892 0.95964126 0.91855204 0.87654321 0.86466165 0.99630996]\n",
      "recall_full: [0.99270073 0.86639676 0.93119266 0.84860558 0.88461538 1.        ]\n",
      "3.1703624725341797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9335505797030538\n",
      "precision_full: [0.94097222 0.9650655  0.93243243 0.90295359 0.86861314 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.94954128 0.85258964 0.91538462 1.        ]\n",
      "2.8146615028381348\n",
      "accuracy_full: 0.9368164472439479\n",
      "precision_full: [0.95698925 0.96995708 0.9254386  0.91703057 0.85765125 1.        ]\n",
      "recall_full: [0.97445255 0.91497976 0.96788991 0.83665339 0.92692308 1.        ]\n",
      "2.516819715499878\n",
      "4\n",
      "accuracy_full: 0.924628668516565\n",
      "precision_full: [0.90033223 0.98148148 0.94196429 0.89270386 0.85144928 1.        ]\n",
      "recall_full: [0.98905109 0.8582996  0.96788991 0.82868526 0.90384615 1.        ]\n",
      "2.5146987438201904\n",
      "accuracy_full: 0.9318305837885816\n",
      "precision_full: [0.91610738 0.98173516 0.94196429 0.89873418 0.86764706 1.        ]\n",
      "recall_full: [0.99635036 0.87044534 0.96788991 0.84860558 0.90769231 1.        ]\n",
      "2.428497791290283\n",
      "accuracy_full: 0.9352457315239538\n",
      "precision_full: [0.93150685 0.98654709 0.94222222 0.91629956 0.85159011 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.97247706 0.82868526 0.92692308 1.        ]\n",
      "3.3355414867401123\n",
      "accuracy_full: 0.9193865708757057\n",
      "precision_full: [0.90301003 0.97663551 0.90748899 0.91111111 0.84210526 1.        ]\n",
      "recall_full: [0.98540146 0.84615385 0.94495413 0.81673307 0.92307692 1.        ]\n",
      "2.8424785137176514\n",
      "accuracy_full: 0.9317937754993976\n",
      "precision_full: [0.93127148 0.97046414 0.95283019 0.90789474 0.84751773 1.        ]\n",
      "recall_full: [0.98905109 0.93117409 0.9266055  0.8247012  0.91923077 1.        ]\n",
      "2.3901305198669434\n",
      "accuracy_full: 0.9271853863959288\n",
      "precision_full: [0.9222973  0.97333333 0.95       0.87190083 0.8576779  1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.9587156  0.84063745 0.88076923 1.        ]\n",
      "2.5714657306671143\n",
      "accuracy_full: 0.9453154732405668\n",
      "precision_full: [0.95804196 0.98678414 0.94273128 0.92640693 0.86738351 1.        ]\n",
      "recall_full: [1.         0.90688259 0.98165138 0.85258964 0.93076923 1.        ]\n",
      "2.6177845001220703\n",
      "accuracy_full: 0.9320652397544255\n",
      "precision_full: [0.93771626 0.97854077 0.93577982 0.89029536 0.86080586 1.        ]\n",
      "recall_full: [0.98905109 0.92307692 0.93577982 0.84063745 0.90384615 1.        ]\n",
      "2.375758409500122\n",
      "accuracy_full: 0.9268576944378654\n",
      "precision_full: [0.90572391 0.96330275 0.92       0.91101695 0.87591241 1.        ]\n",
      "recall_full: [0.98175182 0.85020243 0.94954128 0.85657371 0.92307692 1.        ]\n",
      "3.9560818672180176\n",
      "accuracy_full: 0.9348313146927967\n",
      "precision_full: [0.92413793 0.98206278 0.92951542 0.89754098 0.88345865 1.        ]\n",
      "recall_full: [0.97810219 0.88663968 0.96788991 0.87250996 0.90384615 1.        ]\n",
      "2.2822771072387695\n",
      "5\n",
      "accuracy_full: 0.9317757525336515\n",
      "precision_full: [0.90666667 0.97747748 0.9543379  0.88934426 0.87924528 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.9587156  0.86454183 0.89615385 1.        ]\n",
      "2.5287609100341797\n",
      "accuracy_full: 0.9360377235835968\n",
      "precision_full: [0.9222973  0.96875    0.94545455 0.92640693 0.87096774 1.        ]\n",
      "recall_full: [0.99635036 0.87854251 0.95412844 0.85258964 0.93461538 1.        ]\n",
      "2.1195974349975586\n",
      "accuracy_full: 0.9328990867050445\n",
      "precision_full: [0.92517007 0.96888889 0.94117647 0.90677966 0.86861314 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.95412844 0.85258964 0.91538462 1.        ]\n",
      "2.2080776691436768\n",
      "accuracy_full: 0.9304710494663385\n",
      "precision_full: [0.90333333 0.97235023 0.92342342 0.92735043 0.87725632 1.        ]\n",
      "recall_full: [0.98905109 0.85425101 0.94036697 0.86454183 0.93461538 1.        ]\n",
      "1.998277187347412\n",
      "accuracy_full: 0.9425212843021576\n",
      "precision_full: [0.94699647 0.98734177 0.94977169 0.91810345 0.86379928 1.        ]\n",
      "recall_full: [0.97810219 0.94736842 0.95412844 0.84860558 0.92692308 1.        ]\n",
      "1.9731199741363525\n",
      "accuracy_full: 0.9381467698412863\n",
      "precision_full: [0.95422535 0.96218487 0.94954128 0.92410714 0.85314685 1.        ]\n",
      "recall_full: [0.98905109 0.92712551 0.94954128 0.8247012  0.93846154 1.        ]\n",
      "2.2750158309936523\n",
      "accuracy_full: 0.9399813101272195\n",
      "precision_full: [0.95438596 0.97835498 0.94222222 0.91703057 0.85714286 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.97247706 0.83665339 0.92307692 1.        ]\n",
      "2.2415175437927246\n",
      "accuracy_full: 0.9353531114433425\n",
      "precision_full: [0.92255892 0.97816594 0.96261682 0.89915966 0.86764706 1.        ]\n",
      "recall_full: [1.         0.90688259 0.94495413 0.85258964 0.90769231 1.        ]\n",
      "2.834334135055542\n",
      "accuracy_full: 0.933028620678649\n",
      "precision_full: [0.93379791 0.96069869 0.92035398 0.9254386  0.86785714 1.        ]\n",
      "recall_full: [0.97810219 0.89068826 0.95412844 0.84063745 0.93461538 1.        ]\n",
      "1.9456758499145508\n",
      "accuracy_full: 0.9510532257075783\n",
      "precision_full: [0.96441281 0.99563319 0.93886463 0.90725806 0.90114068 1.        ]\n",
      "recall_full: [0.98905109 0.92307692 0.98623853 0.89641434 0.91153846 1.        ]\n",
      "2.4165172576904297\n",
      "6\n",
      "accuracy_full: 0.9337074048938648\n",
      "precision_full: [0.90666667 0.98190045 0.95454545 0.9137931  0.86642599 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.96330275 0.84462151 0.92307692 1.        ]\n",
      "2.506711959838867\n",
      "accuracy_full: 0.9325288714979751\n",
      "precision_full: [0.91610738 0.97737557 0.93636364 0.92207792 0.86428571 1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.94495413 0.84860558 0.93076923 1.        ]\n",
      "2.018953323364258\n",
      "accuracy_full: 0.934336614076179\n",
      "precision_full: [0.91467577 0.96860987 0.92857143 0.92372881 0.88321168 1.        ]\n",
      "recall_full: [0.97810219 0.87449393 0.95412844 0.8685259  0.93076923 1.        ]\n",
      "2.452636957168579\n",
      "accuracy_full: 0.9358887746247372\n",
      "precision_full: [0.93150685 0.96460177 0.93243243 0.94594595 0.86111111 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.94954128 0.83665339 0.95384615 1.        ]\n",
      "1.991595983505249\n",
      "accuracy_full: 0.9414322272159881\n",
      "precision_full: [0.93379791 0.98734177 0.94883721 0.92274678 0.8705036  1.        ]\n",
      "recall_full: [0.97810219 0.94736842 0.93577982 0.85657371 0.93076923 1.        ]\n",
      "2.563920497894287\n",
      "accuracy_full: 0.9322301488351602\n",
      "precision_full: [0.9375     0.969163   0.92857143 0.92825112 0.84722222 1.        ]\n",
      "recall_full: [0.98540146 0.89068826 0.95412844 0.8247012  0.93846154 1.        ]\n",
      "3.0617103576660156\n",
      "accuracy_full: 0.9370929623223363\n",
      "precision_full: [0.95121951 0.96969697 0.9375     0.90948276 0.86231884 1.        ]\n",
      "recall_full: [0.99635036 0.90688259 0.96330275 0.84063745 0.91538462 1.        ]\n",
      "2.1658730506896973\n",
      "accuracy_full: 0.9308649468994729\n",
      "precision_full: [0.92542373 0.97379913 0.9537037  0.88065844 0.86516854 1.        ]\n",
      "recall_full: [0.99635036 0.90283401 0.94495413 0.85258964 0.88846154 1.        ]\n",
      "2.0052077770233154\n",
      "accuracy_full: 0.932364610054479\n",
      "precision_full: [0.93379791 0.96069869 0.92035398 0.92511013 0.86476868 1.        ]\n",
      "recall_full: [0.97810219 0.89068826 0.95412844 0.83665339 0.93461538 1.        ]\n",
      "1.9633331298828125\n",
      "accuracy_full: 0.9559234692636064\n",
      "precision_full: [0.96126761 0.99130435 0.95111111 0.94468085 0.90145985 0.99264706]\n",
      "recall_full: [0.99635036 0.92307692 0.98165138 0.88446215 0.95       1.        ]\n",
      "2.25544810295105\n",
      "7\n",
      "accuracy_full: 0.9249907196779136\n",
      "precision_full: [0.88888889 0.98104265 0.9375     0.90909091 0.85971223 1.        ]\n",
      "recall_full: [0.99270073 0.83805668 0.96330275 0.83665339 0.91923077 1.        ]\n",
      "2.0124599933624268\n",
      "accuracy_full: 0.9428981090545521\n",
      "precision_full: [0.95454545 0.96995708 0.94144144 0.92274678 0.87681159 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.9587156  0.85657371 0.93076923 1.        ]\n",
      "1.9657957553863525\n",
      "accuracy_full: 0.9320158539180091\n",
      "precision_full: [0.93448276 0.97816594 0.95475113 0.89912281 0.84042553 1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.96788991 0.81673307 0.91153846 1.        ]\n",
      "2.352574110031128\n",
      "accuracy_full: 0.9377207711320161\n",
      "precision_full: [0.93150685 0.98245614 0.95890411 0.92070485 0.85211268 1.        ]\n",
      "recall_full: [0.99270073 0.90688259 0.96330275 0.83266932 0.93076923 1.        ]\n",
      "1.989448070526123\n",
      "accuracy_full: 0.9425144732826936\n",
      "precision_full: [0.9471831  0.9787234  0.93693694 0.90909091 0.88764045 1.        ]\n",
      "recall_full: [0.98175182 0.93117409 0.95412844 0.87649402 0.91153846 1.        ]\n",
      "2.0034544467926025\n",
      "accuracy_full: 0.9380344688600162\n",
      "precision_full: [0.96113074 0.97468354 0.95909091 0.8961039  0.84587814 1.        ]\n",
      "recall_full: [0.99270073 0.93522267 0.96788991 0.8247012  0.90769231 1.        ]\n",
      "1.9826164245605469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9403115150167825\n",
      "precision_full: [0.93793103 0.96536797 0.95       0.91949153 0.87912088 1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.9587156  0.86454183 0.92307692 1.        ]\n",
      "2.2495808601379395\n",
      "accuracy_full: 0.9379763226115467\n",
      "precision_full: [0.92517007 0.96982759 0.95327103 0.89558233 0.89655172 1.        ]\n",
      "recall_full: [0.99270073 0.91093117 0.93577982 0.88844622 0.9        1.        ]\n",
      "1.9987154006958008\n",
      "accuracy_full: 0.9311415398743543\n",
      "precision_full: [0.91467577 0.97272727 0.91666667 0.91525424 0.87912088 1.        ]\n",
      "recall_full: [0.97810219 0.86639676 0.9587156  0.86055777 0.92307692 1.        ]\n",
      "1.9451508522033691\n",
      "accuracy_full: 0.946611934068626\n",
      "precision_full: [0.95470383 0.98245614 0.94666667 0.91286307 0.89179104 0.99630996]\n",
      "recall_full: [1.         0.90688259 0.97706422 0.87649402 0.91923077 1.        ]\n",
      "2.0716159343719482\n",
      "8\n",
      "accuracy_full: 0.9247256550509344\n",
      "precision_full: [0.92439863 0.98214286 0.93333333 0.89035088 0.83333333 1.        ]\n",
      "recall_full: [0.98175182 0.89068826 0.96330275 0.80876494 0.90384615 1.        ]\n",
      "1.9863884449005127\n",
      "accuracy_full: 0.9388002677243593\n",
      "precision_full: [0.93771626 0.99553571 0.94247788 0.90987124 0.85971223 1.        ]\n",
      "recall_full: [0.98905109 0.90283401 0.97706422 0.84462151 0.91923077 1.        ]\n",
      "1.9540972709655762\n",
      "accuracy_full: 0.9309059896200473\n",
      "precision_full: [0.93127148 0.96566524 0.9537037  0.89361702 0.85454545 1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.94495413 0.83665339 0.90384615 1.        ]\n",
      "2.038794994354248\n",
      "accuracy_full: 0.9328176141294507\n",
      "precision_full: [0.92808219 0.97787611 0.92825112 0.91703057 0.86071429 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.94954128 0.83665339 0.92692308 1.        ]\n",
      "1.9656810760498047\n",
      "accuracy_full: 0.9379337497568588\n",
      "precision_full: [0.9209622  0.97321429 0.94196429 0.93103448 0.87455197 1.        ]\n",
      "recall_full: [0.97810219 0.88259109 0.96788991 0.86055777 0.93846154 1.        ]\n",
      "2.263000011444092\n",
      "accuracy_full: 0.9238404235626679\n",
      "precision_full: [0.91582492 0.97777778 0.92727273 0.91363636 0.83333333 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.93577982 0.80079681 0.92307692 1.        ]\n",
      "2.008477210998535\n",
      "accuracy_full: 0.9315799267453461\n",
      "precision_full: [0.91919192 0.98181818 0.94170404 0.92376682 0.8466899  1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.96330275 0.82071713 0.93461538 1.        ]\n",
      "1.981821060180664\n",
      "accuracy_full: 0.9377615815312961\n",
      "precision_full: [0.93150685 0.97435897 0.94392523 0.90163934 0.88721805 1.        ]\n",
      "recall_full: [0.99270073 0.92307692 0.9266055  0.87649402 0.90769231 1.        ]\n",
      "1.9508028030395508\n",
      "accuracy_full: 0.9249472626431241\n",
      "precision_full: [0.91467577 0.96396396 0.90707965 0.88663968 0.88549618 1.        ]\n",
      "recall_full: [0.97810219 0.86639676 0.94036697 0.87250996 0.89230769 1.        ]\n",
      "2.039067029953003\n",
      "accuracy_full: 0.9454780997308299\n",
      "precision_full: [0.94137931 0.96969697 0.95412844 0.91428571 0.90225564 1.        ]\n",
      "recall_full: [0.99635036 0.90688259 0.95412844 0.89243028 0.92307692 1.        ]\n",
      "2.0837817192077637\n",
      "9\n",
      "accuracy_full: 0.9320839039665493\n",
      "precision_full: [0.92783505 0.98623853 0.92207792 0.91666667 0.85460993 1.        ]\n",
      "recall_full: [0.98540146 0.87044534 0.97706422 0.83266932 0.92692308 1.        ]\n",
      "1.9514834880828857\n",
      "accuracy_full: 0.935915701796906\n",
      "precision_full: [0.91       0.96846847 0.95391705 0.92735043 0.87725632 1.        ]\n",
      "recall_full: [0.99635036 0.87044534 0.94954128 0.86454183 0.93461538 1.        ]\n",
      "1.9504759311676025\n",
      "accuracy_full: 0.9330649006866721\n",
      "precision_full: [0.92517007 0.98206278 0.94594595 0.91266376 0.85106383 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.96330275 0.83266932 0.92307692 1.        ]\n",
      "2.297621488571167\n",
      "accuracy_full: 0.9229620417900782\n",
      "precision_full: [0.92068966 0.96460177 0.91517857 0.89699571 0.85198556 1.        ]\n",
      "recall_full: [0.97445255 0.88259109 0.94036697 0.83266932 0.90769231 1.        ]\n",
      "1.9987878799438477\n",
      "accuracy_full: 0.9410309779075346\n",
      "precision_full: [0.93425606 0.97402597 0.94117647 0.91666667 0.88847584 1.        ]\n",
      "recall_full: [0.98540146 0.91093117 0.95412844 0.87649402 0.91923077 1.        ]\n",
      "2.038132905960083\n",
      "accuracy_full: 0.9205435630829345\n",
      "precision_full: [0.90301003 0.97333333 0.93119266 0.90950226 0.83275261 1.        ]\n",
      "recall_full: [0.98540146 0.88663968 0.93119266 0.80079681 0.91923077 1.        ]\n",
      "1.956697702407837\n",
      "accuracy_full: 0.9421398551865421\n",
      "precision_full: [0.96453901 0.98712446 0.95515695 0.9047619  0.85053381 1.        ]\n",
      "recall_full: [0.99270073 0.93117409 0.97706422 0.83266932 0.91923077 1.        ]\n",
      "1.9818062782287598\n",
      "accuracy_full: 0.9343950997063643\n",
      "precision_full: [0.94444444 0.97777778 0.92070485 0.89958159 0.87084871 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.9587156  0.85657371 0.90769231 1.        ]\n",
      "1.9704036712646484\n",
      "accuracy_full: 0.9314257274512509\n",
      "precision_full: [0.9375     0.97727273 0.9173913  0.88663968 0.8754717  1.        ]\n",
      "recall_full: [0.98540146 0.87044534 0.96788991 0.87250996 0.89230769 1.        ]\n",
      "1.9354867935180664\n",
      "accuracy_full: 0.9412560588425939\n",
      "precision_full: [0.94425087 0.98198198 0.91774892 0.92050209 0.89259259 0.99630996]\n",
      "recall_full: [0.98905109 0.88259109 0.97247706 0.87649402 0.92692308 1.        ]\n",
      "1.9969542026519775\n",
      "10\n",
      "accuracy_full: 0.9280015026231677\n",
      "precision_full: [0.93103448 0.98181818 0.91341991 0.9004329  0.85251799 1.        ]\n",
      "recall_full: [0.98540146 0.87449393 0.96788991 0.82868526 0.91153846 1.        ]\n",
      "2.2210309505462646\n",
      "accuracy_full: 0.9335284542366887\n",
      "precision_full: [0.90033223 0.97196262 0.92920354 0.93913043 0.88172043 1.        ]\n",
      "recall_full: [0.98905109 0.84210526 0.96330275 0.86055777 0.94615385 1.        ]\n",
      "1.9752585887908936\n",
      "accuracy_full: 0.9372974437035754\n",
      "precision_full: [0.92517007 0.97309417 0.94222222 0.90456432 0.88764045 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.97247706 0.8685259  0.91153846 1.        ]\n",
      "1.9909873008728027\n",
      "accuracy_full: 0.9383664835513645\n",
      "precision_full: [0.92567568 0.97008547 0.97607656 0.92173913 0.86120996 1.        ]\n",
      "recall_full: [1.         0.91902834 0.93577982 0.84462151 0.93076923 1.        ]\n",
      "1.9898724555969238\n",
      "accuracy_full: 0.9387884966497612\n",
      "precision_full: [0.93379791 0.97402597 0.92792793 0.93859649 0.87234043 1.        ]\n",
      "recall_full: [0.97810219 0.91093117 0.94495413 0.85258964 0.94615385 1.        ]\n",
      "2.0034303665161133\n",
      "accuracy_full: 0.9263389416633517\n",
      "precision_full: [0.89735099 0.95670996 0.96650718 0.91964286 0.84859155 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.9266055  0.82071713 0.92692308 1.        ]\n",
      "1.9594922065734863\n",
      "accuracy_full: 0.9338014362581641\n",
      "precision_full: [0.95357143 0.96521739 0.90869565 0.93665158 0.85121107 1.        ]\n",
      "recall_full: [0.97445255 0.89878543 0.9587156  0.8247012  0.94615385 1.        ]\n",
      "2.0114049911499023\n",
      "accuracy_full: 0.9442031453197477\n",
      "precision_full: [0.94791667 0.96995708 0.94570136 0.93103448 0.88043478 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.9587156  0.86055777 0.93461538 1.        ]\n",
      "1.919928789138794\n",
      "accuracy_full: 0.9249775830023651\n",
      "precision_full: [0.93771626 0.96460177 0.9380531  0.86363636 0.85018727 1.        ]\n",
      "recall_full: [0.98905109 0.88259109 0.97247706 0.83266932 0.87307692 1.        ]\n",
      "2.2649402618408203\n",
      "accuracy_full: 0.9483547073082702\n",
      "precision_full: [0.95470383 0.98297872 0.95890411 0.91596639 0.88888889 0.99630996]\n",
      "recall_full: [1.         0.93522267 0.96330275 0.8685259  0.92307692 1.        ]\n",
      "2.0162839889526367\n",
      "11\n",
      "accuracy_full: 0.9240585351289329\n",
      "precision_full: [0.90939597 0.97321429 0.94444444 0.88333333 0.85294118 1.        ]\n",
      "recall_full: [0.98905109 0.88259109 0.93577982 0.84462151 0.89230769 1.        ]\n",
      "2.0136783123016357\n",
      "accuracy_full: 0.9361756334824629\n",
      "precision_full: [0.9222973  0.97747748 0.93693694 0.90534979 0.88764045 1.        ]\n",
      "recall_full: [0.99635036 0.87854251 0.95412844 0.87649402 0.91153846 1.        ]\n",
      "2.009474515914917\n",
      "accuracy_full: 0.9303882586361721\n",
      "precision_full: [0.93103448 0.96475771 0.93273543 0.90212766 0.86181818 1.        ]\n",
      "recall_full: [0.98540146 0.88663968 0.95412844 0.84462151 0.91153846 1.        ]\n",
      "2.0752720832824707\n",
      "accuracy_full: 0.9307399679804478\n",
      "precision_full: [0.91610738 0.98253275 0.96698113 0.88655462 0.85347985 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.94036697 0.84063745 0.89615385 1.        ]\n",
      "1.9528224468231201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9365466692130594\n",
      "precision_full: [0.93639576 0.96982759 0.92857143 0.930131   0.86524823 1.        ]\n",
      "recall_full: [0.96715328 0.91093117 0.95412844 0.84860558 0.93846154 1.        ]\n",
      "1.9673776626586914\n",
      "accuracy_full: 0.9223695733158448\n",
      "precision_full: [0.90066225 0.96475771 0.95283019 0.89912281 0.84341637 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.9266055  0.81673307 0.91153846 1.        ]\n",
      "2.0098063945770264\n",
      "accuracy_full: 0.9380585190556477\n",
      "precision_full: [0.94791667 0.98245614 0.94666667 0.90869565 0.85304659 1.        ]\n",
      "recall_full: [0.99635036 0.90688259 0.97706422 0.83266932 0.91538462 1.        ]\n",
      "2.2784900665283203\n",
      "accuracy_full: 0.9376681176484382\n",
      "precision_full: [0.95422535 0.97008547 0.93665158 0.89300412 0.87686567 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.94954128 0.86454183 0.90384615 1.        ]\n",
      "1.9892573356628418\n",
      "accuracy_full: 0.9310060916360813\n",
      "precision_full: [0.94117647 0.96491228 0.94144144 0.90789474 0.84452297 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.9587156  0.8247012  0.91923077 1.        ]\n",
      "2.013495683670044\n",
      "accuracy_full: 0.9419868446825804\n",
      "precision_full: [0.93515358 0.98678414 0.96818182 0.90677966 0.86861314 1.        ]\n",
      "recall_full: [1.         0.90688259 0.97706422 0.85258964 0.91538462 1.        ]\n",
      "2.052192211151123\n",
      "12\n",
      "accuracy_full: 0.9261069569783373\n",
      "precision_full: [0.92517007 0.97630332 0.89270386 0.91101695 0.86594203 1.        ]\n",
      "recall_full: [0.99270073 0.8340081  0.95412844 0.85657371 0.91923077 1.        ]\n",
      "2.1292426586151123\n",
      "accuracy_full: 0.9348781875977137\n",
      "precision_full: [0.92517007 0.97737557 0.92477876 0.92241379 0.87364621 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.9587156  0.85258964 0.93076923 1.        ]\n",
      "2.0810041427612305\n",
      "accuracy_full: 0.9258439426205354\n",
      "precision_full: [0.92491468 0.95945946 0.92920354 0.89699571 0.85507246 1.        ]\n",
      "recall_full: [0.98905109 0.86234818 0.96330275 0.83266932 0.90769231 1.        ]\n",
      "2.078484535217285\n",
      "accuracy_full: 0.9309817575512089\n",
      "precision_full: [0.91438356 0.96521739 0.94063927 0.9137931  0.86642599 1.        ]\n",
      "recall_full: [0.97445255 0.89878543 0.94495413 0.84462151 0.92307692 1.        ]\n",
      "2.3150510787963867\n",
      "accuracy_full: 0.9394110058155635\n",
      "precision_full: [0.91525424 0.97285068 0.95089286 0.92083333 0.88888889 1.        ]\n",
      "recall_full: [0.98540146 0.87044534 0.97706422 0.88047809 0.92307692 1.        ]\n",
      "2.1342825889587402\n",
      "accuracy_full: 0.9308265673136308\n",
      "precision_full: [0.9220339  0.97368421 0.94954128 0.91189427 0.84751773 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.94954128 0.8247012  0.91923077 1.        ]\n",
      "1.9920094013214111\n",
      "accuracy_full: 0.9211294570805668\n",
      "precision_full: [0.89180328 0.98550725 0.9339207  0.91441441 0.83391003 1.        ]\n",
      "recall_full: [0.99270073 0.82591093 0.97247706 0.80876494 0.92692308 1.        ]\n",
      "2.010484457015991\n",
      "accuracy_full: 0.9273086482436597\n",
      "precision_full: [0.92783505 0.96444444 0.91071429 0.90295359 0.86813187 1.        ]\n",
      "recall_full: [0.98540146 0.87854251 0.93577982 0.85258964 0.91153846 1.        ]\n",
      "1.9661586284637451\n",
      "accuracy_full: 0.9239136413243143\n",
      "precision_full: [0.91610738 0.97142857 0.90987124 0.8879668  0.86940299 1.        ]\n",
      "recall_full: [0.99635036 0.82591093 0.97247706 0.85258964 0.89615385 1.        ]\n",
      "1.9347407817840576\n",
      "accuracy_full: 0.9347791054100538\n",
      "precision_full: [0.90939597 0.98139535 0.93832599 0.89878543 0.89353612 1.        ]\n",
      "recall_full: [0.98905109 0.85425101 0.97706422 0.88446215 0.90384615 1.        ]\n",
      "1.9657902717590332\n",
      "13\n",
      "accuracy_full: 0.9327970927691637\n",
      "precision_full: [0.93793103 0.97345133 0.92825112 0.90987124 0.85971223 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.94954128 0.84462151 0.91923077 1.        ]\n",
      "1.966210126876831\n",
      "accuracy_full: 0.9351402087527284\n",
      "precision_full: [0.97826087 0.9787234  0.91666667 0.91818182 0.83161512 1.        ]\n",
      "recall_full: [0.98540146 0.93117409 0.9587156  0.80478088 0.93076923 1.        ]\n",
      "2.1845386028289795\n",
      "accuracy_full: 0.94087951797944\n",
      "precision_full: [0.96085409 0.98717949 0.95067265 0.9017094  0.85251799 1.        ]\n",
      "recall_full: [0.98540146 0.93522267 0.97247706 0.84063745 0.91153846 1.        ]\n",
      "2.2790162563323975\n",
      "accuracy_full: 0.9212900767235017\n",
      "precision_full: [0.89802632 0.969163   0.95673077 0.90990991 0.83044983 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.91284404 0.80478088 0.92307692 1.        ]\n",
      "2.000067710876465\n",
      "accuracy_full: 0.9388479692989007\n",
      "precision_full: [0.92783505 0.97379913 0.94520548 0.92735043 0.87364621 1.        ]\n",
      "recall_full: [0.98540146 0.90283401 0.94954128 0.86454183 0.93076923 1.        ]\n",
      "1.9921176433563232\n",
      "accuracy_full: 0.9285446494036251\n",
      "precision_full: [0.91525424 0.96982759 0.94392523 0.9017094  0.85818182 1.        ]\n",
      "recall_full: [0.98540146 0.91093117 0.9266055  0.84063745 0.90769231 1.        ]\n",
      "1.9904325008392334\n",
      "accuracy_full: 0.9386227936710861\n",
      "precision_full: [0.94463668 0.97767857 0.93421053 0.91810345 0.86642599 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.97706422 0.84860558 0.92307692 1.        ]\n",
      "1.981691837310791\n",
      "accuracy_full: 0.933202317076061\n",
      "precision_full: [0.94137931 0.97368421 0.94170404 0.88702929 0.86296296 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.96330275 0.84462151 0.89615385 1.        ]\n",
      "1.9828596115112305\n",
      "accuracy_full: 0.926452628480298\n",
      "precision_full: [0.91864407 0.97321429 0.94117647 0.88284519 0.85608856 1.        ]\n",
      "recall_full: [0.98905109 0.88259109 0.95412844 0.84063745 0.89230769 1.        ]\n",
      "1.9346318244934082\n",
      "accuracy_full: 0.9388318281446401\n",
      "precision_full: [0.94755245 0.97379913 0.95111111 0.92035398 0.85512367 0.99630996]\n",
      "recall_full: [0.98905109 0.90283401 0.98165138 0.82868526 0.93076923 1.        ]\n",
      "2.291794776916504\n",
      "14\n",
      "accuracy_full: 0.9311868540573073\n",
      "precision_full: [0.94773519 0.9650655  0.92342342 0.92410714 0.84375    1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.94036697 0.8247012  0.93461538 1.        ]\n",
      "2.0131843090057373\n",
      "accuracy_full: 0.940737674037647\n",
      "precision_full: [0.97833935 0.97468354 0.92920354 0.88571429 0.8754717  1.        ]\n",
      "recall_full: [0.98905109 0.93522267 0.96330275 0.86454183 0.89230769 1.        ]\n",
      "1.9987397193908691\n",
      "accuracy_full: 0.9426952685133391\n",
      "precision_full: [0.94097222 0.97844828 0.95909091 0.90123457 0.88389513 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96788991 0.87250996 0.90769231 1.        ]\n",
      "2.000349521636963\n",
      "accuracy_full: 0.927419995015395\n",
      "precision_full: [0.89508197 0.99086758 0.95833333 0.90393013 0.84697509 1.        ]\n",
      "recall_full: [0.99635036 0.87854251 0.94954128 0.8247012  0.91538462 1.        ]\n",
      "1.942631721496582\n",
      "accuracy_full: 0.9399304684076916\n",
      "precision_full: [0.92150171 0.97356828 0.93607306 0.92887029 0.89338235 1.        ]\n",
      "recall_full: [0.98540146 0.89473684 0.94036697 0.88446215 0.93461538 1.        ]\n",
      "1.9881038665771484\n",
      "accuracy_full: 0.9428065824756547\n",
      "precision_full: [0.94444444 0.98297872 0.95391705 0.92207792 0.86738351 1.        ]\n",
      "recall_full: [0.99270073 0.93522267 0.94954128 0.84860558 0.93076923 1.        ]\n",
      "1.9629621505737305\n",
      "accuracy_full: 0.9479232096502757\n",
      "precision_full: [0.95759717 0.97890295 0.95909091 0.92307692 0.87681159 1.        ]\n",
      "recall_full: [0.98905109 0.93927126 0.96788991 0.86055777 0.93076923 1.        ]\n",
      "1.9395737648010254\n",
      "accuracy_full: 0.9265658691341447\n",
      "precision_full: [0.91525424 0.96832579 0.93721973 0.88477366 0.86567164 1.        ]\n",
      "recall_full: [0.98540146 0.86639676 0.9587156  0.85657371 0.89230769 1.        ]\n",
      "2.3753223419189453\n",
      "accuracy_full: 0.9316827473885869\n",
      "precision_full: [0.93127148 0.96969697 0.94520548 0.8907563  0.86346863 1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.94954128 0.84462151 0.9        1.        ]\n",
      "2.0472373962402344\n",
      "accuracy_full: 0.9430043329932268\n",
      "precision_full: [0.9347079  0.97247706 0.9173913  0.92682927 0.91320755 1.        ]\n",
      "recall_full: [0.99270073 0.8582996  0.96788991 0.90836653 0.93076923 1.        ]\n",
      "2.0198123455047607\n",
      "15\n",
      "accuracy_full: 0.9252156876477561\n",
      "precision_full: [0.92491468 0.97695853 0.89519651 0.91703057 0.85460993 1.        ]\n",
      "recall_full: [0.98905109 0.8582996  0.94036697 0.83665339 0.92692308 1.        ]\n",
      "1.993462324142456\n",
      "accuracy_full: 0.9388812139810564\n",
      "precision_full: [0.95759717 0.97424893 0.92825112 0.91452991 0.86642599 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.94954128 0.85258964 0.92307692 1.        ]\n",
      "1.9758095741271973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9430968036732975\n",
      "precision_full: [0.95744681 0.975      0.95852535 0.91416309 0.86330935 1.        ]\n",
      "recall_full: [0.98540146 0.94736842 0.95412844 0.84860558 0.92307692 1.        ]\n",
      "1.9623761177062988\n",
      "accuracy_full: 0.9273641787037749\n",
      "precision_full: [0.90033223 0.98642534 0.94470046 0.9017094  0.85559567 1.        ]\n",
      "recall_full: [0.98905109 0.88259109 0.94036697 0.84063745 0.91153846 1.        ]\n",
      "1.9902055263519287\n",
      "accuracy_full: 0.9430220247233546\n",
      "precision_full: [0.93079585 0.98245614 0.93693694 0.9214876  0.89591078 1.        ]\n",
      "recall_full: [0.98175182 0.90688259 0.95412844 0.88844622 0.92692308 1.        ]\n",
      "1.9557390213012695\n",
      "accuracy_full: 0.9339626604135288\n",
      "precision_full: [0.93793103 0.98712446 0.94907407 0.91855204 0.83448276 1.        ]\n",
      "recall_full: [0.99270073 0.93117409 0.94036697 0.80876494 0.93076923 1.        ]\n",
      "2.3342154026031494\n",
      "accuracy_full: 0.9406433506380095\n",
      "precision_full: [0.95070423 0.98245614 0.92982456 0.93362832 0.85915493 1.        ]\n",
      "recall_full: [0.98540146 0.90688259 0.97247706 0.84063745 0.93846154 1.        ]\n",
      "2.0196762084960938\n",
      "accuracy_full: 0.9452269037940036\n",
      "precision_full: [0.96126761 0.97826087 0.94642857 0.91213389 0.87912088 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.97247706 0.8685259  0.92307692 1.        ]\n",
      "1.9839754104614258\n",
      "accuracy_full: 0.925454112916336\n",
      "precision_full: [0.89438944 0.96803653 0.94495413 0.89583333 0.87037037 1.        ]\n",
      "recall_full: [0.98905109 0.8582996  0.94495413 0.85657371 0.90384615 1.        ]\n",
      "1.9366230964660645\n",
      "accuracy_full: 0.9514770466454961\n",
      "precision_full: [0.95744681 0.97478992 0.9638009  0.9279661  0.89338235 0.99630996]\n",
      "recall_full: [0.98540146 0.93927126 0.97706422 0.87250996 0.93461538 1.        ]\n",
      "2.0316953659057617\n",
      "16\n",
      "accuracy_full: 0.9370899269964691\n",
      "precision_full: [0.95070423 0.97033898 0.94117647 0.90909091 0.85971223 1.        ]\n",
      "recall_full: [0.98540146 0.92712551 0.95412844 0.83665339 0.91923077 1.        ]\n",
      "1.9200975894927979\n",
      "accuracy_full: 0.9468199506760704\n",
      "precision_full: [0.95729537 0.97881356 0.93243243 0.94736842 0.87632509 1.        ]\n",
      "recall_full: [0.98175182 0.93522267 0.94954128 0.86055777 0.95384615 1.        ]\n",
      "1.9349348545074463\n",
      "accuracy_full: 0.9430838726934567\n",
      "precision_full: [0.96085409 0.97890295 0.94570136 0.92920354 0.85614035 1.        ]\n",
      "recall_full: [0.98540146 0.93927126 0.9587156  0.83665339 0.93846154 1.        ]\n",
      "1.99123215675354\n",
      "accuracy_full: 0.9256024080541239\n",
      "precision_full: [0.88064516 0.97685185 0.95305164 0.9106383  0.86594203 1.        ]\n",
      "recall_full: [0.99635036 0.85425101 0.93119266 0.85258964 0.91923077 1.        ]\n",
      "2.2865817546844482\n",
      "accuracy_full: 0.9429205223346865\n",
      "precision_full: [0.94097222 0.97457627 0.95833333 0.91596639 0.87867647 1.        ]\n",
      "recall_full: [0.98905109 0.93117409 0.94954128 0.8685259  0.91923077 1.        ]\n",
      "2.00900936126709\n",
      "accuracy_full: 0.9326931267576382\n",
      "precision_full: [0.93493151 0.97844828 0.9537037  0.91071429 0.83916084 1.        ]\n",
      "recall_full: [0.99635036 0.91902834 0.94495413 0.812749   0.92307692 1.        ]\n",
      "2.014054298400879\n",
      "accuracy_full: 0.9349072042393402\n",
      "precision_full: [0.95759717 0.96566524 0.92857143 0.92376682 0.8466899  1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.95412844 0.82071713 0.93461538 1.        ]\n",
      "2.11704421043396\n",
      "accuracy_full: 0.9423010813041709\n",
      "precision_full: [0.96819788 0.9665272  0.9587156  0.9055794  0.86281588 1.        ]\n",
      "recall_full: [1.         0.93522267 0.9587156  0.84063745 0.91923077 1.        ]\n",
      "2.0221197605133057\n",
      "accuracy_full: 0.9288939298967275\n",
      "precision_full: [0.93448276 0.96929825 0.92376682 0.8907563  0.86346863 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.94495413 0.84462151 0.9        1.        ]\n",
      "1.9661719799041748\n",
      "accuracy_full: 0.9445413867528565\n",
      "precision_full: [0.93814433 0.96956522 0.96363636 0.91631799 0.89219331 0.99630996]\n",
      "recall_full: [0.99635036 0.90283401 0.97247706 0.87250996 0.92307692 1.        ]\n",
      "1.9588449001312256\n",
      "17\n",
      "accuracy_full: 0.9268376298531072\n",
      "precision_full: [0.91610738 0.96969697 0.95238095 0.89699571 0.84892086 1.        ]\n",
      "recall_full: [0.99635036 0.90688259 0.91743119 0.83266932 0.90769231 1.        ]\n",
      "1.9858996868133545\n",
      "accuracy_full: 0.9416683472110409\n",
      "precision_full: [0.95744681 0.96995708 0.93303571 0.93421053 0.86572438 1.        ]\n",
      "recall_full: [0.98540146 0.91497976 0.9587156  0.84860558 0.94230769 1.        ]\n",
      "2.2022852897644043\n",
      "accuracy_full: 0.938567104861641\n",
      "precision_full: [0.95053004 0.97424893 0.92857143 0.89795918 0.88301887 1.        ]\n",
      "recall_full: [0.98175182 0.91902834 0.95412844 0.87649402 0.9        1.        ]\n",
      "1.9819161891937256\n",
      "accuracy_full: 0.9358251602746984\n",
      "precision_full: [0.91304348 0.98660714 0.94907407 0.91880342 0.8700361  1.        ]\n",
      "recall_full: [0.99635036 0.89473684 0.94036697 0.85657371 0.92692308 1.        ]\n",
      "1.9847028255462646\n",
      "accuracy_full: 0.9418875693739063\n",
      "precision_full: [0.91864407 0.97777778 0.94063927 0.94042553 0.89130435 1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.94495413 0.88047809 0.94615385 1.        ]\n",
      "1.9580481052398682\n",
      "accuracy_full: 0.9386095420680564\n",
      "precision_full: [0.94137931 0.98290598 0.9537037  0.92792793 0.84722222 1.        ]\n",
      "recall_full: [0.99635036 0.93117409 0.94495413 0.82071713 0.93846154 1.        ]\n",
      "1.9869065284729004\n",
      "accuracy_full: 0.9406328031252288\n",
      "precision_full: [0.97132616 0.97446809 0.93362832 0.91304348 0.85714286 1.        ]\n",
      "recall_full: [0.98905109 0.92712551 0.96788991 0.83665339 0.92307692 1.        ]\n",
      "1.9605889320373535\n",
      "accuracy_full: 0.9357437205085243\n",
      "precision_full: [0.93835616 0.97345133 0.95045045 0.90517241 0.85971223 1.        ]\n",
      "recall_full: [1.         0.89068826 0.96788991 0.83665339 0.91923077 1.        ]\n",
      "1.904057502746582\n",
      "accuracy_full: 0.9234383166996993\n",
      "precision_full: [0.92491468 0.96444444 0.92342342 0.8893617  0.85090909 1.        ]\n",
      "recall_full: [0.98905109 0.87854251 0.94036697 0.83266932 0.9        1.        ]\n",
      "1.9955763816833496\n",
      "accuracy_full: 0.9451894310713184\n",
      "precision_full: [0.95070423 0.96581197 0.94618834 0.93913043 0.8781362  1.        ]\n",
      "recall_full: [0.98540146 0.91497976 0.96788991 0.86055777 0.94230769 1.        ]\n",
      "2.3175177574157715\n",
      "18\n",
      "accuracy_full: 0.9267353848374049\n",
      "precision_full: [0.91245791 0.97309417 0.94907407 0.89121339 0.85454545 1.        ]\n",
      "recall_full: [0.98905109 0.87854251 0.94036697 0.84860558 0.90384615 1.        ]\n",
      "1.997950792312622\n",
      "accuracy_full: 0.9424430547104032\n",
      "precision_full: [0.97101449 0.9665272  0.92857143 0.92640693 0.86785714 1.        ]\n",
      "recall_full: [0.97810219 0.93522267 0.95412844 0.85258964 0.93461538 1.        ]\n",
      "1.9612646102905273\n",
      "accuracy_full: 0.9399266865302617\n",
      "precision_full: [0.9471831  0.97424893 0.94144144 0.90456432 0.87777778 1.        ]\n",
      "recall_full: [0.98175182 0.91902834 0.9587156  0.8685259  0.91153846 1.        ]\n",
      "1.9978680610656738\n",
      "accuracy_full: 0.9281570240963642\n",
      "precision_full: [0.92068966 0.96444444 0.91964286 0.93273543 0.85069444 1.        ]\n",
      "recall_full: [0.97445255 0.87854251 0.94495413 0.82868526 0.94230769 1.        ]\n",
      "1.9716017246246338\n",
      "accuracy_full: 0.9381289217240928\n",
      "precision_full: [0.93706294 0.96902655 0.90350877 0.93277311 0.89338235 1.        ]\n",
      "recall_full: [0.97810219 0.88663968 0.94495413 0.88446215 0.93461538 1.        ]\n",
      "2.615009069442749\n",
      "accuracy_full: 0.9166747101051413\n",
      "precision_full: [0.93771626 0.96444444 0.90666667 0.88839286 0.81881533 1.        ]\n",
      "recall_full: [0.98905109 0.87854251 0.93577982 0.79282869 0.90384615 1.        ]\n",
      "2.0312395095825195\n",
      "accuracy_full: 0.9391902722771114\n",
      "precision_full: [0.95698925 0.96595745 0.92070485 0.93777778 0.86267606 1.        ]\n",
      "recall_full: [0.97445255 0.91902834 0.9587156  0.84063745 0.94230769 1.        ]\n",
      "2.294468402862549\n",
      "accuracy_full: 0.9415250247030805\n",
      "precision_full: [0.95759717 0.96202532 0.94090909 0.91914894 0.87636364 1.        ]\n",
      "recall_full: [0.98905109 0.92307692 0.94954128 0.86055777 0.92692308 1.        ]\n",
      "2.0295774936676025\n",
      "accuracy_full: 0.9334033497777529\n",
      "precision_full: [0.93425606 0.97727273 0.9137931  0.90376569 0.87777778 1.        ]\n",
      "recall_full: [0.98540146 0.87044534 0.97247706 0.86055777 0.91153846 1.        ]\n",
      "1.96708345413208\n",
      "accuracy_full: 0.9336366073332267\n",
      "precision_full: [0.95035461 0.96103896 0.90789474 0.92173913 0.86738351 1.        ]\n",
      "recall_full: [0.97810219 0.89878543 0.94954128 0.84462151 0.93076923 1.        ]\n",
      "1.9976365566253662\n",
      "19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9362265225483687\n",
      "precision_full: [0.92857143 0.97757848 0.94170404 0.92920354 0.85915493 1.        ]\n",
      "recall_full: [0.99635036 0.88259109 0.96330275 0.83665339 0.93846154 1.        ]\n",
      "1.9332692623138428\n",
      "accuracy_full: 0.9403182458804494\n",
      "precision_full: [0.96785714 0.96707819 0.94954128 0.91266376 0.85357143 1.        ]\n",
      "recall_full: [0.98905109 0.951417   0.94954128 0.83266932 0.91923077 1.        ]\n",
      "1.940671682357788\n",
      "accuracy_full: 0.9389245126665159\n",
      "precision_full: [0.95774648 0.97033898 0.94545455 0.91666667 0.85460993 1.        ]\n",
      "recall_full: [0.99270073 0.92712551 0.95412844 0.83266932 0.92692308 1.        ]\n",
      "2.010667324066162\n",
      "accuracy_full: 0.9333177808853733\n",
      "precision_full: [0.91919192 0.98230088 0.94907407 0.89626556 0.87037037 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.94036697 0.86055777 0.90384615 1.        ]\n",
      "1.960360050201416\n",
      "accuracy_full: 0.9411564957201505\n",
      "precision_full: [0.92150171 0.97807018 0.93577982 0.93277311 0.89377289 1.        ]\n",
      "recall_full: [0.98540146 0.90283401 0.93577982 0.88446215 0.93846154 1.        ]\n",
      "2.296492576599121\n",
      "accuracy_full: 0.9231783048583452\n",
      "precision_full: [0.92808219 0.96536797 0.91818182 0.89519651 0.84532374 1.        ]\n",
      "recall_full: [0.98905109 0.90283401 0.9266055  0.81673307 0.90384615 1.        ]\n",
      "1.9897165298461914\n",
      "accuracy_full: 0.9296782780457135\n",
      "precision_full: [0.94736842 0.96475771 0.9122807  0.90869565 0.85357143 1.        ]\n",
      "recall_full: [0.98540146 0.88663968 0.95412844 0.83266932 0.91923077 1.        ]\n",
      "1.9900107383728027\n",
      "accuracy_full: 0.9325818127953225\n",
      "precision_full: [0.94117647 0.97379913 0.94594595 0.88983051 0.8540146  1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.96330275 0.83665339 0.9        1.        ]\n",
      "1.9976444244384766\n",
      "accuracy_full: 0.9161606354587853\n",
      "precision_full: [0.91525424 0.95890411 0.91111111 0.88135593 0.84363636 1.        ]\n",
      "recall_full: [0.98540146 0.85020243 0.94036697 0.82868526 0.89230769 1.        ]\n",
      "1.9674232006072998\n",
      "accuracy_full: 0.9510543363041788\n",
      "precision_full: [0.94463668 0.98245614 0.95067265 0.94067797 0.9010989  0.99630996]\n",
      "recall_full: [0.99635036 0.90688259 0.97247706 0.88446215 0.94615385 1.        ]\n",
      "2.002554416656494\n",
      "20\n",
      "accuracy_full: 0.9402893093946202\n",
      "precision_full: [0.9220339  0.97757848 0.94594595 0.92765957 0.88363636 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.96330275 0.8685259  0.93461538 1.        ]\n",
      "1.9697215557098389\n",
      "accuracy_full: 0.9341788800599464\n",
      "precision_full: [0.95438596 0.96566524 0.92825112 0.91266376 0.85357143 1.        ]\n",
      "recall_full: [0.99270073 0.91093117 0.94954128 0.83266932 0.91923077 1.        ]\n",
      "1.93800687789917\n",
      "accuracy_full: 0.9415702954641844\n",
      "precision_full: [0.94425087 0.96982759 0.94545455 0.92340426 0.87681159 1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.95412844 0.86454183 0.93076923 1.        ]\n",
      "2.3022429943084717\n",
      "accuracy_full: 0.9223929243062914\n",
      "precision_full: [0.89802632 0.99052133 0.91517857 0.91964286 0.84320557 1.        ]\n",
      "recall_full: [0.99635036 0.84615385 0.94036697 0.82071713 0.93076923 1.        ]\n",
      "1.9817407131195068\n",
      "accuracy_full: 0.9334252367389905\n",
      "precision_full: [0.93031359 0.96995708 0.92272727 0.90794979 0.87822878 1.        ]\n",
      "recall_full: [0.97445255 0.91497976 0.93119266 0.86454183 0.91538462 1.        ]\n",
      "1.9819717407226562\n",
      "accuracy_full: 0.9366263014367524\n",
      "precision_full: [0.93174061 0.97413793 0.94883721 0.89068826 0.88593156 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.93577982 0.87649402 0.89615385 1.        ]\n",
      "1.9560253620147705\n",
      "accuracy_full: 0.9390804822650761\n",
      "precision_full: [0.9434629  0.95319149 0.93693694 0.93103448 0.87769784 1.        ]\n",
      "recall_full: [0.97445255 0.90688259 0.95412844 0.86055777 0.93846154 1.        ]\n",
      "2.0795605182647705\n",
      "accuracy_full: 0.9337403637245156\n",
      "precision_full: [0.95104895 0.96956522 0.92888889 0.90128755 0.85869565 1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.9587156  0.83665339 0.91153846 1.        ]\n",
      "2.0493152141571045\n",
      "accuracy_full: 0.930573902918999\n",
      "precision_full: [0.91864407 0.96412556 0.94144144 0.87747036 0.89105058 1.        ]\n",
      "recall_full: [0.98905109 0.87044534 0.9587156  0.88446215 0.88076923 1.        ]\n",
      "1.9514431953430176\n",
      "accuracy_full: 0.9469963985101089\n",
      "precision_full: [0.93493151 0.97807018 0.95454545 0.91836735 0.90909091 0.99630996]\n",
      "recall_full: [0.99635036 0.90283401 0.96330275 0.89641434 0.92307692 1.        ]\n",
      "2.0905656814575195\n",
      "21\n",
      "accuracy_full: 0.942928970269648\n",
      "precision_full: [0.93174061 0.98672566 0.95909091 0.94594595 0.85813149 1.        ]\n",
      "recall_full: [0.99635036 0.90283401 0.96788991 0.83665339 0.95384615 1.        ]\n",
      "2.615262746810913\n",
      "accuracy_full: 0.9472526738581465\n",
      "precision_full: [0.95789474 0.98689956 0.9380531  0.91701245 0.88847584 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.97247706 0.88047809 0.91923077 1.        ]\n",
      "2.094388723373413\n",
      "accuracy_full: 0.9296077663365803\n",
      "precision_full: [0.90816327 0.97368421 0.94930876 0.92035398 0.84912281 1.        ]\n",
      "recall_full: [0.97445255 0.89878543 0.94495413 0.82868526 0.93076923 1.        ]\n",
      "2.663851261138916\n",
      "accuracy_full: 0.9363400983623625\n",
      "precision_full: [0.91156463 0.98214286 0.93665158 0.91322314 0.88847584 1.        ]\n",
      "recall_full: [0.97810219 0.89068826 0.94954128 0.88047809 0.91923077 1.        ]\n",
      "3.4665915966033936\n",
      "accuracy_full: 0.9426622768732686\n",
      "precision_full: [0.93402778 0.97402597 0.93181818 0.93277311 0.89377289 1.        ]\n",
      "recall_full: [0.98175182 0.91093117 0.94036697 0.88446215 0.93846154 1.        ]\n",
      "3.2178986072540283\n",
      "accuracy_full: 0.947828939780849\n",
      "precision_full: [0.94137931 0.97826087 0.94063927 0.93723849 0.90073529 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.94495413 0.89243028 0.94230769 1.        ]\n",
      "2.814707040786743\n",
      "accuracy_full: 0.9466682110803037\n",
      "precision_full: [0.94463668 0.98678414 0.93273543 0.94017094 0.88808664 1.        ]\n",
      "recall_full: [0.99635036 0.90688259 0.95412844 0.87649402 0.94615385 1.        ]\n",
      "3.441040277481079\n",
      "accuracy_full: 0.9402781901788294\n",
      "precision_full: [0.95422535 0.96186441 0.94520548 0.90123457 0.88432836 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.94954128 0.87250996 0.91153846 1.        ]\n",
      "3.073197603225708\n",
      "accuracy_full: 0.927648286124874\n",
      "precision_full: [0.9009901  0.96296296 0.93181818 0.930131   0.86524823 1.        ]\n",
      "recall_full: [0.99635036 0.84210526 0.94036697 0.84860558 0.93846154 1.        ]\n",
      "2.520080804824829\n",
      "accuracy_full: 0.9452798924377287\n",
      "precision_full: [0.96428571 0.97854077 0.92951542 0.92340426 0.88       1.        ]\n",
      "recall_full: [0.98540146 0.92307692 0.96788991 0.86454183 0.93076923 1.        ]\n",
      "2.0220694541931152\n",
      "22\n",
      "accuracy_full: 0.9430433234823595\n",
      "precision_full: [0.94425087 0.97424893 0.9543379  0.91949153 0.87636364 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.9587156  0.86454183 0.92692308 1.        ]\n",
      "2.0869431495666504\n",
      "accuracy_full: 0.9432761203377757\n",
      "precision_full: [0.97142857 0.98728814 0.94196429 0.91266376 0.85409253 1.        ]\n",
      "recall_full: [0.99270073 0.94331984 0.96788991 0.83266932 0.92307692 1.        ]\n",
      "2.0336673259735107\n",
      "accuracy_full: 0.9379096975989629\n",
      "precision_full: [0.96085409 0.97890295 0.94570136 0.90434783 0.84697509 1.        ]\n",
      "recall_full: [0.98540146 0.93927126 0.9587156  0.82868526 0.91538462 1.        ]\n",
      "2.431735038757324\n",
      "accuracy_full: 0.9286177788633769\n",
      "precision_full: [0.93728223 0.99099099 0.91304348 0.90707965 0.83859649 1.        ]\n",
      "recall_full: [0.98175182 0.89068826 0.96330275 0.81673307 0.91923077 1.        ]\n",
      "2.0456559658050537\n",
      "accuracy_full: 0.9355618620276558\n",
      "precision_full: [0.9209622  0.96956522 0.93636364 0.92307692 0.87636364 1.        ]\n",
      "recall_full: [0.97810219 0.90283401 0.94495413 0.86055777 0.92692308 1.        ]\n",
      "2.0237722396850586\n",
      "accuracy_full: 0.9226258506261469\n",
      "precision_full: [0.91808874 0.97285068 0.89867841 0.91189427 0.85106383 1.        ]\n",
      "recall_full: [0.98175182 0.87044534 0.93577982 0.8247012  0.92307692 1.        ]\n",
      "2.00250244140625\n",
      "accuracy_full: 0.9324045464000214\n",
      "precision_full: [0.93793103 0.97757848 0.92477876 0.89583333 0.86715867 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.9587156  0.85657371 0.90384615 1.        ]\n",
      "1.938627004623413\n",
      "accuracy_full: 0.9391661809189351\n",
      "precision_full: [0.94791667 0.97379913 0.94594595 0.8902439  0.88301887 1.        ]\n",
      "recall_full: [0.99635036 0.90283401 0.96330275 0.87250996 0.9        1.        ]\n",
      "1.9602820873260498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9289723198000762\n",
      "precision_full: [0.90635452 0.96296296 0.92920354 0.92207792 0.8705036  1.        ]\n",
      "recall_full: [0.98905109 0.84210526 0.96330275 0.84860558 0.93076923 1.        ]\n",
      "1.9377048015594482\n",
      "accuracy_full: 0.9484654843392598\n",
      "precision_full: [0.96113074 0.97435897 0.94618834 0.9279661  0.89010989 0.99630996]\n",
      "recall_full: [0.99270073 0.92307692 0.96788991 0.87250996 0.93461538 1.        ]\n",
      "1.9462811946868896\n",
      "23\n",
      "accuracy_full: 0.9390521628663705\n",
      "precision_full: [0.94097222 0.96982759 0.94977169 0.90123457 0.88059701 1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.95412844 0.87250996 0.90769231 1.        ]\n",
      "2.2584288120269775\n",
      "accuracy_full: 0.94182439304087\n",
      "precision_full: [0.97132616 0.97844828 0.9254386  0.93303571 0.85365854 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96788991 0.83266932 0.94230769 1.        ]\n",
      "1.9776649475097656\n",
      "accuracy_full: 0.9410417291537589\n",
      "precision_full: [0.96126761 0.97083333 0.95852535 0.89873418 0.86397059 1.        ]\n",
      "recall_full: [0.99635036 0.94331984 0.95412844 0.84860558 0.90384615 1.        ]\n",
      "1.975893259048462\n",
      "accuracy_full: 0.9211222472443809\n",
      "precision_full: [0.90301003 0.97716895 0.91402715 0.89787234 0.85507246 1.        ]\n",
      "recall_full: [0.98540146 0.86639676 0.9266055  0.84063745 0.90769231 1.        ]\n",
      "2.0238072872161865\n",
      "accuracy_full: 0.9339086104818451\n",
      "precision_full: [0.91156463 0.96069869 0.94444444 0.93478261 0.87188612 1.        ]\n",
      "recall_full: [0.97810219 0.89068826 0.93577982 0.85657371 0.94230769 1.        ]\n",
      "1.961012840270996\n",
      "accuracy_full: 0.932561624632918\n",
      "precision_full: [0.93150685 0.96       0.91964286 0.92608696 0.87096774 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.94495413 0.84860558 0.93461538 1.        ]\n",
      "1.92698335647583\n",
      "accuracy_full: 0.9407393582995218\n",
      "precision_full: [0.93150685 0.97737557 0.92477876 0.94372294 0.88214286 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.9587156  0.8685259  0.95       1.        ]\n",
      "1.9533345699310303\n",
      "accuracy_full: 0.9311000016820387\n",
      "precision_full: [0.94809689 0.97368421 0.93721973 0.87916667 0.85555556 1.        ]\n",
      "recall_full: [1.         0.89878543 0.9587156  0.84063745 0.88846154 1.        ]\n",
      "1.94484281539917\n",
      "accuracy_full: 0.9260112351683301\n",
      "precision_full: [0.92808219 0.97695853 0.92173913 0.9        0.84341637 1.        ]\n",
      "recall_full: [0.98905109 0.8582996  0.97247706 0.8247012  0.91153846 1.        ]\n",
      "2.2658655643463135\n",
      "accuracy_full: 0.9465531606246714\n",
      "precision_full: [0.95774648 0.97863248 0.95045045 0.91596639 0.88560886 0.99630996]\n",
      "recall_full: [0.99270073 0.92712551 0.96788991 0.8685259  0.92307692 1.        ]\n",
      "1.9889886379241943\n",
      "24\n",
      "accuracy_full: 0.9378272007663987\n",
      "precision_full: [0.93150685 0.97737557 0.93362832 0.90909091 0.88475836 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.96788991 0.87649402 0.91538462 1.        ]\n",
      "2.0088138580322266\n",
      "accuracy_full: 0.9418033781711056\n",
      "precision_full: [0.96808511 0.98283262 0.93777778 0.92035398 0.85211268 1.        ]\n",
      "recall_full: [0.99635036 0.92712551 0.96788991 0.82868526 0.93076923 1.        ]\n",
      "1.95332932472229\n",
      "accuracy_full: 0.9325451174713552\n",
      "precision_full: [0.95774648 0.97835498 0.9375     0.89867841 0.83450704 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.96330275 0.812749   0.91153846 1.        ]\n",
      "1.9741134643554688\n",
      "accuracy_full: 0.9147971116011403\n",
      "precision_full: [0.89666667 0.97706422 0.92307692 0.88311688 0.83214286 1.        ]\n",
      "recall_full: [0.98175182 0.86234818 0.93577982 0.812749   0.89615385 1.        ]\n",
      "2.000214099884033\n",
      "accuracy_full: 0.9406935158354082\n",
      "precision_full: [0.92150171 0.98237885 0.9321267  0.93589744 0.88727273 1.        ]\n",
      "recall_full: [0.98540146 0.90283401 0.94495413 0.87250996 0.93846154 1.        ]\n",
      "1.9948813915252686\n",
      "accuracy_full: 0.9333908775357055\n",
      "precision_full: [0.9375     0.95670996 0.92792793 0.9254386  0.86476868 1.        ]\n",
      "recall_full: [0.98540146 0.89473684 0.94495413 0.84063745 0.93461538 1.        ]\n",
      "1.9712364673614502\n",
      "accuracy_full: 0.92612493455997\n",
      "precision_full: [0.91525424 0.97297297 0.91964286 0.90869565 0.85663082 1.        ]\n",
      "recall_full: [0.98540146 0.87449393 0.94495413 0.83266932 0.91923077 1.        ]\n",
      "2.2045905590057373\n",
      "accuracy_full: 0.9300424596320364\n",
      "precision_full: [0.93814433 0.96902655 0.94618834 0.87295082 0.86090226 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.96788991 0.84860558 0.88076923 1.        ]\n",
      "1.9764516353607178\n",
      "accuracy_full: 0.9269817664937335\n",
      "precision_full: [0.91245791 0.96713615 0.91304348 0.91810345 0.86690647 1.        ]\n",
      "recall_full: [0.98905109 0.8340081  0.96330275 0.84860558 0.92692308 1.        ]\n",
      "1.9980134963989258\n",
      "accuracy_full: 0.9367271147759367\n",
      "precision_full: [0.93174061 0.98198198 0.94222222 0.88709677 0.88931298 0.9962963 ]\n",
      "recall_full: [0.99635036 0.88259109 0.97247706 0.87649402 0.89615385 0.9962963 ]\n",
      "1.9739103317260742\n",
      "25\n",
      "accuracy_full: 0.946386234084179\n",
      "precision_full: [0.93174061 0.98214286 0.95495495 0.93617021 0.88768116 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.97247706 0.87649402 0.94230769 1.        ]\n",
      "1.9718263149261475\n",
      "accuracy_full: 0.9409377651044979\n",
      "precision_full: [0.97482014 0.95491803 0.94954128 0.91341991 0.86021505 1.        ]\n",
      "recall_full: [0.98905109 0.94331984 0.94954128 0.84063745 0.92307692 1.        ]\n",
      "1.9279475212097168\n",
      "accuracy_full: 0.9459321628344557\n",
      "precision_full: [0.96453901 0.98312236 0.95909091 0.91416309 0.86330935 1.        ]\n",
      "recall_full: [0.99270073 0.94331984 0.96788991 0.84860558 0.92307692 1.        ]\n",
      "1.9427149295806885\n",
      "accuracy_full: 0.9335188116248009\n",
      "precision_full: [0.91304348 0.99107143 0.95833333 0.89539749 0.86397059 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.94954128 0.85258964 0.90384615 1.        ]\n",
      "2.0470924377441406\n",
      "accuracy_full: 0.9354068012545169\n",
      "precision_full: [0.9209622  0.97807018 0.92307692 0.91666667 0.88518519 1.        ]\n",
      "recall_full: [0.97810219 0.90283401 0.93577982 0.87649402 0.91923077 1.        ]\n",
      "2.2159929275512695\n",
      "accuracy_full: 0.934696199652406\n",
      "precision_full: [0.92808219 0.96902655 0.93243243 0.93362832 0.86267606 1.        ]\n",
      "recall_full: [0.98905109 0.88663968 0.94954128 0.84063745 0.94230769 1.        ]\n",
      "1.9968628883361816\n",
      "accuracy_full: 0.9335450314456873\n",
      "precision_full: [0.9347079  0.98648649 0.92920354 0.94392523 0.83501684 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.96330275 0.80478088 0.95384615 1.        ]\n",
      "1.9845860004425049\n",
      "accuracy_full: 0.9314600827300072\n",
      "precision_full: [0.93493151 0.96846847 0.92444444 0.90638298 0.86594203 1.        ]\n",
      "recall_full: [0.99635036 0.87044534 0.95412844 0.84860558 0.91923077 1.        ]\n",
      "1.9765312671661377\n",
      "accuracy_full: 0.922816985711601\n",
      "precision_full: [0.90666667 0.96296296 0.92888889 0.92272727 0.84083045 1.        ]\n",
      "recall_full: [0.99270073 0.84210526 0.9587156  0.80876494 0.93461538 1.        ]\n",
      "2.1168103218078613\n",
      "accuracy_full: 0.9411987620025423\n",
      "precision_full: [0.96453901 0.97435897 0.9375     0.90336134 0.87453875 0.99630996]\n",
      "recall_full: [0.99270073 0.92307692 0.96330275 0.85657371 0.91153846 1.        ]\n",
      "2.015838861465454\n",
      "26\n",
      "accuracy_full: 0.9488957110890591\n",
      "precision_full: [0.95121951 0.97854077 0.9587156  0.925      0.88970588 1.        ]\n",
      "recall_full: [0.99635036 0.92307692 0.9587156  0.88446215 0.93076923 1.        ]\n",
      "1.9940211772918701\n",
      "accuracy_full: 0.9449059407373427\n",
      "precision_full: [0.96099291 0.97510373 0.96296296 0.93693694 0.85121107 1.        ]\n",
      "recall_full: [0.98905109 0.951417   0.95412844 0.82868526 0.94615385 1.        ]\n",
      "2.812004566192627\n",
      "accuracy_full: 0.9470364542117289\n",
      "precision_full: [0.95789474 0.98297872 0.95890411 0.92274678 0.8705036  1.        ]\n",
      "recall_full: [0.99635036 0.93522267 0.96330275 0.85657371 0.93076923 1.        ]\n",
      "2.1709511280059814\n",
      "accuracy_full: 0.93350489558827\n",
      "precision_full: [0.91582492 0.98648649 0.94545455 0.9173913  0.85765125 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.95412844 0.84063745 0.92692308 1.        ]\n",
      "1.9973351955413818\n",
      "accuracy_full: 0.941003559188153\n",
      "precision_full: [0.92068966 0.98245614 0.93273543 0.94323144 0.88214286 1.        ]\n",
      "recall_full: [0.97445255 0.90688259 0.95412844 0.86055777 0.95       1.        ]\n",
      "2.0359435081481934\n",
      "accuracy_full: 0.9327048669850811\n",
      "precision_full: [0.92491468 0.97797357 0.93636364 0.92070485 0.85512367 1.        ]\n",
      "recall_full: [0.98905109 0.89878543 0.94495413 0.83266932 0.93076923 1.        ]\n",
      "1.966304063796997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9358248290390802\n",
      "precision_full: [0.92491468 0.98654709 0.93303571 0.89795918 0.88301887 1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.9587156  0.87649402 0.9        1.        ]\n",
      "1.997469186782837\n",
      "accuracy_full: 0.9350134262157505\n",
      "precision_full: [0.93174061 0.96460177 0.95022624 0.91025641 0.86594203 1.        ]\n",
      "recall_full: [0.99635036 0.88259109 0.96330275 0.84860558 0.91923077 1.        ]\n",
      "1.9549827575683594\n",
      "accuracy_full: 0.9347321957711885\n",
      "precision_full: [0.92176871 0.9638009  0.92035398 0.93506494 0.88129496 1.        ]\n",
      "recall_full: [0.98905109 0.86234818 0.95412844 0.86055777 0.94230769 1.        ]\n",
      "1.9260549545288086\n",
      "accuracy_full: 0.9436416221409359\n",
      "precision_full: [0.96453901 0.96929825 0.91304348 0.92827004 0.89338235 0.99630996]\n",
      "recall_full: [0.99270073 0.89473684 0.96330275 0.87649402 0.93461538 1.        ]\n",
      "2.3098034858703613\n",
      "27\n",
      "accuracy_full: 0.936249635033688\n",
      "precision_full: [0.92491468 0.97402597 0.95833333 0.90677966 0.86861314 1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.94954128 0.85258964 0.91538462 1.        ]\n",
      "1.9761874675750732\n",
      "accuracy_full: 0.9441294234361948\n",
      "precision_full: [0.97132616 0.98297872 0.94666667 0.92070485 0.85211268 1.        ]\n",
      "recall_full: [0.98905109 0.93522267 0.97706422 0.83266932 0.93076923 1.        ]\n",
      "1.9817194938659668\n",
      "accuracy_full: 0.9472246814734907\n",
      "precision_full: [0.97482014 0.97925311 0.95454545 0.91810345 0.86379928 1.        ]\n",
      "recall_full: [0.98905109 0.95546559 0.96330275 0.84860558 0.92692308 1.        ]\n",
      "1.999276876449585\n",
      "accuracy_full: 0.924708707910105\n",
      "precision_full: [0.90397351 0.98617512 0.94090909 0.90707965 0.83859649 1.        ]\n",
      "recall_full: [0.99635036 0.86639676 0.94954128 0.81673307 0.91923077 1.        ]\n",
      "1.9752728939056396\n",
      "accuracy_full: 0.9359563804724423\n",
      "precision_full: [0.91438356 0.969163   0.92727273 0.93589744 0.88447653 1.        ]\n",
      "recall_full: [0.97445255 0.89068826 0.93577982 0.87250996 0.94230769 1.        ]\n",
      "1.9817488193511963\n",
      "accuracy_full: 0.9313470497341326\n",
      "precision_full: [0.9220339  0.98198198 0.92376682 0.91025641 0.86594203 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.94495413 0.84860558 0.91923077 1.        ]\n",
      "2.0073773860931396\n",
      "accuracy_full: 0.9337211152346878\n",
      "precision_full: [0.91891892 0.98617512 0.92920354 0.90794979 0.875      1.        ]\n",
      "recall_full: [0.99270073 0.86639676 0.96330275 0.86454183 0.91538462 1.        ]\n",
      "1.9346210956573486\n",
      "accuracy_full: 0.9423698305578961\n",
      "precision_full: [0.95789474 0.96982759 0.94170404 0.91525424 0.87591241 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.96330275 0.86055777 0.92307692 1.        ]\n",
      "2.4289820194244385\n",
      "accuracy_full: 0.9279025459754183\n",
      "precision_full: [0.92150171 0.97630332 0.89830508 0.91810345 0.86690647 1.        ]\n",
      "recall_full: [0.98540146 0.8340081  0.97247706 0.84860558 0.92692308 1.        ]\n",
      "2.1293349266052246\n",
      "accuracy_full: 0.9419427666361387\n",
      "precision_full: [0.96808511 0.97424893 0.93777778 0.89669421 0.88014981 0.99630996]\n",
      "recall_full: [0.99635036 0.91902834 0.96788991 0.86454183 0.90384615 1.        ]\n",
      "1.9973301887512207\n",
      "28\n",
      "accuracy_full: 0.9335515647597438\n",
      "precision_full: [0.9347079  0.96943231 0.94520548 0.89915966 0.86446886 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.94954128 0.85258964 0.90769231 1.        ]\n",
      "1.9819159507751465\n",
      "accuracy_full: 0.9428566467964649\n",
      "precision_full: [0.97132616 0.98734177 0.95515695 0.91517857 0.83972125 1.        ]\n",
      "recall_full: [0.98905109 0.94736842 0.97706422 0.81673307 0.92692308 1.        ]\n",
      "1.9662959575653076\n",
      "accuracy_full: 0.9430208300464281\n",
      "precision_full: [0.95789474 0.98297872 0.9543379  0.91025641 0.86281588 1.        ]\n",
      "recall_full: [0.99635036 0.93522267 0.9587156  0.84860558 0.91923077 1.        ]\n",
      "1.9500725269317627\n",
      "accuracy_full: 0.9274431876565115\n",
      "precision_full: [0.89438944 0.99082569 0.94495413 0.90212766 0.85869565 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94495413 0.84462151 0.91153846 1.        ]\n",
      "1.9750711917877197\n",
      "accuracy_full: 0.9314002460358298\n",
      "precision_full: [0.91752577 0.95652174 0.93150685 0.91914894 0.87636364 1.        ]\n",
      "recall_full: [0.97445255 0.89068826 0.93577982 0.86055777 0.92692308 1.        ]\n",
      "1.990492343902588\n",
      "accuracy_full: 0.9281161870714979\n",
      "precision_full: [0.92783505 0.97356828 0.91928251 0.90128755 0.85869565 1.        ]\n",
      "recall_full: [0.98540146 0.89473684 0.94036697 0.83665339 0.91153846 1.        ]\n",
      "2.2844061851501465\n",
      "accuracy_full: 0.9342794755854574\n",
      "precision_full: [0.94117647 0.98190045 0.91703057 0.92888889 0.85314685 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.96330275 0.83266932 0.93846154 1.        ]\n",
      "1.9870896339416504\n",
      "accuracy_full: 0.9323036176766277\n",
      "precision_full: [0.91919192 0.95945946 0.95022624 0.90677966 0.87226277 1.        ]\n",
      "recall_full: [0.99635036 0.86234818 0.96330275 0.85258964 0.91923077 1.        ]\n",
      "1.946399211883545\n",
      "accuracy_full: 0.9263277297170699\n",
      "precision_full: [0.92176871 0.96803653 0.92070485 0.90869565 0.85357143 1.        ]\n",
      "recall_full: [0.98905109 0.8582996  0.9587156  0.83266932 0.91923077 1.        ]\n",
      "1.9977176189422607\n",
      "accuracy_full: 0.9385889772859203\n",
      "precision_full: [0.94736842 0.97767857 0.91341991 0.91596639 0.88560886 0.99630996]\n",
      "recall_full: [0.98540146 0.88663968 0.96788991 0.8685259  0.92307692 1.        ]\n",
      "1.9949958324432373\n",
      "29\n",
      "accuracy_full: 0.9389287407070452\n",
      "precision_full: [0.93835616 0.97816594 0.9543379  0.90677966 0.86861314 1.        ]\n",
      "recall_full: [1.         0.90688259 0.9587156  0.85258964 0.91538462 1.        ]\n",
      "1.9457876682281494\n",
      "accuracy_full: 0.946405690231979\n",
      "precision_full: [0.95422535 0.98701299 0.9375     0.93133047 0.87769784 1.        ]\n",
      "recall_full: [0.98905109 0.92307692 0.96330275 0.86454183 0.93846154 1.        ]\n",
      "1.9704551696777344\n",
      "accuracy_full: 0.9434115666137847\n",
      "precision_full: [0.97482014 0.98319328 0.94196429 0.90598291 0.85869565 1.        ]\n",
      "recall_full: [0.98905109 0.94736842 0.96788991 0.84462151 0.91153846 1.        ]\n",
      "2.0369186401367188\n",
      "accuracy_full: 0.9277689114634594\n",
      "precision_full: [0.92465753 0.97737557 0.92035398 0.89166667 0.86346863 1.        ]\n",
      "recall_full: [0.98540146 0.87449393 0.95412844 0.85258964 0.9        1.        ]\n",
      "2.218620538711548\n",
      "accuracy_full: 0.9364869149339835\n",
      "precision_full: [0.91836735 0.96929825 0.94009217 0.93133047 0.87769784 1.        ]\n",
      "recall_full: [0.98540146 0.89473684 0.93577982 0.86454183 0.93846154 1.        ]\n",
      "2.00630259513855\n",
      "accuracy_full: 0.932259745325894\n",
      "precision_full: [0.93814433 0.97368421 0.92825112 0.88842975 0.87218045 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.94954128 0.85657371 0.89230769 1.        ]\n",
      "1.997648000717163\n",
      "accuracy_full: 0.9368467409776021\n",
      "precision_full: [0.92857143 0.98206278 0.93721973 0.92207792 0.86738351 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.9587156  0.84860558 0.93076923 1.        ]\n",
      "2.026247262954712\n",
      "accuracy_full: 0.9289989591584756\n",
      "precision_full: [0.92881356 0.97272727 0.93721973 0.88114754 0.86567164 1.        ]\n",
      "recall_full: [1.         0.86639676 0.9587156  0.85657371 0.89230769 1.        ]\n",
      "1.9434375762939453\n",
      "accuracy_full: 0.935070642900005\n",
      "precision_full: [0.92517007 0.96860987 0.94170404 0.90794979 0.87822878 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.96330275 0.86454183 0.91538462 1.        ]\n",
      "1.9782750606536865\n",
      "accuracy_full: 0.9378516643157102\n",
      "precision_full: [0.92517007 0.97716895 0.92951542 0.90322581 0.90076336 1.        ]\n",
      "recall_full: [0.99270073 0.86639676 0.96788991 0.89243028 0.90769231 1.        ]\n",
      "2.0291638374328613\n",
      "30\n",
      "accuracy_full: 0.932927198445778\n",
      "precision_full: [0.92465753 0.98198198 0.92888889 0.93665158 0.84827586 1.        ]\n",
      "recall_full: [0.98540146 0.88259109 0.9587156  0.8247012  0.94615385 1.        ]\n",
      "2.076005458831787\n",
      "accuracy_full: 0.9432316289376543\n",
      "precision_full: [0.97142857 0.98717949 0.93777778 0.91703057 0.85460993 1.        ]\n",
      "recall_full: [0.99270073 0.93522267 0.96788991 0.83665339 0.92692308 1.        ]\n",
      "2.1387879848480225\n",
      "accuracy_full: 0.9377972363060985\n",
      "precision_full: [0.95087719 0.9665272  0.96759259 0.91150442 0.84507042 1.        ]\n",
      "recall_full: [0.98905109 0.93522267 0.9587156  0.82071713 0.92307692 1.        ]\n",
      "2.0255849361419678\n",
      "accuracy_full: 0.9403125802292697\n",
      "precision_full: [0.91304348 0.99539171 0.94618834 0.92765957 0.88043478 1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.96788991 0.8685259  0.93461538 1.        ]\n",
      "2.0290615558624268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9336182637442917\n",
      "precision_full: [0.92758621 0.97368421 0.92792793 0.90082645 0.88059701 1.        ]\n",
      "recall_full: [0.98175182 0.89878543 0.94495413 0.8685259  0.90769231 1.        ]\n",
      "1.9548161029815674\n",
      "accuracy_full: 0.9290429242397004\n",
      "precision_full: [0.92542373 0.96956522 0.94392523 0.89451477 0.85766423 1.        ]\n",
      "recall_full: [0.99635036 0.90283401 0.9266055  0.84462151 0.90384615 1.        ]\n",
      "1.9822180271148682\n",
      "accuracy_full: 0.9266960182326084\n",
      "precision_full: [0.9220339  0.98666667 0.94063927 0.91324201 0.82534247 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.94495413 0.79681275 0.92692308 1.        ]\n",
      "1.9182379245758057\n",
      "accuracy_full: 0.9291852945003903\n",
      "precision_full: [0.93493151 0.96860987 0.93777778 0.89655172 0.84892086 1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.96788991 0.82868526 0.90769231 1.        ]\n",
      "1.9945507049560547\n",
      "accuracy_full: 0.9309070548325346\n",
      "precision_full: [0.92832765 0.96888889 0.93693694 0.9017094  0.86231884 1.        ]\n",
      "recall_full: [0.99270073 0.88259109 0.95412844 0.84063745 0.91538462 1.        ]\n",
      "2.106688976287842\n",
      "accuracy_full: 0.941224290764341\n",
      "precision_full: [0.94791667 0.97333333 0.92982456 0.90909091 0.89473684 0.99630996]\n",
      "recall_full: [0.99635036 0.88663968 0.97247706 0.87649402 0.91538462 1.        ]\n",
      "2.121769428253174\n",
      "31\n",
      "accuracy_full: 0.9335606337063574\n",
      "precision_full: [0.91554054 0.96902655 0.95412844 0.92173913 0.86071429 1.        ]\n",
      "recall_full: [0.98905109 0.88663968 0.95412844 0.84462151 0.92692308 1.        ]\n",
      "2.0129616260528564\n",
      "accuracy_full: 0.941637564189478\n",
      "precision_full: [0.95454545 0.98275862 0.94570136 0.91416309 0.86330935 1.        ]\n",
      "recall_full: [0.99635036 0.92307692 0.9587156  0.84860558 0.92307692 1.        ]\n",
      "2.0203540325164795\n",
      "accuracy_full: 0.9543293243596329\n",
      "precision_full: [0.96140351 0.98312236 0.96774194 0.9218107  0.89925373 1.        ]\n",
      "recall_full: [1.         0.94331984 0.96330275 0.89243028 0.92692308 1.        ]\n",
      "1.9740004539489746\n",
      "accuracy_full: 0.9280512525046221\n",
      "precision_full: [0.90728477 0.98190045 0.95391705 0.9004329  0.84946237 1.        ]\n",
      "recall_full: [1.         0.87854251 0.94954128 0.82868526 0.91153846 1.        ]\n",
      "1.961634874343872\n",
      "accuracy_full: 0.940285988217248\n",
      "precision_full: [0.93379791 0.97402597 0.93243243 0.92765957 0.88363636 1.        ]\n",
      "recall_full: [0.97810219 0.91093117 0.94954128 0.8685259  0.93461538 1.        ]\n",
      "2.097933292388916\n",
      "accuracy_full: 0.9278882619693211\n",
      "precision_full: [0.94097222 0.97345133 0.92511013 0.89867841 0.84042553 1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.96330275 0.812749   0.91153846 1.        ]\n",
      "1.991994857788086\n",
      "accuracy_full: 0.9338466330473038\n",
      "precision_full: [0.909699   0.97695853 0.92376682 0.9279661  0.88363636 1.        ]\n",
      "recall_full: [0.99270073 0.8582996  0.94495413 0.87250996 0.93461538 1.        ]\n",
      "2.2332093715667725\n",
      "accuracy_full: 0.9393915148960797\n",
      "precision_full: [0.94463668 0.96460177 0.92444444 0.92405063 0.88644689 1.        ]\n",
      "recall_full: [0.99635036 0.88259109 0.95412844 0.87250996 0.93076923 1.        ]\n",
      "2.0138237476348877\n",
      "accuracy_full: 0.9395114410294801\n",
      "precision_full: [0.94076655 0.97379913 0.94642857 0.89754098 0.88345865 1.        ]\n",
      "recall_full: [0.98540146 0.90283401 0.97247706 0.87250996 0.90384615 1.        ]\n",
      "1.9559972286224365\n",
      "accuracy_full: 0.9473957105146019\n",
      "precision_full: [0.96099291 0.97835498 0.93832599 0.92405063 0.88970588 0.99630996]\n",
      "recall_full: [0.98905109 0.91497976 0.97706422 0.87250996 0.93076923 1.        ]\n",
      "2.005885362625122\n",
      "32\n",
      "accuracy_full: 0.9365779480034037\n",
      "precision_full: [0.91275168 0.97333333 0.9537037  0.92703863 0.87410072 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.94495413 0.86055777 0.93461538 1.        ]\n",
      "2.089653968811035\n",
      "accuracy_full: 0.9426258200544287\n",
      "precision_full: [0.95774648 0.98290598 0.95045045 0.90638298 0.86545455 1.        ]\n",
      "recall_full: [0.99270073 0.93117409 0.96788991 0.84860558 0.91538462 1.        ]\n",
      "2.076519012451172\n",
      "accuracy_full: 0.9421312015558727\n",
      "precision_full: [0.97463768 0.97468354 0.92920354 0.89387755 0.87969925 1.        ]\n",
      "recall_full: [0.98175182 0.93522267 0.96330275 0.87250996 0.9        1.        ]\n",
      "1.9860174655914307\n",
      "accuracy_full: 0.9355854167515458\n",
      "precision_full: [0.93493151 0.99122807 0.95412844 0.9047619  0.84697509 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.95412844 0.83266932 0.91538462 1.        ]\n",
      "1.9666166305541992\n",
      "accuracy_full: 0.9415338077981891\n",
      "precision_full: [0.93402778 0.97844828 0.94520548 0.93478261 0.87188612 1.        ]\n",
      "recall_full: [0.98175182 0.91902834 0.94954128 0.85657371 0.94230769 1.        ]\n",
      "2.273092746734619\n",
      "accuracy_full: 0.9286264078307239\n",
      "precision_full: [0.9220339  0.96491228 0.93577982 0.89166667 0.86988848 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.93577982 0.85258964 0.9        1.        ]\n",
      "2.0131704807281494\n",
      "accuracy_full: 0.9357812425398514\n",
      "precision_full: [0.90066225 0.97196262 0.92825112 0.94827586 0.88888889 1.        ]\n",
      "recall_full: [0.99270073 0.84210526 0.94954128 0.87649402 0.95384615 1.        ]\n",
      "2.004720449447632\n",
      "accuracy_full: 0.9464995220844035\n",
      "precision_full: [0.96428571 0.9665272  0.94545455 0.90039841 0.90384615 1.        ]\n",
      "recall_full: [0.98540146 0.93522267 0.95412844 0.90039841 0.90384615 1.        ]\n",
      "1.9711229801177979\n",
      "accuracy_full: 0.9300292428006908\n",
      "precision_full: [0.9347079  0.97333333 0.93777778 0.88284519 0.85925926 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.96788991 0.84063745 0.89230769 1.        ]\n",
      "1.9189245700836182\n",
      "accuracy_full: 0.930538686161199\n",
      "precision_full: [0.92808219 0.97297297 0.92477876 0.88306452 0.88167939 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.9587156  0.87250996 0.88846154 1.        ]\n",
      "2.0485944747924805\n",
      "33\n",
      "accuracy_full: 0.9464438621598491\n",
      "precision_full: [0.95470383 0.98290598 0.95890411 0.90163934 0.88721805 1.        ]\n",
      "recall_full: [1.         0.93117409 0.96330275 0.87649402 0.90769231 1.        ]\n",
      "2.3392817974090576\n",
      "accuracy_full: 0.9365291812163751\n",
      "precision_full: [0.95104895 0.97835498 0.94594595 0.90128755 0.85251799 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.96330275 0.83665339 0.91153846 1.        ]\n",
      "1.98347806930542\n",
      "accuracy_full: 0.9425717681604809\n",
      "precision_full: [0.94755245 0.97844828 0.95022624 0.90495868 0.88104089 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96330275 0.87250996 0.91153846 1.        ]\n",
      "2.294106960296631\n",
      "accuracy_full: 0.941439928599387\n",
      "precision_full: [0.95438596 0.99563319 0.95111111 0.92727273 0.83848797 1.        ]\n",
      "recall_full: [0.99270073 0.92307692 0.98165138 0.812749   0.93846154 1.        ]\n",
      "2.023681402206421\n",
      "accuracy_full: 0.9287978420794177\n",
      "precision_full: [0.92758621 0.97321429 0.9159292  0.93577982 0.84246575 1.        ]\n",
      "recall_full: [0.98175182 0.88259109 0.94954128 0.812749   0.94615385 1.        ]\n",
      "2.029024124145508\n",
      "accuracy_full: 0.9318760274359738\n",
      "precision_full: [0.92517007 0.96943231 0.94009217 0.90638298 0.86545455 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.93577982 0.84860558 0.91538462 1.        ]\n",
      "2.059758424758911\n",
      "accuracy_full: 0.9361607323892422\n",
      "precision_full: [0.91554054 0.97706422 0.92477876 0.93534483 0.88129496 1.        ]\n",
      "recall_full: [0.98905109 0.86234818 0.9587156  0.86454183 0.94230769 1.        ]\n",
      "2.0727624893188477\n",
      "accuracy_full: 0.9393462441349761\n",
      "precision_full: [0.93493151 0.9650655  0.94954128 0.91983122 0.87956204 1.        ]\n",
      "recall_full: [0.99635036 0.89473684 0.94954128 0.8685259  0.92692308 1.        ]\n",
      "2.047092914581299\n",
      "accuracy_full: 0.9275214172482659\n",
      "precision_full: [0.92176871 0.96902655 0.93636364 0.8940678  0.85766423 1.        ]\n",
      "recall_full: [0.98905109 0.88663968 0.94495413 0.84063745 0.90384615 1.        ]\n",
      "2.0651116371154785\n",
      "accuracy_full: 0.9384121222820349\n",
      "precision_full: [0.96113074 0.96581197 0.93693694 0.8902439  0.87924528 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.95412844 0.87250996 0.89615385 1.        ]\n",
      "2.1130948066711426\n",
      "34\n",
      "accuracy_full: 0.9465123255620692\n",
      "precision_full: [0.94773519 0.98689956 0.94170404 0.904      0.90421456 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.96330275 0.90039841 0.90769231 1.        ]\n",
      "2.2557621002197266\n",
      "accuracy_full: 0.9373286381165541\n",
      "precision_full: [0.95087719 0.97844828 0.94594595 0.89166667 0.86346863 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96330275 0.85258964 0.9        1.        ]\n",
      "2.0139479637145996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.939489200635634\n",
      "precision_full: [0.94425087 0.98283262 0.94063927 0.91101695 0.86909091 1.        ]\n",
      "recall_full: [0.98905109 0.92712551 0.94495413 0.85657371 0.91923077 1.        ]\n",
      "1.9764742851257324\n",
      "accuracy_full: 0.9319432981235317\n",
      "precision_full: [0.91554054 0.97321429 0.92760181 0.91489362 0.87591241 1.        ]\n",
      "recall_full: [0.98905109 0.88259109 0.94036697 0.85657371 0.92307692 1.        ]\n",
      "1.9982941150665283\n",
      "accuracy_full: 0.9193309602597934\n",
      "precision_full: [0.91496599 0.96860987 0.9103139  0.8961039  0.84229391 1.        ]\n",
      "recall_full: [0.98175182 0.87449393 0.93119266 0.8247012  0.90384615 1.        ]\n",
      "1.949385166168213\n",
      "accuracy_full: 0.9245631294372596\n",
      "precision_full: [0.91864407 0.96860987 0.91891892 0.9047619  0.85304659 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.93577982 0.83266932 0.91538462 1.        ]\n",
      "2.0013558864593506\n",
      "accuracy_full: 0.9360677272441776\n",
      "precision_full: [0.93425606 0.97777778 0.9159292  0.9380531  0.86619718 1.        ]\n",
      "recall_full: [0.98540146 0.89068826 0.94954128 0.84462151 0.94615385 1.        ]\n",
      "1.9343469142913818\n",
      "accuracy_full: 0.9368574941860907\n",
      "precision_full: [0.93814433 0.96491228 0.94570136 0.92173913 0.86428571 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.9587156  0.84462151 0.93076923 1.        ]\n",
      "2.153381824493408\n",
      "accuracy_full: 0.9294437949661578\n",
      "precision_full: [0.92176871 0.96428571 0.92825112 0.91703057 0.86071429 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94954128 0.83665339 0.92692308 1.        ]\n",
      "2.0921592712402344\n",
      "accuracy_full: 0.9322466086503454\n",
      "precision_full: [0.93793103 0.96396396 0.91666667 0.91452991 0.86956522 1.        ]\n",
      "recall_full: [0.99270073 0.86639676 0.9587156  0.85258964 0.92307692 1.        ]\n",
      "1.9817969799041748\n",
      "35\n",
      "accuracy_full: 0.9417840495254807\n",
      "precision_full: [0.94137931 0.98275862 0.96330275 0.90677966 0.86861314 1.        ]\n",
      "recall_full: [0.99635036 0.92307692 0.96330275 0.85258964 0.91538462 1.        ]\n",
      "2.0873589515686035\n",
      "accuracy_full: 0.9438220513642793\n",
      "precision_full: [0.95789474 0.98701299 0.9375     0.90123457 0.88389513 1.        ]\n",
      "recall_full: [0.99635036 0.92307692 0.96330275 0.87250996 0.90769231 1.        ]\n",
      "2.7786269187927246\n",
      "accuracy_full: 0.9380191625592128\n",
      "precision_full: [0.94137931 0.98206278 0.9380531  0.89068826 0.88257576 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.97247706 0.87649402 0.89615385 1.        ]\n",
      "2.2959179878234863\n",
      "accuracy_full: 0.9255622186664961\n",
      "precision_full: [0.9        0.98598131 0.92444444 0.91666667 0.85159011 1.        ]\n",
      "recall_full: [0.98540146 0.85425101 0.95412844 0.83266932 0.92692308 1.        ]\n",
      "2.542780637741089\n",
      "accuracy_full: 0.9393898779805824\n",
      "precision_full: [0.93103448 0.97446809 0.94883721 0.90534979 0.88764045 1.        ]\n",
      "recall_full: [0.98540146 0.92712551 0.93577982 0.87649402 0.91153846 1.        ]\n",
      "2.882521152496338\n",
      "accuracy_full: 0.9377234424128456\n",
      "precision_full: [0.93448276 0.97368421 0.93721973 0.91139241 0.87867647 1.        ]\n",
      "recall_full: [0.98905109 0.89878543 0.9587156  0.86055777 0.91923077 1.        ]\n",
      "2.051466703414917\n",
      "accuracy_full: 0.9401967977590329\n",
      "precision_full: [0.93425606 0.97797357 0.93273543 0.93506494 0.875      1.        ]\n",
      "recall_full: [0.98540146 0.89878543 0.95412844 0.86055777 0.94230769 1.        ]\n",
      "1.9914288520812988\n",
      "accuracy_full: 0.9458300413963999\n",
      "precision_full: [0.96140351 0.98701299 0.95515695 0.93693694 0.85121107 1.        ]\n",
      "recall_full: [1.         0.92307692 0.97706422 0.82868526 0.94615385 1.        ]\n",
      "2.0132765769958496\n",
      "accuracy_full: 0.9351486648337873\n",
      "precision_full: [0.93835616 0.97777778 0.94618834 0.89830508 0.86131387 1.        ]\n",
      "recall_full: [1.         0.89068826 0.96788991 0.84462151 0.90769231 1.        ]\n",
      "1.9822216033935547\n",
      "accuracy_full: 0.9377025076988784\n",
      "precision_full: [0.93814433 0.96860987 0.93362832 0.91914894 0.87636364 1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.96788991 0.86055777 0.92692308 1.        ]\n",
      "2.8315420150756836\n",
      "36\n",
      "accuracy_full: 0.9364727438931029\n",
      "precision_full: [0.92857143 0.98237885 0.96347032 0.9122807  0.85106383 1.        ]\n",
      "recall_full: [0.99635036 0.90283401 0.96788991 0.82868526 0.92307692 1.        ]\n",
      "2.274606704711914\n",
      "accuracy_full: 0.9391374893290941\n",
      "precision_full: [0.95759717 0.97046414 0.94570136 0.90909091 0.85971223 1.        ]\n",
      "recall_full: [0.98905109 0.93117409 0.9587156  0.83665339 0.91923077 1.        ]\n",
      "2.0851733684539795\n",
      "accuracy_full: 0.9424013108223797\n",
      "precision_full: [0.96126761 0.98312236 0.9587156  0.9055794  0.85611511 1.        ]\n",
      "recall_full: [0.99635036 0.94331984 0.9587156  0.84063745 0.91538462 1.        ]\n",
      "2.0866310596466064\n",
      "accuracy_full: 0.9319561016011976\n",
      "precision_full: [0.90697674 0.97706422 0.94090909 0.91880342 0.8700361  1.        ]\n",
      "recall_full: [0.99635036 0.86234818 0.94954128 0.85657371 0.92692308 1.        ]\n",
      "2.003352165222168\n",
      "accuracy_full: 0.934411600684094\n",
      "precision_full: [0.92068966 0.97826087 0.94090909 0.91774892 0.86379928 1.        ]\n",
      "recall_full: [0.97445255 0.91093117 0.94954128 0.84462151 0.92692308 1.        ]\n",
      "1.9850153923034668\n",
      "accuracy_full: 0.9318750423792838\n",
      "precision_full: [0.92176871 0.97356828 0.93150685 0.91416309 0.86642599 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.93577982 0.84860558 0.92307692 1.        ]\n",
      "1.9984495639801025\n",
      "accuracy_full: 0.9365286896691623\n",
      "precision_full: [0.94405594 0.97797357 0.92920354 0.91416309 0.86330935 1.        ]\n",
      "recall_full: [0.98540146 0.89878543 0.96330275 0.84860558 0.92307692 1.        ]\n",
      "1.9349172115325928\n",
      "accuracy_full: 0.9409774957543324\n",
      "precision_full: [0.96478873 0.96982759 0.93721973 0.90082645 0.87732342 1.        ]\n",
      "recall_full: [1.         0.91093117 0.9587156  0.8685259  0.90769231 1.        ]\n",
      "2.27791428565979\n",
      "accuracy_full: 0.9326516726456483\n",
      "precision_full: [0.93493151 0.95945946 0.92035398 0.92982456 0.86524823 1.        ]\n",
      "recall_full: [0.99635036 0.86234818 0.95412844 0.84462151 0.93846154 1.        ]\n",
      "2.263779401779175\n",
      "accuracy_full: 0.9349902355368983\n",
      "precision_full: [0.9220339  0.97247706 0.92951542 0.93043478 0.87455197 0.99630996]\n",
      "recall_full: [0.99270073 0.8582996  0.96788991 0.85258964 0.93846154 1.        ]\n",
      "2.472067356109619\n",
      "37\n",
      "accuracy_full: 0.9471694368648805\n",
      "precision_full: [0.96099291 0.9748954  0.95022624 0.92274678 0.88       1.        ]\n",
      "recall_full: [0.98905109 0.94331984 0.96330275 0.85657371 0.93076923 1.        ]\n",
      "2.107131242752075\n",
      "accuracy_full: 0.9348203992104492\n",
      "precision_full: [0.94097222 0.97797357 0.92410714 0.91774892 0.86071429 1.        ]\n",
      "recall_full: [0.98905109 0.89878543 0.94954128 0.84462151 0.92692308 1.        ]\n",
      "3.2478280067443848\n",
      "accuracy_full: 0.9431190894512569\n",
      "precision_full: [0.9540636  0.97468354 0.9543379  0.92207792 0.86428571 1.        ]\n",
      "recall_full: [0.98540146 0.93522267 0.9587156  0.84860558 0.93076923 1.        ]\n",
      "3.0557801723480225\n",
      "accuracy_full: 0.9318442613199851\n",
      "precision_full: [0.90333333 0.96860987 0.94444444 0.9125     0.88191882 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.93577982 0.87250996 0.91923077 1.        ]\n",
      "3.0404183864593506\n",
      "accuracy_full: 0.9431781159372968\n",
      "precision_full: [0.93127148 0.97854077 0.94907407 0.94298246 0.87588652 1.        ]\n",
      "recall_full: [0.98905109 0.92307692 0.94036697 0.85657371 0.95       1.        ]\n",
      "2.475386381149292\n",
      "accuracy_full: 0.9252156074919587\n",
      "precision_full: [0.93448276 0.97345133 0.90222222 0.90086207 0.85198556 1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.93119266 0.83266932 0.90769231 1.        ]\n",
      "2.8096227645874023\n",
      "accuracy_full: 0.9377654701901098\n",
      "precision_full: [0.94076655 0.97826087 0.93721973 0.91774892 0.86379928 1.        ]\n",
      "recall_full: [0.98540146 0.91093117 0.9587156  0.84462151 0.92692308 1.        ]\n",
      "2.070028781890869\n",
      "accuracy_full: 0.9420685703002597\n",
      "precision_full: [0.94158076 0.97379913 0.94545455 0.91983122 0.88278388 1.        ]\n",
      "recall_full: [1.         0.90283401 0.95412844 0.8685259  0.92692308 1.        ]\n",
      "2.040302276611328\n",
      "accuracy_full: 0.9397810587487742\n",
      "precision_full: [0.94117647 0.97356828 0.94196429 0.92241379 0.8705036  1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.96788991 0.85258964 0.93076923 1.        ]\n",
      "2.0223946571350098\n",
      "accuracy_full: 0.9281329327381881\n",
      "precision_full: [0.9222973  0.9638009  0.93243243 0.89256198 0.87313433 0.99630996]\n",
      "recall_full: [0.99635036 0.86234818 0.94954128 0.86055777 0.9        1.        ]\n",
      "2.3283727169036865\n",
      "38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9523930306052102\n",
      "precision_full: [0.96808511 0.97083333 0.95890411 0.92116183 0.89925373 1.        ]\n",
      "recall_full: [0.99635036 0.94331984 0.96330275 0.88446215 0.92692308 1.        ]\n",
      "2.0592801570892334\n",
      "accuracy_full: 0.9277916887886316\n",
      "precision_full: [0.9220339  0.97747748 0.94144144 0.88655462 0.85347985 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.9587156  0.84063745 0.89615385 1.        ]\n",
      "2.0262908935546875\n",
      "accuracy_full: 0.9430570338231825\n",
      "precision_full: [0.94755245 0.97816594 0.93721973 0.91358025 0.88847584 1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.9587156  0.88446215 0.91923077 1.        ]\n",
      "2.328798770904541\n",
      "accuracy_full: 0.9334548312674599\n",
      "precision_full: [0.90397351 0.96860987 0.94392523 0.92405063 0.88321168 1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.9266055  0.87250996 0.93076923 1.        ]\n",
      "2.1869544982910156\n",
      "accuracy_full: 0.9427287662375803\n",
      "precision_full: [0.93448276 0.9789916  0.96244131 0.91914894 0.87591241 1.        ]\n",
      "recall_full: [0.98905109 0.94331984 0.94036697 0.86055777 0.92307692 1.        ]\n",
      "2.320063352584839\n",
      "accuracy_full: 0.9312626281723017\n",
      "precision_full: [0.93493151 0.96103896 0.93981481 0.87698413 0.88416988 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.93119266 0.88047809 0.88076923 1.        ]\n",
      "2.2756693363189697\n",
      "accuracy_full: 0.9365197008783458\n",
      "precision_full: [0.93448276 0.97309417 0.92951542 0.91525424 0.87591241 1.        ]\n",
      "recall_full: [0.98905109 0.87854251 0.96788991 0.86055777 0.92307692 1.        ]\n",
      "2.203359842300415\n",
      "accuracy_full: 0.9385873364458943\n",
      "precision_full: [0.94137931 0.96566524 0.94954128 0.94090909 0.85467128 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.94954128 0.8247012  0.95       1.        ]\n",
      "2.166827440261841\n",
      "accuracy_full: 0.9305648258262882\n",
      "precision_full: [0.92465753 0.96929825 0.95022624 0.91150442 0.84452297 1.        ]\n",
      "recall_full: [0.98540146 0.89473684 0.96330275 0.82071713 0.91923077 1.        ]\n",
      "2.062720775604248\n",
      "accuracy_full: 0.935793266656535\n",
      "precision_full: [0.91333333 0.96296296 0.92857143 0.94372294 0.88530466 1.        ]\n",
      "recall_full: [1.         0.84210526 0.95412844 0.8685259  0.95       1.        ]\n",
      "2.1665399074554443\n",
      "39\n",
      "accuracy_full: 0.9322228443062187\n",
      "precision_full: [0.9220339  0.96902655 0.94545455 0.90948276 0.86281588 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.95412844 0.84063745 0.91923077 1.        ]\n",
      "2.2166781425476074\n",
      "accuracy_full: 0.9373402160701381\n",
      "precision_full: [0.93793103 0.96581197 0.9537037  0.92139738 0.86120996 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.94495413 0.84063745 0.93076923 1.        ]\n",
      "1.9377059936523438\n",
      "accuracy_full: 0.9408943389168636\n",
      "precision_full: [0.9347079  0.97816594 0.9587156  0.930131   0.86219081 1.        ]\n",
      "recall_full: [0.99270073 0.90688259 0.9587156  0.84860558 0.93846154 1.        ]\n",
      "2.0077767372131348\n",
      "accuracy_full: 0.9203343229136727\n",
      "precision_full: [0.88273616 0.96759259 0.93981481 0.91629956 0.84859155 1.        ]\n",
      "recall_full: [0.98905109 0.84615385 0.93119266 0.82868526 0.92692308 1.        ]\n",
      "2.1361002922058105\n",
      "accuracy_full: 0.9434901294034219\n",
      "precision_full: [0.94405594 0.98297872 0.94520548 0.94222222 0.86315789 1.        ]\n",
      "recall_full: [0.98540146 0.93522267 0.94954128 0.84462151 0.94615385 1.        ]\n",
      "1.984586477279663\n",
      "accuracy_full: 0.9355220902152767\n",
      "precision_full: [0.94117647 0.96491228 0.93243243 0.90123457 0.88059701 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.94954128 0.87250996 0.90769231 1.        ]\n",
      "2.015838623046875\n",
      "accuracy_full: 0.9325816070996146\n",
      "precision_full: [0.93127148 0.97747748 0.92951542 0.90598291 0.86231884 1.        ]\n",
      "recall_full: [0.98905109 0.87854251 0.96788991 0.84462151 0.91538462 1.        ]\n",
      "2.006288528442383\n",
      "accuracy_full: 0.9375774486240558\n",
      "precision_full: [0.95121951 0.96581197 0.94977169 0.90598291 0.86231884 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.95412844 0.84462151 0.91538462 1.        ]\n",
      "2.330517292022705\n",
      "accuracy_full: 0.9411469680357437\n",
      "precision_full: [0.91245791 0.98198198 0.95022624 0.90763052 0.90804598 1.        ]\n",
      "recall_full: [0.98905109 0.88259109 0.96330275 0.90039841 0.91153846 1.        ]\n",
      "2.0088531970977783\n",
      "accuracy_full: 0.9256876891327342\n",
      "precision_full: [0.92517007 0.9638009  0.93303571 0.89699571 0.84892086 1.        ]\n",
      "recall_full: [0.99270073 0.86234818 0.9587156  0.83266932 0.90769231 1.        ]\n",
      "2.0479700565338135\n",
      "40\n",
      "accuracy_full: 0.9473908367990981\n",
      "precision_full: [0.93150685 0.97854077 0.95813953 0.91532258 0.91221374 1.        ]\n",
      "recall_full: [0.99270073 0.92307692 0.94495413 0.90438247 0.91923077 1.        ]\n",
      "1.992025375366211\n",
      "accuracy_full: 0.9375652641957778\n",
      "precision_full: [0.93127148 0.98237885 0.91855204 0.95067265 0.86458333 1.        ]\n",
      "recall_full: [0.98905109 0.90283401 0.93119266 0.84462151 0.95769231 1.        ]\n",
      "1.9897165298461914\n",
      "accuracy_full: 0.9355061239095686\n",
      "precision_full: [0.91808874 0.96536797 0.94930876 0.91880342 0.87636364 1.        ]\n",
      "recall_full: [0.98175182 0.90283401 0.94495413 0.85657371 0.92692308 1.        ]\n",
      "2.000214099884033\n",
      "accuracy_full: 0.9282911689140629\n",
      "precision_full: [0.89508197 0.97368421 0.95145631 0.91810345 0.86379928 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.89908257 0.84860558 0.92692308 1.        ]\n",
      "2.023723840713501\n",
      "accuracy_full: 0.9433085609956272\n",
      "precision_full: [0.91610738 0.98245614 0.94366197 0.94092827 0.89781022 1.        ]\n",
      "recall_full: [0.99635036 0.90688259 0.92201835 0.88844622 0.94615385 1.        ]\n",
      "2.024815082550049\n",
      "accuracy_full: 0.9202027406331553\n",
      "precision_full: [0.86261981 0.98564593 0.92201835 0.91139241 0.87545788 1.        ]\n",
      "recall_full: [0.98540146 0.8340081  0.92201835 0.86055777 0.91923077 1.        ]\n",
      "2.3166677951812744\n",
      "accuracy_full: 0.9315035890734387\n",
      "precision_full: [0.9220339  0.98181818 0.92857143 0.9137931  0.86021505 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.95412844 0.84462151 0.92307692 1.        ]\n",
      "1.984586477279663\n",
      "accuracy_full: 0.9349436938675996\n",
      "precision_full: [0.90604027 0.98181818 0.94570136 0.93043478 0.8683274  1.        ]\n",
      "recall_full: [0.98540146 0.87449393 0.9587156  0.85258964 0.93846154 1.        ]\n",
      "2.0317509174346924\n",
      "accuracy_full: 0.9214590101113224\n",
      "precision_full: [0.88815789 0.9638009  0.94907407 0.8940678  0.85714286 1.        ]\n",
      "recall_full: [0.98540146 0.86234818 0.94036697 0.84063745 0.9        1.        ]\n",
      "2.0229532718658447\n",
      "accuracy_full: 0.9369559592866273\n",
      "precision_full: [0.94755245 0.96995708 0.94117647 0.91703057 0.85765125 1.        ]\n",
      "recall_full: [0.98905109 0.91497976 0.95412844 0.83665339 0.92692308 1.        ]\n",
      "2.000213384628296\n",
      "41\n",
      "accuracy_full: 0.9324375853864694\n",
      "precision_full: [0.90365449 0.96860987 0.97222222 0.90295359 0.86813187 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.96330275 0.85258964 0.91153846 1.        ]\n",
      "1.993398904800415\n",
      "accuracy_full: 0.9355062021031014\n",
      "precision_full: [0.92517007 0.96943231 0.95852535 0.92105263 0.85815603 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.95412844 0.83665339 0.93076923 1.        ]\n",
      "2.0198824405670166\n",
      "accuracy_full: 0.9443131449520195\n",
      "precision_full: [0.92733564 0.9650655  0.94144144 0.95258621 0.89208633 1.        ]\n",
      "recall_full: [0.97810219 0.89473684 0.9587156  0.88047809 0.95384615 1.        ]\n",
      "2.002310276031494\n",
      "accuracy_full: 0.9211256959239279\n",
      "precision_full: [0.90066225 0.95535714 0.94392523 0.88429752 0.8619403  1.        ]\n",
      "recall_full: [0.99270073 0.86639676 0.9266055  0.85258964 0.88846154 1.        ]\n",
      "2.3184306621551514\n",
      "accuracy_full: 0.9368969061750008\n",
      "precision_full: [0.9009901  0.97321429 0.95305164 0.92468619 0.89298893 1.        ]\n",
      "recall_full: [0.99635036 0.88259109 0.93119266 0.88047809 0.93076923 1.        ]\n",
      "2.125225305557251\n",
      "accuracy_full: 0.9292233554253081\n",
      "precision_full: [0.92176871 0.95708155 0.95283019 0.88571429 0.87218045 1.        ]\n",
      "recall_full: [0.98905109 0.90283401 0.9266055  0.86454183 0.89230769 1.        ]\n",
      "2.0184223651885986\n",
      "accuracy_full: 0.9440696711193831\n",
      "precision_full: [0.91610738 0.97777778 0.96313364 0.93991416 0.88808664 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.9587156  0.87250996 0.94615385 1.        ]\n",
      "2.1294662952423096\n",
      "accuracy_full: 0.9259085913359061\n",
      "precision_full: [0.93006993 0.94805195 0.92825112 0.89451477 0.86080586 1.        ]\n",
      "recall_full: [0.97080292 0.88663968 0.94954128 0.84462151 0.90384615 1.        ]\n",
      "2.1095991134643555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.924308824202602\n",
      "precision_full: [0.89508197 0.95555556 0.96190476 0.89495798 0.86397059 1.        ]\n",
      "recall_full: [0.99635036 0.87044534 0.9266055  0.84860558 0.90384615 1.        ]\n",
      "2.110860824584961\n",
      "accuracy_full: 0.9457410625206855\n",
      "precision_full: [0.96402878 0.98283262 0.92608696 0.90243902 0.8973384  1.        ]\n",
      "recall_full: [0.97810219 0.92712551 0.97706422 0.88446215 0.90769231 1.        ]\n",
      "2.1349966526031494\n",
      "42\n",
      "accuracy_full: 0.9358125972644243\n",
      "precision_full: [0.92176871 0.98222222 0.94570136 0.89711934 0.88014981 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.9587156  0.8685259  0.90384615 1.        ]\n",
      "2.969480514526367\n",
      "accuracy_full: 0.9461772388109053\n",
      "precision_full: [0.95422535 0.9790795  0.95852535 0.94570136 0.85813149 1.        ]\n",
      "recall_full: [0.98905109 0.94736842 0.95412844 0.83266932 0.95384615 1.        ]\n",
      "2.1605050563812256\n",
      "accuracy_full: 0.9433431051738288\n",
      "precision_full: [0.96774194 0.97468354 0.94196429 0.91774892 0.86379928 1.        ]\n",
      "recall_full: [0.98540146 0.93522267 0.96788991 0.84462151 0.92692308 1.        ]\n",
      "2.0158395767211914\n",
      "accuracy_full: 0.9168381941499195\n",
      "precision_full: [0.88064516 0.97685185 0.94366197 0.89177489 0.84285714 1.        ]\n",
      "recall_full: [0.99635036 0.85425101 0.92201835 0.82071713 0.90769231 1.        ]\n",
      "2.140852212905884\n",
      "accuracy_full: 0.9478581640804475\n",
      "precision_full: [0.94405594 0.9789916  0.94444444 0.94017094 0.89130435 1.        ]\n",
      "recall_full: [0.98540146 0.94331984 0.93577982 0.87649402 0.94615385 1.        ]\n",
      "1.9722788333892822\n",
      "accuracy_full: 0.9337405713824878\n",
      "precision_full: [0.9375     0.96943231 0.93273543 0.90295359 0.86813187 1.        ]\n",
      "recall_full: [0.98540146 0.89878543 0.95412844 0.85258964 0.91153846 1.        ]\n",
      "2.0305445194244385\n",
      "accuracy_full: 0.9395525291341679\n",
      "precision_full: [0.95390071 0.97021277 0.93243243 0.93362832 0.85964912 1.        ]\n",
      "recall_full: [0.98175182 0.92307692 0.94954128 0.84063745 0.94230769 1.        ]\n",
      "2.2971203327178955\n",
      "accuracy_full: 0.948959039587593\n",
      "precision_full: [0.95087719 0.97008547 0.95454545 0.94782609 0.88256228 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96330275 0.8685259  0.95384615 1.        ]\n",
      "2.0405569076538086\n",
      "accuracy_full: 0.9267476166120607\n",
      "precision_full: [0.91245791 0.96860987 0.93181818 0.89211618 0.86988848 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94036697 0.85657371 0.9        1.        ]\n",
      "2.351030111312866\n",
      "accuracy_full: 0.9463094029027945\n",
      "precision_full: [0.93493151 0.97379913 0.96330275 0.9214876  0.89925373 0.99630996]\n",
      "recall_full: [0.99635036 0.90283401 0.96330275 0.88844622 0.92692308 1.        ]\n",
      "2.2189862728118896\n",
      "43\n",
      "accuracy_full: 0.9410207964020562\n",
      "precision_full: [0.93793103 0.97345133 0.9375     0.92016807 0.88602941 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.96330275 0.87250996 0.92692308 1.        ]\n",
      "1.9622344970703125\n",
      "accuracy_full: 0.9368508025227041\n",
      "precision_full: [0.94405594 0.96995708 0.94117647 0.94444444 0.84353741 1.        ]\n",
      "recall_full: [0.98540146 0.91497976 0.95412844 0.812749   0.95384615 1.        ]\n",
      "2.0939722061157227\n",
      "accuracy_full: 0.9329056920288009\n",
      "precision_full: [0.93103448 0.96428571 0.92070485 0.93721973 0.86013986 1.        ]\n",
      "recall_full: [0.98540146 0.87449393 0.9587156  0.83266932 0.94615385 1.        ]\n",
      "2.083235263824463\n",
      "accuracy_full: 0.9256769813083591\n",
      "precision_full: [0.90397351 0.97727273 0.94009217 0.91964286 0.84320557 1.        ]\n",
      "recall_full: [0.99635036 0.87044534 0.93577982 0.82071713 0.93076923 1.        ]\n",
      "2.037423610687256\n",
      "accuracy_full: 0.9362083538079863\n",
      "precision_full: [0.91216216 0.97356828 0.92626728 0.92857143 0.89338235 1.        ]\n",
      "recall_full: [0.98540146 0.89473684 0.92201835 0.88047809 0.93461538 1.        ]\n",
      "1.988511562347412\n",
      "accuracy_full: 0.9304932550885008\n",
      "precision_full: [0.92808219 0.95575221 0.91891892 0.91525424 0.87591241 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.93577982 0.86055777 0.92307692 1.        ]\n",
      "2.2502379417419434\n",
      "accuracy_full: 0.9430980765437568\n",
      "precision_full: [0.95053004 0.97835498 0.92888889 0.92765957 0.88043478 1.        ]\n",
      "recall_full: [0.98175182 0.91497976 0.9587156  0.8685259  0.93461538 1.        ]\n",
      "1.9763906002044678\n",
      "accuracy_full: 0.9363404624074004\n",
      "precision_full: [0.93150685 0.96875    0.94170404 0.91489362 0.87318841 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.96330275 0.85657371 0.92692308 1.        ]\n",
      "1.93815279006958\n",
      "accuracy_full: 0.9299527448171889\n",
      "precision_full: [0.92491468 0.96428571 0.91517857 0.91101695 0.87545788 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94036697 0.85657371 0.91923077 1.        ]\n",
      "1.9533321857452393\n",
      "accuracy_full: 0.9401216034931457\n",
      "precision_full: [0.93174061 0.97272727 0.93333333 0.93562232 0.88489209 0.99630996]\n",
      "recall_full: [0.99635036 0.86639676 0.96330275 0.8685259  0.94615385 1.        ]\n",
      "1.9805121421813965\n",
      "44\n",
      "accuracy_full: 0.9361306485728643\n",
      "precision_full: [0.91333333 0.97321429 0.95852535 0.90456432 0.88432836 1.        ]\n",
      "recall_full: [1.         0.88259109 0.95412844 0.8685259  0.91153846 1.        ]\n",
      "1.9932966232299805\n",
      "accuracy_full: 0.9466595019571594\n",
      "precision_full: [0.96428571 0.97890295 0.95067265 0.9375     0.86013986 1.        ]\n",
      "recall_full: [0.98540146 0.93927126 0.97247706 0.83665339 0.94615385 1.        ]\n",
      "1.9255168437957764\n",
      "accuracy_full: 0.9347654443778728\n",
      "precision_full: [0.93661972 0.96103896 0.92857143 0.88582677 0.89883268 1.        ]\n",
      "recall_full: [0.97080292 0.89878543 0.95412844 0.89641434 0.88846154 1.        ]\n",
      "1.9441804885864258\n",
      "accuracy_full: 0.9258228949413515\n",
      "precision_full: [0.90333333 0.96475771 0.95754717 0.9047619  0.85       1.        ]\n",
      "recall_full: [0.98905109 0.88663968 0.93119266 0.83266932 0.91538462 1.        ]\n",
      "2.250239372253418\n",
      "accuracy_full: 0.9404110125203866\n",
      "precision_full: [0.91808874 0.9826087  0.93981481 0.94347826 0.87900356 1.        ]\n",
      "recall_full: [0.98175182 0.91497976 0.93119266 0.86454183 0.95       1.        ]\n",
      "1.9886364936828613\n",
      "accuracy_full: 0.9292434634319152\n",
      "precision_full: [0.92176871 0.96475771 0.93150685 0.90638298 0.86545455 1.        ]\n",
      "recall_full: [0.98905109 0.88663968 0.93577982 0.84860558 0.91538462 1.        ]\n",
      "1.984586477279663\n",
      "accuracy_full: 0.9490610335234738\n",
      "precision_full: [0.95087719 0.97402597 0.93777778 0.94827586 0.89169675 1.        ]\n",
      "recall_full: [0.98905109 0.91093117 0.96788991 0.87649402 0.95       1.        ]\n",
      "1.9689576625823975\n",
      "accuracy_full: 0.936214989978898\n",
      "precision_full: [0.93814433 0.96521739 0.9543379  0.92070485 0.85512367 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.9587156  0.83266932 0.93076923 1.        ]\n",
      "1.9625232219696045\n",
      "accuracy_full: 0.9318328069440472\n",
      "precision_full: [0.91638796 0.96475771 0.95794393 0.91025641 0.86231884 1.        ]\n",
      "recall_full: [1.         0.88663968 0.94036697 0.84860558 0.91538462 1.        ]\n",
      "1.9281611442565918\n",
      "accuracy_full: 0.9466481832294936\n",
      "precision_full: [0.94137931 0.96491228 0.94117647 0.9375     0.90740741 0.99630996]\n",
      "recall_full: [0.99635036 0.89068826 0.95412844 0.89641434 0.94230769 1.        ]\n",
      "2.006375312805176\n",
      "45\n",
      "accuracy_full: 0.9217914154732952\n",
      "precision_full: [0.93493151 0.98190045 0.93333333 0.89140271 0.81099656 1.        ]\n",
      "recall_full: [0.99635036 0.87854251 0.96330275 0.78486056 0.90769231 1.        ]\n",
      "1.9065816402435303\n",
      "accuracy_full: 0.9192110587897154\n",
      "precision_full: [0.95774648 0.97033898 0.94545455 0.87037037 0.78911565 1.        ]\n",
      "recall_full: [0.99270073 0.92712551 0.95412844 0.74900398 0.89230769 1.        ]\n",
      "2.3752520084381104\n",
      "accuracy_full: 0.9189728739885271\n",
      "precision_full: [0.94773519 0.98678414 0.94666667 0.87323944 0.78187919 1.        ]\n",
      "recall_full: [0.99270073 0.90688259 0.97706422 0.74103586 0.89615385 1.        ]\n",
      "2.078310966491699\n",
      "accuracy_full: 0.9030175081291562\n",
      "precision_full: [0.89368771 0.98148148 0.94144144 0.82352941 0.7985348  1.        ]\n",
      "recall_full: [0.98175182 0.8582996  0.9587156  0.78087649 0.83846154 1.        ]\n",
      "1.9928407669067383\n",
      "accuracy_full: 0.9146085903417761\n",
      "precision_full: [0.94366197 0.97890295 0.93607306 0.85520362 0.78892734 1.        ]\n",
      "recall_full: [0.97810219 0.93927126 0.94036697 0.75298805 0.87692308 1.        ]\n",
      "1.9710516929626465\n",
      "accuracy_full: 0.9129260363028339\n",
      "precision_full: [0.93379791 0.96521739 0.91441441 0.86784141 0.80985915 1.        ]\n",
      "recall_full: [0.97810219 0.89878543 0.93119266 0.78486056 0.88461538 1.        ]\n",
      "1.9856274127960205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9251622775042537\n",
      "precision_full: [0.94791667 0.98689956 0.94594595 0.89671362 0.79865772 1.        ]\n",
      "recall_full: [0.99635036 0.91497976 0.96330275 0.76095618 0.91538462 1.        ]\n",
      "2.035447835922241\n",
      "accuracy_full: 0.9285517790840139\n",
      "precision_full: [0.93793103 0.97379913 0.94594595 0.89380531 0.83392226 1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.96330275 0.80478088 0.90769231 1.        ]\n",
      "1.9472808837890625\n",
      "accuracy_full: 0.913468675036856\n",
      "precision_full: [0.91610738 0.97727273 0.9321267  0.87782805 0.80344828 1.        ]\n",
      "recall_full: [0.99635036 0.87044534 0.94495413 0.77290837 0.89615385 1.        ]\n",
      "1.938577651977539\n",
      "accuracy_full: 0.9183490547142493\n",
      "precision_full: [0.92517007 0.96875    0.93693694 0.88687783 0.81597222 0.99630996]\n",
      "recall_full: [0.99270073 0.87854251 0.95412844 0.78087649 0.90384615 1.        ]\n",
      "2.344001054763794\n",
      "46\n",
      "accuracy_full: 0.9381075736564458\n",
      "precision_full: [0.94097222 0.98268398 0.95022624 0.87649402 0.88416988 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96330275 0.87649402 0.88076923 1.        ]\n",
      "2.0091259479522705\n",
      "accuracy_full: 0.9342315335435245\n",
      "precision_full: [0.94137931 0.98230088 0.9375     0.93488372 0.83389831 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.96330275 0.80079681 0.94615385 1.        ]\n",
      "1.9928548336029053\n",
      "accuracy_full: 0.9324828561475731\n",
      "precision_full: [0.91891892 0.97706422 0.93777778 0.907173   0.86861314 1.        ]\n",
      "recall_full: [0.99270073 0.86234818 0.96788991 0.85657371 0.91538462 1.        ]\n",
      "2.0722551345825195\n",
      "accuracy_full: 0.9329107921608036\n",
      "precision_full: [0.91245791 0.96969697 0.94811321 0.91845494 0.8700361  1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.92201835 0.85258964 0.92692308 1.        ]\n",
      "2.176738739013672\n",
      "accuracy_full: 0.9349013454671464\n",
      "precision_full: [0.93771626 0.94957983 0.93925234 0.92241379 0.87364621 1.        ]\n",
      "recall_full: [0.98905109 0.91497976 0.92201835 0.85258964 0.93076923 1.        ]\n",
      "2.1521661281585693\n",
      "accuracy_full: 0.9390416955093869\n",
      "precision_full: [0.94117647 0.97368421 0.93721973 0.90495868 0.88432836 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.9587156  0.87250996 0.91153846 1.        ]\n",
      "2.176997423171997\n",
      "accuracy_full: 0.9377501619270422\n",
      "precision_full: [0.92881356 0.98654709 0.95454545 0.8902439  0.87969925 1.        ]\n",
      "recall_full: [1.         0.89068826 0.96330275 0.87250996 0.9        1.        ]\n",
      "2.430950880050659\n",
      "accuracy_full: 0.9269720003041991\n",
      "precision_full: [0.93402778 0.97321429 0.92105263 0.859375   0.87795276 1.        ]\n",
      "recall_full: [0.98175182 0.88259109 0.96330275 0.87649402 0.85769231 1.        ]\n",
      "2.2879815101623535\n",
      "accuracy_full: 0.9265598027039789\n",
      "precision_full: [0.90365449 0.97297297 0.93981481 0.88306452 0.878327   1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.93119266 0.87250996 0.88846154 1.        ]\n",
      "2.0225863456726074\n",
      "accuracy_full: 0.9283814120100714\n",
      "precision_full: [0.9222973  0.97685185 0.91666667 0.88306452 0.88505747 0.99630996]\n",
      "recall_full: [0.99635036 0.85425101 0.9587156  0.87250996 0.88846154 1.        ]\n",
      "2.188244581222534\n",
      "47\n",
      "accuracy_full: 0.9311863151637166\n",
      "precision_full: [0.93150685 0.97787611 0.94594595 0.89655172 0.84892086 1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.96330275 0.82868526 0.90769231 1.        ]\n",
      "2.01589298248291\n",
      "accuracy_full: 0.9329298677643432\n",
      "precision_full: [0.9347079  0.97807018 0.94545455 0.90829694 0.84751773 1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.95412844 0.82868526 0.91923077 1.        ]\n",
      "2.2033579349517822\n",
      "accuracy_full: 0.9378599992854549\n",
      "precision_full: [0.91891892 0.96475771 0.94930876 0.93913043 0.875      1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.94495413 0.86055777 0.94230769 1.        ]\n",
      "2.118840217590332\n",
      "accuracy_full: 0.9291007865989293\n",
      "precision_full: [0.93079585 0.97391304 0.94117647 0.9103139  0.83623693 1.        ]\n",
      "recall_full: [0.98175182 0.90688259 0.95412844 0.80876494 0.92307692 1.        ]\n",
      "1.9677176475524902\n",
      "accuracy_full: 0.943383296523721\n",
      "precision_full: [0.93103448 0.98245614 0.9321267  0.92916667 0.89667897 1.        ]\n",
      "recall_full: [0.98540146 0.90688259 0.94495413 0.88844622 0.93461538 1.        ]\n",
      "2.321429967880249\n",
      "accuracy_full: 0.9356649192137597\n",
      "precision_full: [0.94444444 0.98660714 0.92070485 0.91025641 0.86281588 1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.9587156  0.84860558 0.91923077 1.        ]\n",
      "2.1408536434173584\n",
      "accuracy_full: 0.9384977365585279\n",
      "precision_full: [0.9375     0.98230088 0.92920354 0.91880342 0.87318841 1.        ]\n",
      "recall_full: [0.98540146 0.89878543 0.96330275 0.85657371 0.92692308 1.        ]\n",
      "2.115640878677368\n",
      "accuracy_full: 0.9358208868500557\n",
      "precision_full: [0.94736842 0.96536797 0.93303571 0.90677966 0.86861314 1.        ]\n",
      "recall_full: [0.98540146 0.90283401 0.9587156  0.85258964 0.91538462 1.        ]\n",
      "2.0562832355499268\n",
      "accuracy_full: 0.9375251611477801\n",
      "precision_full: [0.93493151 0.96475771 0.94117647 0.90534979 0.88764045 1.        ]\n",
      "recall_full: [0.99635036 0.88663968 0.95412844 0.87649402 0.91153846 1.        ]\n",
      "2.116647958755493\n",
      "accuracy_full: 0.9321238075026722\n",
      "precision_full: [0.91891892 0.96875    0.94090909 0.907173   0.87179487 1.        ]\n",
      "recall_full: [0.99270073 0.87854251 0.94954128 0.85657371 0.91538462 1.        ]\n",
      "2.2233023643493652\n",
      "48\n",
      "accuracy_full: 0.9323319351130691\n",
      "precision_full: [0.92517007 0.97767857 0.95022624 0.92342342 0.84083045 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.96330275 0.81673307 0.93461538 1.        ]\n",
      "2.1877334117889404\n",
      "accuracy_full: 0.9367405190011918\n",
      "precision_full: [0.93771626 0.97835498 0.94520548 0.93636364 0.84536082 1.        ]\n",
      "recall_full: [0.98905109 0.91497976 0.94954128 0.82071713 0.94615385 1.        ]\n",
      "2.359626531600952\n",
      "accuracy_full: 0.9329558098798217\n",
      "precision_full: [0.92517007 0.97333333 0.94117647 0.90336134 0.86764706 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.95412844 0.85657371 0.90769231 1.        ]\n",
      "2.188676595687866\n",
      "accuracy_full: 0.9240683032807314\n",
      "precision_full: [0.91525424 0.96460177 0.92307692 0.89029536 0.86346863 1.        ]\n",
      "recall_full: [0.98540146 0.88259109 0.93577982 0.84063745 0.9        1.        ]\n",
      "2.160613536834717\n",
      "accuracy_full: 0.9401546898259713\n",
      "precision_full: [0.93127148 0.98268398 0.94930876 0.90871369 0.88148148 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.94495413 0.87250996 0.91538462 1.        ]\n",
      "2.0967495441436768\n",
      "accuracy_full: 0.9324938623981471\n",
      "precision_full: [0.92176871 0.97297297 0.91517857 0.93043478 0.87142857 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.94036697 0.85258964 0.93846154 1.        ]\n",
      "2.0114266872406006\n",
      "accuracy_full: 0.941175285472185\n",
      "precision_full: [0.94076655 0.98245614 0.93333333 0.91949153 0.87956204 1.        ]\n",
      "recall_full: [0.98540146 0.90688259 0.96330275 0.86454183 0.92692308 1.        ]\n",
      "2.015838623046875\n",
      "accuracy_full: 0.9373509238945134\n",
      "precision_full: [0.94755245 0.96969697 0.94618834 0.89915966 0.86764706 1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.96788991 0.85258964 0.90769231 1.        ]\n",
      "2.0774123668670654\n",
      "accuracy_full: 0.9340910899743656\n",
      "precision_full: [0.92176871 0.96929825 0.94495413 0.91101695 0.87226277 1.        ]\n",
      "recall_full: [0.98905109 0.89473684 0.94495413 0.85657371 0.91923077 1.        ]\n",
      "2.0783474445343018\n",
      "accuracy_full: 0.9432668456954544\n",
      "precision_full: [0.96453901 0.96638655 0.95475113 0.91025641 0.86909091 1.        ]\n",
      "recall_full: [0.99270073 0.93117409 0.96788991 0.84860558 0.91923077 1.        ]\n",
      "2.6565003395080566\n",
      "49\n",
      "accuracy_full: 0.9331783470362266\n",
      "precision_full: [0.93150685 0.96929825 0.95454545 0.89787234 0.85818182 1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.96330275 0.84063745 0.90769231 1.        ]\n",
      "2.1222383975982666\n",
      "accuracy_full: 0.9416580855497653\n",
      "precision_full: [0.95438596 0.97446809 0.95       0.92139738 0.86120996 1.        ]\n",
      "recall_full: [0.99270073 0.92712551 0.9587156  0.84063745 0.93076923 1.        ]\n",
      "1.9834623336791992\n",
      "accuracy_full: 0.9345966693393822\n",
      "precision_full: [0.9220339  0.96491228 0.94930876 0.92982456 0.86170213 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.94495413 0.84462151 0.93461538 1.        ]\n",
      "1.9822742938995361\n",
      "accuracy_full: 0.9339998492469732\n",
      "precision_full: [0.93127148 0.97816594 0.93181818 0.9137931  0.86330935 1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.94036697 0.84462151 0.92307692 1.        ]\n",
      "1.968959093093872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9378710876540906\n",
      "precision_full: [0.9209622  0.97413793 0.93518519 0.91735537 0.89219331 1.        ]\n",
      "recall_full: [0.97810219 0.91497976 0.9266055  0.88446215 0.92307692 1.        ]\n",
      "2.0212454795837402\n",
      "accuracy_full: 0.9389402404670965\n",
      "precision_full: [0.94444444 0.96137339 0.92694064 0.93506494 0.8781362  1.        ]\n",
      "recall_full: [0.99270073 0.90688259 0.93119266 0.86055777 0.94230769 1.        ]\n",
      "2.019463300704956\n",
      "accuracy_full: 0.9397286911167012\n",
      "precision_full: [0.93793103 0.98230088 0.93721973 0.90204082 0.88721805 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.9587156  0.88047809 0.90769231 1.        ]\n",
      "2.0825462341308594\n",
      "accuracy_full: 0.9358873781766316\n",
      "precision_full: [0.94385965 0.96551724 0.93721973 0.90677966 0.86861314 1.        ]\n",
      "recall_full: [0.98175182 0.90688259 0.9587156  0.85258964 0.91538462 1.        ]\n",
      "2.262047290802002\n",
      "accuracy_full: 0.9316942799580578\n",
      "precision_full: [0.93771626 0.96069869 0.93273543 0.89873418 0.86764706 1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.95412844 0.84860558 0.90769231 1.        ]\n",
      "1.9883551597595215\n",
      "accuracy_full: 0.9345609136879917\n",
      "precision_full: [0.95438596 0.96929825 0.92139738 0.90517241 0.86231884 1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.96788991 0.83665339 0.91538462 1.        ]\n",
      "2.017634391784668\n",
      "50\n",
      "accuracy_full: 0.9290610167488143\n",
      "precision_full: [0.92150171 0.96832579 0.92477876 0.90987124 0.86281588 1.        ]\n",
      "recall_full: [0.98540146 0.86639676 0.9587156  0.84462151 0.91923077 1.        ]\n",
      "1.993901252746582\n",
      "accuracy_full: 0.9383297428432839\n",
      "precision_full: [0.94791667 0.97844828 0.9543379  0.90909091 0.85357143 1.        ]\n",
      "recall_full: [0.99635036 0.91902834 0.9587156  0.83665339 0.91923077 1.        ]\n",
      "2.035888671875\n",
      "accuracy_full: 0.9340016938204426\n",
      "precision_full: [0.91275168 0.97247706 0.92857143 0.93886463 0.87188612 1.        ]\n",
      "recall_full: [0.99270073 0.8582996  0.95412844 0.85657371 0.94230769 1.        ]\n",
      "1.9845871925354004\n",
      "accuracy_full: 0.937744009157246\n",
      "precision_full: [0.92491468 0.97413793 0.94444444 0.94170404 0.86363636 1.        ]\n",
      "recall_full: [0.98905109 0.91497976 0.93577982 0.83665339 0.95       1.        ]\n",
      "2.0175530910491943\n",
      "accuracy_full: 0.9469260924966836\n",
      "precision_full: [0.94755245 0.97890295 0.95833333 0.91358025 0.89179104 1.        ]\n",
      "recall_full: [0.98905109 0.93927126 0.94954128 0.88446215 0.91923077 1.        ]\n",
      "2.284576892852783\n",
      "accuracy_full: 0.9307688590821636\n",
      "precision_full: [0.93127148 0.98214286 0.92410714 0.92376682 0.84375    1.        ]\n",
      "recall_full: [0.98905109 0.89068826 0.94954128 0.82071713 0.93461538 1.        ]\n",
      "2.0563368797302246\n",
      "accuracy_full: 0.9395152209446458\n",
      "precision_full: [0.93835616 0.97816594 0.94977169 0.90416667 0.87777778 1.        ]\n",
      "recall_full: [1.         0.90688259 0.95412844 0.86454183 0.91153846 1.        ]\n",
      "1.9788315296173096\n",
      "accuracy_full: 0.9369393801153646\n",
      "precision_full: [0.93174061 0.97797357 0.94977169 0.89711934 0.87686567 1.        ]\n",
      "recall_full: [0.99635036 0.89878543 0.95412844 0.8685259  0.90384615 1.        ]\n",
      "2.0004348754882812\n",
      "accuracy_full: 0.9346448170770233\n",
      "precision_full: [0.9220339  0.98222222 0.93607306 0.90456432 0.87777778 1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.94036697 0.8685259  0.91153846 1.        ]\n",
      "1.9845857620239258\n",
      "accuracy_full: 0.9313220472912306\n",
      "precision_full: [0.94117647 0.97777778 0.93777778 0.88607595 0.8540146  1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.96788991 0.83665339 0.9        1.        ]\n",
      "2.0703678131103516\n",
      "51\n",
      "accuracy_full: 0.9338976824248039\n",
      "precision_full: [0.9220339  0.98630137 0.94222222 0.91341991 0.85714286 1.        ]\n",
      "recall_full: [0.99270073 0.87449393 0.97247706 0.84063745 0.92307692 1.        ]\n",
      "2.1552796363830566\n",
      "accuracy_full: 0.9358786404656364\n",
      "precision_full: [0.94444444 0.97021277 0.94883721 0.91341991 0.85409253 1.        ]\n",
      "recall_full: [0.99270073 0.92307692 0.93577982 0.84063745 0.92307692 1.        ]\n",
      "2.026763677597046\n",
      "accuracy_full: 0.9417290125748425\n",
      "precision_full: [0.92808219 0.98245614 0.95       0.91666667 0.88518519 1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.9587156  0.87649402 0.91923077 1.        ]\n",
      "2.3105602264404297\n",
      "accuracy_full: 0.929545754130355\n",
      "precision_full: [0.92517007 0.96982759 0.93488372 0.9159292  0.85159011 1.        ]\n",
      "recall_full: [0.99270073 0.91093117 0.92201835 0.8247012  0.92692308 1.        ]\n",
      "2.031466484069824\n",
      "accuracy_full: 0.9484446771274676\n",
      "precision_full: [0.95104895 0.97863248 0.95454545 0.91735537 0.89552239 1.        ]\n",
      "recall_full: [0.99270073 0.92712551 0.96330275 0.88446215 0.92307692 1.        ]\n",
      "1.9788475036621094\n",
      "accuracy_full: 0.9411878484824592\n",
      "precision_full: [0.94117647 0.97391304 0.9321267  0.94273128 0.87279152 1.        ]\n",
      "recall_full: [0.99270073 0.90688259 0.94495413 0.85258964 0.95       1.        ]\n",
      "2.031716823577881\n",
      "accuracy_full: 0.9403522718858518\n",
      "precision_full: [0.95053004 0.97844828 0.92444444 0.92640693 0.87096774 1.        ]\n",
      "recall_full: [0.98175182 0.91902834 0.95412844 0.85258964 0.93461538 1.        ]\n",
      "2.0627171993255615\n",
      "accuracy_full: 0.9435751308143602\n",
      "precision_full: [0.93814433 0.97777778 0.94170404 0.92827004 0.88686131 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.96330275 0.87649402 0.93461538 1.        ]\n",
      "2.0019214153289795\n",
      "accuracy_full: 0.9366116861950365\n",
      "precision_full: [0.92832765 0.969163   0.94063927 0.92307692 0.87364621 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.94495413 0.86055777 0.93076923 1.        ]\n",
      "1.941147804260254\n",
      "accuracy_full: 0.9378856082030508\n",
      "precision_full: [0.95454545 0.97356828 0.92920354 0.88446215 0.89189189 0.99630996]\n",
      "recall_full: [0.99635036 0.89473684 0.96330275 0.88446215 0.88846154 1.        ]\n",
      "2.035278558731079\n",
      "52\n",
      "accuracy_full: 0.9298466358059952\n",
      "precision_full: [0.90333333 0.98139535 0.94222222 0.92444444 0.85263158 1.        ]\n",
      "recall_full: [0.98905109 0.85425101 0.97247706 0.82868526 0.93461538 1.        ]\n",
      "2.2569987773895264\n",
      "accuracy_full: 0.9342635073174851\n",
      "precision_full: [0.94773519 0.97844828 0.9543379  0.92990654 0.82214765 1.        ]\n",
      "recall_full: [0.99270073 0.91902834 0.9587156  0.79282869 0.94230769 1.        ]\n",
      "2.0068607330322266\n",
      "accuracy_full: 0.9354016190044527\n",
      "precision_full: [0.9540636  0.98290598 0.94594595 0.89270386 0.84532374 1.        ]\n",
      "recall_full: [0.98540146 0.93117409 0.96330275 0.82868526 0.90384615 1.        ]\n",
      "2.000394105911255\n",
      "accuracy_full: 0.915044443542475\n",
      "precision_full: [0.91554054 0.96832579 0.90178571 0.90045249 0.82638889 1.        ]\n",
      "recall_full: [0.98905109 0.86639676 0.9266055  0.79282869 0.91538462 1.        ]\n",
      "1.9845850467681885\n",
      "accuracy_full: 0.940152226203114\n",
      "precision_full: [0.93103448 0.97021277 0.95813953 0.91914894 0.87636364 1.        ]\n",
      "recall_full: [0.98540146 0.92307692 0.94495413 0.86055777 0.92692308 1.        ]\n",
      "1.942385196685791\n",
      "accuracy_full: 0.9400307761194332\n",
      "precision_full: [0.93150685 0.97797357 0.94090909 0.92735043 0.87725632 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.94954128 0.86454183 0.93461538 1.        ]\n",
      "1.9533321857452393\n",
      "accuracy_full: 0.9334804320389586\n",
      "precision_full: [0.94444444 0.98222222 0.92035398 0.92410714 0.8466899  1.        ]\n",
      "recall_full: [0.99270073 0.89473684 0.95412844 0.8247012  0.93461538 1.        ]\n",
      "2.0655956268310547\n",
      "accuracy_full: 0.9443476605423703\n",
      "precision_full: [0.95422535 0.96969697 0.9375     0.93534483 0.8781362  1.        ]\n",
      "recall_full: [0.98905109 0.90688259 0.96330275 0.86454183 0.94230769 1.        ]\n",
      "1.9102942943572998\n",
      "accuracy_full: 0.9433417602936696\n",
      "precision_full: [0.94137931 0.96566524 0.94930876 0.91056911 0.90151515 1.        ]\n",
      "recall_full: [0.99635036 0.91093117 0.94495413 0.89243028 0.91538462 1.        ]\n",
      "2.319667339324951\n",
      "accuracy_full: 0.940233571276533\n",
      "precision_full: [0.93814433 0.97321429 0.9375     0.92340426 0.88043478 1.        ]\n",
      "recall_full: [0.99635036 0.88259109 0.96330275 0.86454183 0.93461538 1.        ]\n",
      "2.156522274017334\n",
      "53\n",
      "accuracy_full: 0.924614258970557\n",
      "precision_full: [0.90939597 0.98148148 0.9380531  0.90990991 0.83333333 1.        ]\n",
      "recall_full: [0.98905109 0.8582996  0.97247706 0.80478088 0.92307692 1.        ]\n",
      "2.08659029006958\n",
      "accuracy_full: 0.9430978688857848\n",
      "precision_full: [0.94425087 0.97844828 0.95890411 0.92640693 0.86476868 1.        ]\n",
      "recall_full: [0.98905109 0.91902834 0.96330275 0.85258964 0.93461538 1.        ]\n",
      "2.009897470474243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9289345592636217\n",
      "precision_full: [0.93425606 0.97321429 0.92035398 0.92376682 0.84027778 1.        ]\n",
      "recall_full: [0.98540146 0.88259109 0.95412844 0.82071713 0.93076923 1.        ]\n",
      "1.9845857620239258\n",
      "accuracy_full: 0.9151929009541218\n",
      "precision_full: [0.89108911 0.97663551 0.91441441 0.89565217 0.83985765 1.        ]\n",
      "recall_full: [0.98540146 0.84615385 0.93119266 0.82071713 0.90769231 1.        ]\n",
      "1.9927940368652344\n",
      "accuracy_full: 0.9405347185689527\n",
      "precision_full: [0.9375     0.96666667 0.95305164 0.92672414 0.87364621 1.        ]\n",
      "recall_full: [0.98540146 0.93927126 0.93119266 0.85657371 0.93076923 1.        ]\n",
      "2.0412206649780273\n",
      "accuracy_full: 0.9244824362226479\n",
      "precision_full: [0.9375     0.95964126 0.89082969 0.92410714 0.84965035 1.        ]\n",
      "recall_full: [0.98540146 0.86639676 0.93577982 0.8247012  0.93461538 1.        ]\n",
      "2.177722930908203\n",
      "accuracy_full: 0.9321682989027936\n",
      "precision_full: [0.9220339  0.98206278 0.93243243 0.90295359 0.86813187 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.94954128 0.85258964 0.91153846 1.        ]\n",
      "2.093970775604248\n",
      "accuracy_full: 0.932626511853416\n",
      "precision_full: [0.94405594 0.96969697 0.93721973 0.89121339 0.8597786  1.        ]\n",
      "recall_full: [0.98540146 0.90688259 0.9587156  0.84860558 0.89615385 1.        ]\n",
      "1.9670917987823486\n",
      "accuracy_full: 0.9337420479863906\n",
      "precision_full: [0.94463668 0.97008547 0.95852535 0.88284519 0.85608856 1.        ]\n",
      "recall_full: [0.99635036 0.91902834 0.95412844 0.84063745 0.89230769 1.        ]\n",
      "1.9576232433319092\n",
      "accuracy_full: 0.9304240470969822\n",
      "precision_full: [0.93150685 0.96832579 0.93333333 0.89873418 0.86181818 1.        ]\n",
      "recall_full: [0.99270073 0.86639676 0.96330275 0.84860558 0.91153846 1.        ]\n",
      "2.0470924377441406\n",
      "54\n",
      "accuracy_full: 0.9250904556866452\n",
      "precision_full: [0.9220339  0.96363636 0.9375     0.9        0.84341637 1.        ]\n",
      "recall_full: [0.99270073 0.8582996  0.96330275 0.8247012  0.91153846 1.        ]\n",
      "1.9761533737182617\n",
      "accuracy_full: 0.9347324014668962\n",
      "precision_full: [0.91275168 0.96902655 0.95391705 0.92241379 0.8700361  1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.94954128 0.85258964 0.92692308 1.        ]\n",
      "2.0670855045318604\n",
      "accuracy_full: 0.9410840447447925\n",
      "precision_full: [0.9375     0.97008547 0.9543379  0.92640693 0.8705036  1.        ]\n",
      "recall_full: [0.98540146 0.91902834 0.9587156  0.85258964 0.93076923 1.        ]\n",
      "2.025644063949585\n",
      "accuracy_full: 0.9289268906896425\n",
      "precision_full: [0.90847458 0.96069869 0.94470046 0.89626556 0.87686567 1.        ]\n",
      "recall_full: [0.97810219 0.89068826 0.94036697 0.86055777 0.90384615 1.        ]\n",
      "2.290567398071289\n",
      "accuracy_full: 0.9320343331552162\n",
      "precision_full: [0.91216216 0.96759259 0.90789474 0.92827004 0.89010989 1.        ]\n",
      "recall_full: [0.98540146 0.84615385 0.94954128 0.87649402 0.93461538 1.        ]\n",
      "2.0535264015197754\n",
      "accuracy_full: 0.9431581208959064\n",
      "precision_full: [0.92857143 0.969163   0.96363636 0.92016807 0.88929889 1.        ]\n",
      "recall_full: [0.99635036 0.89068826 0.97247706 0.87250996 0.92692308 1.        ]\n",
      "2.0263476371765137\n",
      "accuracy_full: 0.9399971982393946\n",
      "precision_full: [0.9347079  0.97816594 0.95909091 0.89387755 0.88301887 1.        ]\n",
      "recall_full: [0.99270073 0.90688259 0.96788991 0.87250996 0.9        1.        ]\n",
      "1.9533336162567139\n",
      "accuracy_full: 0.9409058714863344\n",
      "precision_full: [0.94117647 0.97345133 0.94170404 0.93859649 0.86619718 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.96330275 0.85258964 0.94615385 1.        ]\n",
      "2.09397292137146\n",
      "accuracy_full: 0.9265205983730409\n",
      "precision_full: [0.92150171 0.95594714 0.94117647 0.88429752 0.86516854 1.        ]\n",
      "recall_full: [0.98540146 0.87854251 0.95412844 0.85258964 0.88846154 1.        ]\n",
      "2.0536839962005615\n",
      "accuracy_full: 0.9350234802190541\n",
      "precision_full: [0.93174061 0.97297297 0.93362832 0.92139738 0.86428571 1.        ]\n",
      "recall_full: [0.99635036 0.87449393 0.96788991 0.84063745 0.93076923 1.        ]\n",
      "2.039346933364868\n",
      "55\n",
      "accuracy_full: 0.9255602465908518\n",
      "precision_full: [0.93771626 0.95154185 0.92857143 0.91441441 0.83680556 1.        ]\n",
      "recall_full: [0.98905109 0.87449393 0.95412844 0.80876494 0.92692308 1.        ]\n",
      "1.9689624309539795\n",
      "accuracy_full: 0.9287122278029248\n",
      "precision_full: [0.95422535 0.95689655 0.91517857 0.90434783 0.85       1.        ]\n",
      "recall_full: [0.98905109 0.89878543 0.94036697 0.82868526 0.91538462 1.        ]\n",
      "2.301603078842163\n",
      "accuracy_full: 0.9368686607482594\n",
      "precision_full: [0.94444444 0.97835498 0.93665158 0.90638298 0.86545455 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.94954128 0.84860558 0.91538462 1.        ]\n",
      "2.0691490173339844\n",
      "accuracy_full: 0.9403105299600925\n",
      "precision_full: [0.94097222 0.97797357 0.92888889 0.92340426 0.88       1.        ]\n",
      "recall_full: [0.98905109 0.89878543 0.9587156  0.86454183 0.93076923 1.        ]\n",
      "2.0002119541168213\n",
      "accuracy_full: 0.9320445928542277\n",
      "precision_full: [0.91245791 0.95945946 0.93243243 0.92307692 0.88       1.        ]\n",
      "recall_full: [0.98905109 0.86234818 0.94954128 0.86055777 0.93076923 1.        ]\n",
      "2.0084712505340576\n",
      "accuracy_full: 0.9363643976755509\n",
      "precision_full: [0.92567568 0.97033898 0.97129187 0.90948276 0.86281588 1.        ]\n",
      "recall_full: [1.         0.92712551 0.93119266 0.84063745 0.91923077 1.        ]\n",
      "2.016150951385498\n",
      "accuracy_full: 0.9412887772058528\n",
      "precision_full: [0.94755245 0.97446809 0.93607306 0.92672414 0.87410072 1.        ]\n",
      "recall_full: [0.98905109 0.92712551 0.94036697 0.85657371 0.93461538 1.        ]\n",
      "2.079085111618042\n",
      "accuracy_full: 0.9443667033364903\n",
      "precision_full: [0.95744681 0.97008547 0.94170404 0.94642857 0.8641115  1.        ]\n",
      "recall_full: [0.98540146 0.91902834 0.96330275 0.84462151 0.95384615 1.        ]\n",
      "2.1559019088745117\n",
      "accuracy_full: 0.9368501114636166\n",
      "precision_full: [0.93793103 0.96491228 0.93665158 0.90204082 0.88721805 1.        ]\n",
      "recall_full: [0.99270073 0.89068826 0.94954128 0.88047809 0.90769231 1.        ]\n",
      "2.225595474243164\n",
      "accuracy_full: 0.9399297218561289\n",
      "precision_full: [0.95104895 0.96943231 0.92951542 0.90495868 0.88721805 1.        ]\n",
      "recall_full: [0.99270073 0.89878543 0.96788991 0.87250996 0.90769231 1.        ]\n",
      "2.436509609222412\n",
      "56\n",
      "accuracy_full: 0.9277535148984971\n",
      "precision_full: [0.92517007 0.98230088 0.95       0.89777778 0.83450704 0.99630996]\n",
      "recall_full: [0.99270073 0.89878543 0.9587156  0.80478088 0.91153846 1.        ]\n",
      "2.0783448219299316\n",
      "accuracy_full: 0.9309241255510102\n",
      "precision_full: [0.9347079  0.98689956 0.94117647 0.91324201 0.83103448 1.        ]\n",
      "recall_full: [0.99270073 0.91497976 0.95412844 0.79681275 0.92692308 1.        ]\n",
      "2.0878357887268066\n",
      "accuracy_full: 0.9330626427595227\n",
      "precision_full: [0.94444444 0.98689956 0.94144144 0.90666667 0.83859649 0.99630996]\n",
      "recall_full: [0.99270073 0.91497976 0.9587156  0.812749   0.91923077 1.        ]\n",
      "2.261971950531006\n",
      "accuracy_full: 0.922080365762743\n",
      "precision_full: [0.91496599 0.98660714 0.94594595 0.88789238 0.81881533 1.        ]\n",
      "recall_full: [0.98175182 0.89473684 0.96330275 0.78884462 0.90384615 1.        ]\n",
      "2.187732458114624\n",
      "accuracy_full: 0.9290262915382269\n",
      "precision_full: [0.9220339  0.98648649 0.93721973 0.90350877 0.84397163 1.        ]\n",
      "recall_full: [0.99270073 0.88663968 0.9587156  0.82071713 0.91538462 1.        ]\n",
      "2.0958211421966553\n",
      "accuracy_full: 0.9237256589585408\n",
      "precision_full: [0.9347079  0.97379913 0.94545455 0.88392857 0.82167832 1.        ]\n",
      "recall_full: [0.99270073 0.90283401 0.95412844 0.78884462 0.90384615 1.        ]\n",
      "2.2578225135803223\n",
      "accuracy_full: 0.9350649362933083\n",
      "precision_full: [0.94736842 0.98237885 0.91666667 0.92070485 0.85512367 1.        ]\n",
      "recall_full: [0.98540146 0.90283401 0.9587156  0.83266932 0.93076923 1.        ]\n",
      "2.6133270263671875\n",
      "accuracy_full: 0.9306897245895162\n",
      "precision_full: [0.9540636  0.96186441 0.94570136 0.88135593 0.84671533 1.        ]\n",
      "recall_full: [0.98540146 0.91902834 0.9587156  0.82868526 0.89230769 1.        ]\n",
      "2.3283767700195312\n",
      "accuracy_full: 0.932488680148083\n",
      "precision_full: [0.93493151 0.98237885 0.95475113 0.90990991 0.83333333 1.        ]\n",
      "recall_full: [0.99635036 0.90283401 0.96788991 0.80478088 0.92307692 1.        ]\n",
      "2.303868532180786\n",
      "accuracy_full: 0.9352354698626781\n",
      "precision_full: [0.93835616 0.98237885 0.95927602 0.90350877 0.84697509 0.99630996]\n",
      "recall_full: [1.         0.90283401 0.97247706 0.82071713 0.91538462 1.        ]\n",
      "2.405095338821411\n",
      "57\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 57 is out of bounds for axis 0 with size 57",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-a73a98cc2d2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m561\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mx_train_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mx_valid_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_valid_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgridXG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3957\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3958\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 57 is out of bounds for axis 0 with size 57"
     ]
    }
   ],
   "source": [
    "# # First Iteration\n",
    "# select_columns = np.r_[0:561]\n",
    "# # Second Iteration\n",
    "# select_columns = np.r_[0:19,20:28,29:39,40,42:50,55:60,61:94,95:108,113,114,120,123,124,126,131:137,140,141,143:150,151:154,156,157,159:163,165:168,170,172:177,182:186,187:195,196:204,210,213,215:221,224,245,246,248,249,255,263,271,282,300,301,318,319,321,322,325,330,331,333,342,344,347,348,350,354:357,369,372:375,388:392,398:406,407,408,410,413,417:422,426,427,429:444,447,448,450,452:458,459:467,468:473,474:513,514:527,529:533,534,535,538:561]\n",
    "# # Third Iteration\n",
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "# # Fifth Iteration\n",
    "select_columns = select_columns[np.r_[0,1,3:10,11:14,15,16,18,19,23,24,26,28:31,32,34:46,48,51,53:59,62:66,67,69:72,75:78,82,86,107]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "import xgboost\n",
    "gridXG = ParameterGrid({\"n_estimators\": [10],\n",
    "                        \"learning_rate\": [.8],\n",
    "                        \"max_depth\": [4],\n",
    "                        \"booster\": [\"dart\"], #\"gbtree\", \"gblinear\"\n",
    "                        \"subsample\": [.6],\n",
    "                        \"colsample_bytree\": [.8],\n",
    "                        \"colsample_bylevel\": [1],\n",
    "                        \"n_jobs\": [4],\n",
    "                        \"gamma\": [0],\n",
    "                        \"min_child_weight\": [.4],\n",
    "                        \"max_delta_step\": [4],\n",
    "                        \"colsample_bynode\": [.9],\n",
    "                        \"reg_alpha\": [.1],\n",
    "                        \"random_state\": [5,15,35,55,71,88,104,112,128,161]\n",
    "                       })\n",
    "nums = []\n",
    "for i in range(0,561):\n",
    "    print(i)\n",
    "    x_train_sub = x_train_temp.drop(x_train_temp.columns[i], axis=1)\n",
    "    x_valid_sub = x_valid_temp.drop(x_valid_temp.columns[i], axis=1)\n",
    "    for j, params in enumerate(gridXG):\n",
    "        start = time.time()\n",
    "        model = xgboost.XGBClassifier(**params)\n",
    "        model.fit(x_train_sub, y_train)\n",
    "        score = model.predict(x_valid_sub)\n",
    "        cm = confusion_matrix(y_valid, score)\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(y_valid, score)\n",
    "        print('precision_full: {}'.format(precision))\n",
    "        print('recall_full: {}'.format(recall))\n",
    "        end = time.time()\n",
    "        print(end-start)\n",
    "        if sum(cm.diagonal())/6<.935:\n",
    "            nums.append(str(i)+\" - \"+str(j))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results and parameters on validation XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9681184312015887\n",
      "precision_full: [0.97857143 0.99585062 0.98173516 0.93469388 0.92075472 1.        ]\n",
      "recall_full: [1.         0.97165992 0.98623853 0.9123506  0.93846154 1.        ]\n",
      "0 {'booster': 'dart', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 4, 'max_depth': 5, 'min_child_weight': 0.1, 'n_estimators': 120, 'n_jobs': 4, 'random_state': 1, 'reg_alpha': 0, 'subsample': 0.2}\n",
      "34.20910310745239\n"
     ]
    }
   ],
   "source": [
    "# # First Iteration\n",
    "# select_columns = np.r_[0:561]\n",
    "# # Second Iteration\n",
    "# select_columns = np.r_[0:19,20:28,29:39,40,42:50,55:60,61:94,95:108,113,114,120,123,124,126,131:137,140,141,143:150,151:154,156,157,159:163,165:168,170,172:177,182:186,187:195,196:204,210,213,215:221,224,245,246,248,249,255,263,271,282,300,301,318,319,321,322,325,330,331,333,342,344,347,348,350,354:357,369,372:375,388:392,398:406,407,408,410,413,417:422,426,427,429:444,447,448,450,452:458,459:467,468:473,474:513,514:527,529:533,534,535,538:561]\n",
    "# # Third Iteration\n",
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "# # Fifth Iteration\n",
    "# select_columns = select_columns[np.r_[0,1,3:10,11:14,15,16,18,19,23,24,26,28:31,32,34:46,48,51,53:59,62:66,67,69:72,75:78,82,86,107]]\n",
    "# # # Sixth Iteration\n",
    "# select_columns = select_columns[np.r_[3,4,6,8:14,18:21,23:26,28,30,34,36,40,41,45,46,48:51,53,54,56]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "import xgboost\n",
    "gridXG = ParameterGrid({\"n_estimators\": [120],\n",
    "                        \"learning_rate\": [.1],\n",
    "                        \"max_depth\": [5],\n",
    "                        \"booster\": [\"dart\"], #\"gbtree\", \"gblinear\"\n",
    "                        \"subsample\": [.2],\n",
    "                        \"colsample_bytree\": [1],\n",
    "                        \"colsample_bylevel\": [1],\n",
    "                        \"n_jobs\": [4],\n",
    "                        \"gamma\": [0],\n",
    "                        \"min_child_weight\": [.1],\n",
    "                        \"max_delta_step\": [4],\n",
    "                        \"colsample_bynode\": [1],\n",
    "                        \"reg_alpha\": [0], \n",
    "                        \"random_state\": [1]\n",
    "                       })\n",
    "\n",
    "for i, params in enumerate(gridXG):\n",
    "    start = time.time()\n",
    "    model = xgboost.XGBClassifier(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_valid_temp)\n",
    "    cm = confusion_matrix(y_valid, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_valid, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(i, params)\n",
    "    print(end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = []\n",
    "seed = []\n",
    "for i in nums:\n",
    "    iteration.append(int(i.split(\" - \")[0]))\n",
    "    seed.append(int(i.split(\" - \")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9449378105537104\n",
      "accuracy_full: [0.95495495 1.         0.84653465 0.87916667 0.98897059 1.        ]\n",
      "precision_full: [0.96803653 0.88844622 0.96610169 0.98598131 0.90268456 1.        ]\n",
      "recall_full: [0.95495495 1.         0.84653465 0.87916667 0.98897059 1.        ]\n",
      "40.81721758842468\n",
      "accuracy_full: 0.9516543437828359\n",
      "accuracy_full: [0.97297297 1.         0.87623762 0.87916667 0.98529412 0.99625468]\n",
      "precision_full: [0.96860987 0.91393443 0.98333333 0.97685185 0.9023569  1.        ]\n",
      "recall_full: [0.97297297 1.         0.87623762 0.87916667 0.98529412 0.99625468]\n",
      "41.113261461257935\n",
      "accuracy_full: 0.9447342539201135\n",
      "accuracy_full: [0.97747748 1.         0.83168317 0.86666667 0.99632353 0.99625468]\n",
      "precision_full: [0.96875    0.88492063 0.98245614 0.99047619 0.89438944 1.        ]\n",
      "recall_full: [0.97747748 1.         0.83168317 0.86666667 0.99632353 0.99625468]\n",
      "40.79485726356506\n",
      "accuracy_full: 0.9503482801478554\n",
      "accuracy_full: [0.96846847 1.         0.86138614 0.88333333 0.99264706 0.99625468]\n",
      "precision_full: [0.96846847 0.90283401 0.97752809 0.98604651 0.90604027 1.        ]\n",
      "recall_full: [0.96846847 1.         0.86138614 0.88333333 0.99264706 0.99625468]\n",
      "40.62299704551697\n",
      "accuracy_full: 0.9453945245478442\n",
      "accuracy_full: [0.95945946 1.         0.84158416 0.875      0.99632353 1.        ]\n",
      "precision_full: [0.96818182 0.88492063 0.97142857 0.99526066 0.90033223 1.        ]\n",
      "recall_full: [0.95945946 1.         0.84158416 0.875      0.99632353 1.        ]\n",
      "41.56311893463135\n",
      "accuracy_full: 0.9489115784490686\n",
      "accuracy_full: [0.96396396 1.         0.84158416 0.89166667 1.         0.99625468]\n",
      "precision_full: [0.96832579 0.892      0.96590909 0.99534884 0.91275168 1.        ]\n",
      "recall_full: [0.96396396 1.         0.84158416 0.89166667 1.         0.99625468]\n",
      "39.45252466201782\n",
      "accuracy_full: 0.9485005128989524\n",
      "accuracy_full: [0.97747748 1.         0.83663366 0.89166667 0.98897059 0.99625468]\n",
      "precision_full: [0.96875    0.88844622 0.98255814 0.98165138 0.91186441 1.        ]\n",
      "recall_full: [0.97747748 1.         0.83663366 0.89166667 0.98897059 0.99625468]\n",
      "40.70863151550293\n",
      "accuracy_full: 0.94967922874351\n",
      "accuracy_full: [0.96396396 1.         0.86138614 0.8875     0.98897059 0.99625468]\n",
      "precision_full: [0.96832579 0.90283401 0.97206704 0.98156682 0.90878378 1.        ]\n",
      "recall_full: [0.96396396 1.         0.86138614 0.8875     0.98897059 0.99625468]\n",
      "39.731826305389404\n",
      "accuracy_full: 0.9454762238942495\n",
      "accuracy_full: [0.95945946 1.         0.84158416 0.87916667 0.99264706 1.        ]\n",
      "precision_full: [0.96818182 0.88844622 0.96590909 0.99061033 0.90301003 1.        ]\n",
      "recall_full: [0.95945946 1.         0.84158416 0.87916667 0.99264706 1.        ]\n",
      "40.053995847702026\n",
      "accuracy_full: 0.9459148171274676\n",
      "accuracy_full: [0.95495495 1.         0.85148515 0.8875     0.98529412 0.99625468]\n",
      "precision_full: [0.97695853 0.88142292 0.97175141 0.97706422 0.90847458 1.        ]\n",
      "recall_full: [0.95495495 1.         0.85148515 0.8875     0.98529412 0.99625468]\n",
      "39.24730396270752\n"
     ]
    }
   ],
   "source": [
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "import xgboost\n",
    "gridXG = ParameterGrid({\"n_estimators\": [120],\n",
    "                        \"learning_rate\": [.1],\n",
    "                        \"max_depth\": [5],\n",
    "                        \"booster\": [\"dart\"], #\"gbtree\", \"gblinear\"\n",
    "                        \"subsample\": [.2],\n",
    "                        \"colsample_bytree\": [1],\n",
    "                        \"colsample_bylevel\": [1],\n",
    "                        \"n_jobs\": [4],\n",
    "                        \"gamma\": [0],\n",
    "                        \"min_child_weight\": [.1],\n",
    "                        \"max_delta_step\": [4],\n",
    "                        \"colsample_bynode\": [1],\n",
    "                        \"reg_alpha\": [0], \n",
    "                        \"random_state\": [210,220,230,240,250,260,270,280,290,300]\n",
    "                       })\n",
    "\n",
    "for params in gridXG:\n",
    "    start = time.time()\n",
    "    model = xgboost.XGBClassifier(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_test_temp)\n",
    "    cm = confusion_matrix(y_test, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    print(\"accuracy_full: {}\".format(cm.diagonal()))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results and parameters on validation Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.691961569679297\n",
      "precision_full: [0.93714286 0.85820896 0.49767442 0.62886598 0.55188679 1.        ]\n",
      "recall_full: [0.59854015 0.46558704 0.98165138 0.24302789 0.9        0.96296296]\n",
      "0 {'learning_rate': 0.8, 'n_estimators': 160}\n",
      "20.19591760635376\n"
     ]
    }
   ],
   "source": [
    "# # First Iteration\n",
    "# select_columns = np.r_[0:561]\n",
    "# # Second Iteration\n",
    "# select_columns = np.r_[0:19,20:28,29:39,40,42:50,55:60,61:94,95:108,113,114,120,123,124,126,131:137,140,141,143:150,151:154,156,157,159:163,165:168,170,172:177,182:186,187:195,196:204,210,213,215:221,224,245,246,248,249,255,263,271,282,300,301,318,319,321,322,325,330,331,333,342,344,347,348,350,354:357,369,372:375,388:392,398:406,407,408,410,413,417:422,426,427,429:444,447,448,450,452:458,459:467,468:473,474:513,514:527,529:533,534,535,538:561]\n",
    "# # Third Iteration\n",
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "# # Fifth Iteration\n",
    "# select_columns = select_columns[np.r_[0,1,3:10,11:14,15,16,18,19,23,24,26,28:31,32,34:46,48,51,53:59,62:66,67,69:72,75:78,82,86,107]]\n",
    "# # # Sixth Iteration\n",
    "# select_columns = select_columns[np.r_[3,4,6,8:14,18:21,23:26,28,30,34,36,40,41,45,46,48:51,53,54,56]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "gridAB = ParameterGrid({\"n_estimators\": [160],\n",
    "                        \"learning_rate\": [.8],\n",
    "                        })\n",
    "\n",
    "for i, params in enumerate(gridAB):\n",
    "    start = time.time()\n",
    "    model = AdaBoostClassifier(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_valid_temp)\n",
    "    cm = confusion_matrix(y_valid, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_valid, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(i, params)\n",
    "    print(end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.7083252242504541\n",
      "accuracy_full: [0.54954955 0.69058296 0.83663366 0.225      0.96691176 0.98127341]\n",
      "precision_full: [0.89051095 0.79381443 0.53481013 0.79411765 0.5857461  1.        ]\n",
      "recall_full: [0.54954955 0.69058296 0.83663366 0.225      0.96691176 0.98127341]\n",
      "21.15660047531128\n"
     ]
    }
   ],
   "source": [
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "gridAB = ParameterGrid({\"n_estimators\": [160],\n",
    "                        \"learning_rate\": [.8]\n",
    "                        })\n",
    "\n",
    "for params in gridAB:\n",
    "    start = time.time()\n",
    "    model = AdaBoostClassifier(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_test_temp)\n",
    "    cm = confusion_matrix(y_test, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    print(\"accuracy_full: {}\".format(cm.diagonal()))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results and parameters on validation Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9252209747169396\n",
      "precision_full: [0.88778878 0.99078341 0.95454545 0.91479821 0.83623693 1.        ]\n",
      "recall_full: [0.98175182 0.87044534 0.96330275 0.812749   0.92307692 1.        ]\n",
      "0 {'bootstrap': 'True', 'max_depth': 9, 'max_features': 70, 'max_leaf_nodes': 50, 'min_samples_leaf': 13, 'min_samples_split': 0.01, 'n_estimators': 120, 'n_jobs': 4}\n",
      "13.751423597335815\n"
     ]
    }
   ],
   "source": [
    "# # First Iteration\n",
    "# select_columns = np.r_[0:561]\n",
    "# # Second Iteration\n",
    "# select_columns = np.r_[0:19,20:28,29:39,40,42:50,55:60,61:94,95:108,113,114,120,123,124,126,131:137,140,141,143:150,151:154,156,157,159:163,165:168,170,172:177,182:186,187:195,196:204,210,213,215:221,224,245,246,248,249,255,263,271,282,300,301,318,319,321,322,325,330,331,333,342,344,347,348,350,354:357,369,372:375,388:392,398:406,407,408,410,413,417:422,426,427,429:444,447,448,450,452:458,459:467,468:473,474:513,514:527,529:533,534,535,538:561]\n",
    "# # Third Iteration\n",
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "# # Fifth Iteration\n",
    "# select_columns = select_columns[np.r_[0,1,3:10,11:14,15,16,18,19,23,24,26,28:31,32,34:46,48,51,53:59,62:66,67,69:72,75:78,82,86,107]]\n",
    "# # # Sixth Iteration\n",
    "# select_columns = select_columns[np.r_[3,4,6,8:14,18:21,23:26,28,30,34,36,40,41,45,46,48:51,53,54,56]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "gridRF = ParameterGrid({\"n_estimators\": [120],\n",
    "                        \"min_samples_split\": [.01],\n",
    "                        \"max_features\": [70],\n",
    "                        \"max_depth\": [9],\n",
    "                        \"min_samples_leaf\": [13],\n",
    "                        \"bootstrap\": [\"True\"],\n",
    "                        \"max_leaf_nodes\": [50],\n",
    "                        \"n_jobs\": [4],\n",
    "                        })\n",
    "\n",
    "for i, params in enumerate(gridRF):\n",
    "    start = time.time()\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_valid_temp)\n",
    "    cm = confusion_matrix(y_valid, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_valid, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(i, params)\n",
    "    print(end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9027000918580748\n",
      "accuracy_full: [0.92792793 0.96860987 0.73762376 0.80416667 0.98161765 0.99625468]\n",
      "precision_full: [0.9321267  0.79120879 0.97385621 0.96984925 0.85031847 1.        ]\n",
      "recall_full: [0.92792793 0.96860987 0.73762376 0.80416667 0.98161765 0.99625468]\n",
      "23.135361194610596\n"
     ]
    }
   ],
   "source": [
    "select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # Fourth Iteration\n",
    "select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "gridRF = ParameterGrid({\"n_estimators\": [120],\n",
    "                        \"min_samples_split\": [.01],\n",
    "                        \"max_features\": [70],\n",
    "                        \"max_depth\": [9],\n",
    "                        \"min_samples_leaf\": [13],\n",
    "                        \"bootstrap\": [\"True\"],\n",
    "                        \"max_leaf_nodes\": [50],\n",
    "                        \"n_jobs\": [4],\n",
    "                        })\n",
    "\n",
    "for params in gridRF:\n",
    "    start = time.time()\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_test_temp)\n",
    "    cm = confusion_matrix(y_test, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    print(\"accuracy_full: {}\".format(cm.diagonal()))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test results and parameters on validation SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9404100047806412\n",
      "precision_full: [0.9375     0.98275862 0.97747748 0.9468599  0.82724252 1.        ]\n",
      "recall_full: [0.98540146 0.92307692 0.99541284 0.78087649 0.95769231 1.        ]\n",
      "0 {'C': 3.5, 'degree': 6, 'gamma': 0.1, 'kernel': 'linear', 'max_iter': 1000000}\n",
      "3.3136229515075684\n"
     ]
    }
   ],
   "source": [
    "#I trained on a different file with train and validation combined.  Results in the final SVM cell appear a little inflated.\n",
    "\n",
    "# # First Iteration\n",
    "select_columns = np.r_[0:561]\n",
    "# # Second Iteration\n",
    "# select_columns = np.r_[0:19,20:28,29:39,40,42:50,55:60,61:94,95:108,113,114,120,123,124,126,131:137,140,141,143:150,151:154,156,157,159:163,165:168,170,172:177,182:186,187:195,196:204,210,213,215:221,224,245,246,248,249,255,263,271,282,300,301,318,319,321,322,325,330,331,333,342,344,347,348,350,354:357,369,372:375,388:392,398:406,407,408,410,413,417:422,426,427,429:444,447,448,450,452:458,459:467,468:473,474:513,514:527,529:533,534,535,538:561]\n",
    "# # Third Iteration\n",
    "# select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # # Fourth Iteration\n",
    "# select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "# # Fifth Iteration\n",
    "# select_columns = select_columns[np.r_[0,1,3:10,11:14,15,16,18,19,23,24,26,28:31,32,34:46,48,51,53:59,62:66,67,69:72,75:78,82,86,107]]\n",
    "# # # Sixth Iteration\n",
    "# select_columns = select_columns[np.r_[3,4,6,8:14,18:21,23:26,28,30,34,36,40,41,45,46,48:51,53,54,56]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.svm import SVC  \n",
    "gridSVC = ParameterGrid({\"kernel\": [\"linear\"], #, \"poly\", \"rbf\", \"sigmoid\"\n",
    "                         \"gamma\": [.1],\n",
    "                         \"degree\": [6],\n",
    "                         \"C\": [3.5],\n",
    "#                          \"tol\": [1],\n",
    "#                          \"random_state\": [1],\n",
    "                         \"max_iter\": [1000000]\n",
    "                       })\n",
    "\n",
    "for i, params in enumerate(gridSVC):\n",
    "    start = time.time()\n",
    "    model = SVC(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_valid_temp)\n",
    "    cm = confusion_matrix(y_valid, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_valid, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(i, params)\n",
    "    print(end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_full: 0.9878236052964304\n",
      "accuracy_full: [1.         0.9955157  0.95544554 0.98333333 0.99264706 1.        ]\n",
      "precision_full: [0.98230088 0.97368421 1.         0.99159664 0.98540146 1.        ]\n",
      "recall_full: [1.         0.9955157  0.95544554 0.98333333 0.99264706 1.        ]\n",
      "3.3277037143707275\n"
     ]
    }
   ],
   "source": [
    "select_columns = np.r_[0:561]\n",
    "# select_columns = np.r_[0,1,4,5,9,11,21,23,38,42,43,45,46,47,48,49,55,56,58,59,61,62,64,65,67,68,69,71,74,75,76,80,81,83,84,89,90,92,93,95,99,100,101,102,103,114,120,126,131,132,134,145,151,152,153,157,176,183,187,188,189,193,194,197,199,202,203,210,213,215,216,218,245,246,248,249,255,263,271,319,330,333,342,350,355,356,388,407,408,410,429,430,432,433,434,435,437,438,439,440,441,442,443,447,448,450,452,453,454,455,456,457,459,460,461,462,463,464,465,466,468,469,472,474,479,486,487,488,491,496,498,499,503,504,506,507,508,509,511,512,514,515,516,517,518,519,520,521,523,524,525,538,539,540,541,542,543,544,548,555,557,558]\n",
    "# # # Fourth Iteration\n",
    "# select_columns = select_columns[np.r_[10,11,13,14,17:22,23:28,29:35,36,37,39:47,49,50,52:56,59:65,67:74,75,79,91:94,95,99,104:109,110:120,121:137,138,140:147,148:154,155:162]]\n",
    "x_train_temp = x_train.iloc[:,select_columns]\n",
    "x_valid_temp = x_valid.iloc[:,select_columns]\n",
    "x_test_temp = x_test.iloc[:,select_columns]\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support\n",
    "from sklearn.svm import SVC  \n",
    "gridSVC = ParameterGrid({\"kernel\": [\"linear\"], #, \"poly\", \"rbf\", \"sigmoid\"\n",
    "                         \"gamma\": [.1],\n",
    "                         \"degree\": [6],\n",
    "                         \"C\": [3.5],\n",
    "#                          \"tol\": [1],\n",
    "#                          \"random_state\": [1],\n",
    "                         \"max_iter\": [1000000]\n",
    "                       })\n",
    "\n",
    "for params in gridSVC:\n",
    "    start = time.time()\n",
    "    model = SVC(**params)\n",
    "    model.fit(x_train_temp, y_train)\n",
    "    score = model.predict(x_test_temp)\n",
    "    cm = confusion_matrix(y_test, score)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(\"accuracy_full: {}\".format(sum(cm.diagonal())/6))\n",
    "    print(\"accuracy_full: {}\".format(cm.diagonal()))\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(y_test, score)\n",
    "    print('precision_full: {}'.format(precision))\n",
    "    print('recall_full: {}'.format(recall))\n",
    "    end = time.time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/test/Inertial Signals\")\n",
    "test1 = pd.read_csv(\"body_acc_x_test.txt\", \"\\s+\", header=None)\n",
    "test2 = pd.read_csv(\"body_acc_y_test.txt\", \"\\s+\", header=None)\n",
    "test3 = pd.read_csv(\"body_acc_z_test.txt\", \"\\s+\", header=None)\n",
    "test4 = pd.read_csv(\"body_gyro_x_test.txt\", \"\\s+\", header=None)\n",
    "test5 = pd.read_csv(\"body_gyro_y_test.txt\", \"\\s+\", header=None)\n",
    "test6 = pd.read_csv(\"body_gyro_z_test.txt\", \"\\s+\", header=None)\n",
    "test7 = pd.read_csv(\"total_acc_x_test.txt\", \"\\s+\", header=None)\n",
    "test8 = pd.read_csv(\"total_acc_y_test.txt\", \"\\s+\", header=None)\n",
    "test9 = pd.read_csv(\"total_acc_z_test.txt\", \"\\s+\", header=None)\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/train/Inertial Signals\")\n",
    "train1 = pd.read_csv(\"body_acc_x_train.txt\", \"\\s+\", header=None)\n",
    "train2 = pd.read_csv(\"body_acc_y_train.txt\", \"\\s+\", header=None)\n",
    "train3 = pd.read_csv(\"body_acc_z_train.txt\", \"\\s+\", header=None)\n",
    "train4 = pd.read_csv(\"body_gyro_x_train.txt\", \"\\s+\", header=None)\n",
    "train5 = pd.read_csv(\"body_gyro_y_train.txt\", \"\\s+\", header=None)\n",
    "train6 = pd.read_csv(\"body_gyro_z_train.txt\", \"\\s+\", header=None)\n",
    "train7 = pd.read_csv(\"total_acc_x_train.txt\", \"\\s+\", header=None)\n",
    "train8 = pd.read_csv(\"total_acc_y_train.txt\", \"\\s+\", header=None)\n",
    "train9 = pd.read_csv(\"total_acc_z_train.txt\", \"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create arrays in correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9)\n",
      "(2947, 128, 9)\n",
      "(7352, 1)\n",
      "(2947, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.dstack((test1,test2,test3,test4,test5,test6,test7,test8,test9))\n",
    "x_train = np.dstack((train1,train2,train3,train4,train5,train6,train7,train8,train9))\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/test\")\n",
    "y_test = pd.read_csv(\"y_test.txt\", \"\\s+\", header=None)\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/train\")\n",
    "y_train = pd.read_csv(\"y_train.txt\", \"\\s+\", header=None)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train[0]).values\n",
    "y_test = pd.get_dummies(y_test[0]).values\n",
    "x_train = x_train.reshape([7352,1152])\n",
    "x_test = x_test.reshape([2947,1152])\n",
    "print(y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import functools\n",
    "from matplotlib import pyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import BatchNormalization, Flatten, Dense, LeakyReLU, Dropout, GaussianNoise\n",
    "from tensorflow import set_random_seed\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras_gradient_noise import add_gradient_noise\n",
    "from keras.initializers import glorot_uniform, glorot_normal, he_uniform, he_normal\n",
    "set_random_seed(1724)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Dense(128, kernel_initializer=\"glorot_normal\", input_shape=(9*128,)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(.15))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(GaussianNoise(1))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a different optimizer this time\n",
    "noisy = add_gradient_noise(RMSprop)\n",
    "model.compile(optimizer=\"Adamax\",\n",
    "# model.compile(optimizer=noisy(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=16),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/250\n",
      "7352/7352 [==============================] - 4s 536us/step - loss: 0.8548 - acc: 0.6813 - val_loss: 0.6692 - val_acc: 0.7781\n",
      "Epoch 2/250\n",
      "7352/7352 [==============================] - 4s 605us/step - loss: 0.5102 - acc: 0.8243 - val_loss: 0.5082 - val_acc: 0.8344\n",
      "Epoch 3/250\n",
      "7352/7352 [==============================] - 5s 713us/step - loss: 0.4016 - acc: 0.8604 - val_loss: 0.4620 - val_acc: 0.8466\n",
      "Epoch 4/250\n",
      "7352/7352 [==============================] - 5s 618us/step - loss: 0.3395 - acc: 0.8863 - val_loss: 0.3863 - val_acc: 0.8724\n",
      "Epoch 5/250\n",
      "7352/7352 [==============================] - 4s 576us/step - loss: 0.3036 - acc: 0.8934 - val_loss: 0.4075 - val_acc: 0.8419\n",
      "Epoch 6/250\n",
      "7352/7352 [==============================] - 4s 604us/step - loss: 0.2754 - acc: 0.9030 - val_loss: 0.3268 - val_acc: 0.8935\n",
      "Epoch 7/250\n",
      "7352/7352 [==============================] - 5s 673us/step - loss: 0.2483 - acc: 0.9100 - val_loss: 0.3421 - val_acc: 0.8863\n",
      "Epoch 8/250\n",
      "7352/7352 [==============================] - 4s 589us/step - loss: 0.2337 - acc: 0.9119 - val_loss: 0.3176 - val_acc: 0.8853\n",
      "Epoch 9/250\n",
      "7352/7352 [==============================] - 4s 611us/step - loss: 0.2338 - acc: 0.9149 - val_loss: 0.3264 - val_acc: 0.8843\n",
      "Epoch 10/250\n",
      "7352/7352 [==============================] - 5s 677us/step - loss: 0.2197 - acc: 0.9189 - val_loss: 0.3283 - val_acc: 0.8935\n",
      "Epoch 11/250\n",
      "7352/7352 [==============================] - 4s 609us/step - loss: 0.2048 - acc: 0.9257 - val_loss: 0.2958 - val_acc: 0.8992\n",
      "Epoch 12/250\n",
      "7352/7352 [==============================] - 5s 630us/step - loss: 0.1931 - acc: 0.9274 - val_loss: 0.3090 - val_acc: 0.8972\n",
      "Epoch 13/250\n",
      "7352/7352 [==============================] - 5s 646us/step - loss: 0.1999 - acc: 0.9256 - val_loss: 0.3004 - val_acc: 0.8945\n",
      "Epoch 14/250\n",
      "7352/7352 [==============================] - 5s 657us/step - loss: 0.1934 - acc: 0.9267 - val_loss: 0.3095 - val_acc: 0.8887\n",
      "Epoch 15/250\n",
      "7352/7352 [==============================] - 5s 623us/step - loss: 0.1834 - acc: 0.9317 - val_loss: 0.2738 - val_acc: 0.9063\n",
      "Epoch 16/250\n",
      "7352/7352 [==============================] - 5s 620us/step - loss: 0.1837 - acc: 0.9323 - val_loss: 0.2797 - val_acc: 0.9091\n",
      "Epoch 17/250\n",
      "7352/7352 [==============================] - 5s 696us/step - loss: 0.1697 - acc: 0.9361 - val_loss: 0.3022 - val_acc: 0.8914\n",
      "Epoch 18/250\n",
      "7352/7352 [==============================] - 5s 639us/step - loss: 0.1815 - acc: 0.9348 - val_loss: 0.2782 - val_acc: 0.9033\n",
      "Epoch 19/250\n",
      "7352/7352 [==============================] - 5s 620us/step - loss: 0.1793 - acc: 0.9334 - val_loss: 0.2832 - val_acc: 0.9094\n",
      "Epoch 20/250\n",
      "7352/7352 [==============================] - 5s 699us/step - loss: 0.1692 - acc: 0.9335 - val_loss: 0.2790 - val_acc: 0.9016\n",
      "Epoch 21/250\n",
      "7352/7352 [==============================] - 5s 626us/step - loss: 0.1716 - acc: 0.9365 - val_loss: 0.2576 - val_acc: 0.9108\n",
      "Epoch 22/250\n",
      "7352/7352 [==============================] - 5s 633us/step - loss: 0.1656 - acc: 0.9359 - val_loss: 0.2704 - val_acc: 0.9033\n",
      "Epoch 23/250\n",
      "7352/7352 [==============================] - 5s 642us/step - loss: 0.1631 - acc: 0.9380 - val_loss: 0.2506 - val_acc: 0.9080\n",
      "Epoch 24/250\n",
      "7352/7352 [==============================] - 6s 749us/step - loss: 0.1595 - acc: 0.9366 - val_loss: 0.2671 - val_acc: 0.9094\n",
      "Epoch 25/250\n",
      "7352/7352 [==============================] - 5s 651us/step - loss: 0.1528 - acc: 0.9391 - val_loss: 0.2575 - val_acc: 0.9101\n",
      "Epoch 26/250\n",
      "7352/7352 [==============================] - 5s 622us/step - loss: 0.1557 - acc: 0.9372 - val_loss: 0.2762 - val_acc: 0.9016\n",
      "Epoch 27/250\n",
      "7352/7352 [==============================] - 5s 713us/step - loss: 0.1598 - acc: 0.9358 - val_loss: 0.2714 - val_acc: 0.9030\n",
      "Epoch 28/250\n",
      "7352/7352 [==============================] - 5s 638us/step - loss: 0.1588 - acc: 0.9346 - val_loss: 0.2598 - val_acc: 0.9063\n",
      "Epoch 29/250\n",
      "7352/7352 [==============================] - 5s 630us/step - loss: 0.1538 - acc: 0.9388 - val_loss: 0.2668 - val_acc: 0.8972\n",
      "Epoch 30/250\n",
      "7352/7352 [==============================] - 5s 711us/step - loss: 0.1537 - acc: 0.9406 - val_loss: 0.2577 - val_acc: 0.9067\n",
      "Epoch 31/250\n",
      "7352/7352 [==============================] - 5s 646us/step - loss: 0.1503 - acc: 0.9426 - val_loss: 0.2387 - val_acc: 0.9057\n",
      "Epoch 32/250\n",
      "7352/7352 [==============================] - 5s 628us/step - loss: 0.1505 - acc: 0.9391 - val_loss: 0.2549 - val_acc: 0.9101\n",
      "Epoch 33/250\n",
      "7352/7352 [==============================] - 5s 703us/step - loss: 0.1499 - acc: 0.9399 - val_loss: 0.2541 - val_acc: 0.9169\n",
      "Epoch 34/250\n",
      "7352/7352 [==============================] - 5s 682us/step - loss: 0.1567 - acc: 0.9387 - val_loss: 0.2469 - val_acc: 0.9063\n",
      "Epoch 35/250\n",
      "7352/7352 [==============================] - 5s 642us/step - loss: 0.1435 - acc: 0.9441 - val_loss: 0.2507 - val_acc: 0.9094\n",
      "Epoch 36/250\n",
      "7352/7352 [==============================] - 5s 683us/step - loss: 0.1517 - acc: 0.9391 - val_loss: 0.2449 - val_acc: 0.9135\n",
      "Epoch 37/250\n",
      "7352/7352 [==============================] - 6s 796us/step - loss: 0.1485 - acc: 0.9406 - val_loss: 0.2476 - val_acc: 0.9145\n",
      "Epoch 38/250\n",
      "7352/7352 [==============================] - 5s 659us/step - loss: 0.1517 - acc: 0.9389 - val_loss: 0.2443 - val_acc: 0.9070\n",
      "Epoch 39/250\n",
      "7352/7352 [==============================] - 5s 661us/step - loss: 0.1443 - acc: 0.9408 - val_loss: 0.2430 - val_acc: 0.9108\n",
      "Epoch 40/250\n",
      "7352/7352 [==============================] - 6s 780us/step - loss: 0.1459 - acc: 0.9410 - val_loss: 0.2401 - val_acc: 0.9108\n",
      "Epoch 41/250\n",
      "7352/7352 [==============================] - 5s 675us/step - loss: 0.1461 - acc: 0.9418 - val_loss: 0.2609 - val_acc: 0.9077\n",
      "Epoch 42/250\n",
      "7352/7352 [==============================] - 5s 658us/step - loss: 0.1424 - acc: 0.9434 - val_loss: 0.2429 - val_acc: 0.9162\n",
      "Epoch 43/250\n",
      "7352/7352 [==============================] - 6s 765us/step - loss: 0.1464 - acc: 0.9438 - val_loss: 0.2556 - val_acc: 0.9189\n",
      "Epoch 44/250\n",
      "7352/7352 [==============================] - 5s 681us/step - loss: 0.1458 - acc: 0.9429 - val_loss: 0.2787 - val_acc: 0.9026\n",
      "Epoch 45/250\n",
      "7352/7352 [==============================] - 5s 688us/step - loss: 0.1433 - acc: 0.9415 - val_loss: 0.2457 - val_acc: 0.9138\n",
      "Epoch 46/250\n",
      "7352/7352 [==============================] - 6s 782us/step - loss: 0.1458 - acc: 0.9397 - val_loss: 0.2587 - val_acc: 0.9172\n",
      "Epoch 47/250\n",
      "7352/7352 [==============================] - 5s 685us/step - loss: 0.1373 - acc: 0.9426 - val_loss: 0.2506 - val_acc: 0.9128\n",
      "2947/2947 [==============================] - 0s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23868875675294315, 0.9056667797760435]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=250, batch_size=16, validation_data = (x_test, y_test), callbacks=callbacks)\n",
    "from keras.models import load_model\n",
    "# model = load_model('best_model.h5', custom_objects={\"NoisyRMSprop\":noisy()})\n",
    "model = load_model('best_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try ANN again with first 64 of 128 time values per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 64, 9)\n",
      "(2947, 64, 9)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.dstack((test1.iloc[:,0:64],test2.iloc[:,0:64],test3.iloc[:,0:64],test4.iloc[:,0:64],test5.iloc[:,0:64],test6.iloc[:,0:64],test7.iloc[:,0:64],test8.iloc[:,0:64],test9.iloc[:,0:64]))\n",
    "x_train = np.dstack((train1.iloc[:,0:64],train2.iloc[:,0:64],train3.iloc[:,0:64],train4.iloc[:,0:64],train5.iloc[:,0:64],train6.iloc[:,0:64],train7.iloc[:,0:64],train8.iloc[:,0:64],train9.iloc[:,0:64]))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_train = x_train.reshape([7352,576])\n",
    "x_test = x_test.reshape([2947,576])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Dense(1024, kernel_initializer=\"glorot_normal\", input_shape=(9*64,)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(.15))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(GaussianNoise(1))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a different optimizer this time\n",
    "noisy = add_gradient_noise(RMSprop)\n",
    "model.compile(optimizer=\"Adamax\",\n",
    "# model.compile(optimizer=noisy(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=16),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/250\n",
      "7352/7352 [==============================] - 6s 850us/step - loss: 0.6940 - acc: 0.7482 - val_loss: 0.5206 - val_acc: 0.8354\n",
      "Epoch 2/250\n",
      "7352/7352 [==============================] - 5s 674us/step - loss: 0.3818 - acc: 0.8679 - val_loss: 0.4187 - val_acc: 0.8537\n",
      "Epoch 3/250\n",
      "7352/7352 [==============================] - 6s 775us/step - loss: 0.2930 - acc: 0.8943 - val_loss: 0.3534 - val_acc: 0.8778\n",
      "Epoch 4/250\n",
      "7352/7352 [==============================] - 6s 773us/step - loss: 0.2501 - acc: 0.9129 - val_loss: 0.3687 - val_acc: 0.8683\n",
      "Epoch 5/250\n",
      "7352/7352 [==============================] - 8s 1ms/step - loss: 0.2242 - acc: 0.9185 - val_loss: 0.3156 - val_acc: 0.8755\n",
      "Epoch 6/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1962 - acc: 0.9272 - val_loss: 0.3092 - val_acc: 0.8829\n",
      "Epoch 7/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1945 - acc: 0.9266 - val_loss: 0.3084 - val_acc: 0.8965\n",
      "Epoch 8/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1887 - acc: 0.9294 - val_loss: 0.2818 - val_acc: 0.8941\n",
      "Epoch 9/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1769 - acc: 0.9313 - val_loss: 0.3213 - val_acc: 0.8768\n",
      "Epoch 10/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1710 - acc: 0.9342 - val_loss: 0.2779 - val_acc: 0.894507 - acc:\n",
      "Epoch 11/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1643 - acc: 0.9361 - val_loss: 0.2918 - val_acc: 0.9108\n",
      "Epoch 12/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1618 - acc: 0.9370 - val_loss: 0.2596 - val_acc: 0.9087 0.1631 - ac\n",
      "Epoch 13/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1599 - acc: 0.9370 - val_loss: 0.2627 - val_acc: 0.9080\n",
      "Epoch 14/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1486 - acc: 0.9404 - val_loss: 0.2558 - val_acc: 0.9131\n",
      "Epoch 15/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1513 - acc: 0.9380 - val_loss: 0.2517 - val_acc: 0.9131ss: 0.1509 - acc: \n",
      "Epoch 16/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1385 - acc: 0.9450 - val_loss: 0.3207 - val_acc: 0.8941\n",
      "Epoch 17/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1544 - acc: 0.9392 - val_loss: 0.2576 - val_acc: 0.9091\n",
      "Epoch 18/250\n",
      "7352/7352 [==============================] - 8s 1ms/step - loss: 0.1462 - acc: 0.9402 - val_loss: 0.2571 - val_acc: 0.9138\n",
      "Epoch 19/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1416 - acc: 0.9433 - val_loss: 0.2810 - val_acc: 0.9043\n",
      "Epoch 20/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1377 - acc: 0.9440 - val_loss: 0.2562 - val_acc: 0.9148\n",
      "Epoch 21/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1471 - acc: 0.9412 - val_loss: 0.2564 - val_acc: 0.9131\n",
      "Epoch 22/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1396 - acc: 0.9438 - val_loss: 0.2456 - val_acc: 0.9141\n",
      "Epoch 23/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1301 - acc: 0.9456 - val_loss: 0.2640 - val_acc: 0.8985\n",
      "Epoch 24/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1397 - acc: 0.9392 - val_loss: 0.2471 - val_acc: 0.9030\n",
      "Epoch 25/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1342 - acc: 0.9440 - val_loss: 0.2338 - val_acc: 0.9216\n",
      "Epoch 26/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1376 - acc: 0.9433 - val_loss: 0.2360 - val_acc: 0.9182\n",
      "Epoch 27/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1303 - acc: 0.9472 - val_loss: 0.2470 - val_acc: 0.9063\n",
      "Epoch 28/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1321 - acc: 0.9440 - val_loss: 0.2562 - val_acc: 0.9135\n",
      "Epoch 29/250\n",
      "7352/7352 [==============================] - 11s 1ms/step - loss: 0.1348 - acc: 0.9431 - val_loss: 0.2576 - val_acc: 0.9125\n",
      "Epoch 30/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1276 - acc: 0.9472 - val_loss: 0.2578 - val_acc: 0.9067\n",
      "Epoch 31/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1317 - acc: 0.9434 - val_loss: 0.2374 - val_acc: 0.9240\n",
      "Epoch 32/250\n",
      "7352/7352 [==============================] - 11s 1ms/step - loss: 0.1294 - acc: 0.9455 - val_loss: 0.2597 - val_acc: 0.9169\n",
      "Epoch 33/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1323 - acc: 0.9453 - val_loss: 0.2450 - val_acc: 0.9087\n",
      "Epoch 34/250\n",
      "7352/7352 [==============================] - 11s 1ms/step - loss: 0.1284 - acc: 0.9460 - val_loss: 0.2572 - val_acc: 0.9118\n",
      "Epoch 35/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1289 - acc: 0.9464 - val_loss: 0.2445 - val_acc: 0.9192\n",
      "Epoch 36/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1298 - acc: 0.9489 - val_loss: 0.2551 - val_acc: 0.9121\n",
      "Epoch 37/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1244 - acc: 0.9472 - val_loss: 0.2772 - val_acc: 0.9070\n",
      "Epoch 38/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1244 - acc: 0.9478 - val_loss: 0.3113 - val_acc: 0.8928\n",
      "Epoch 39/250\n",
      "7352/7352 [==============================] - 10s 1ms/step - loss: 0.1187 - acc: 0.9499 - val_loss: 0.2458 - val_acc: 0.9179\n",
      "Epoch 40/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1235 - acc: 0.9487 - val_loss: 0.2578 - val_acc: 0.9013\n",
      "Epoch 41/250\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1199 - acc: 0.9489 - val_loss: 0.2956 - val_acc: 0.9087\n",
      "2947/2947 [==============================] - 1s 267us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23383198726386928, 0.9216152019002375]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=250, batch_size=16, validation_data = (x_test, y_test), callbacks=callbacks)\n",
    "from keras.models import load_model\n",
    "# model = load_model('best_model.h5', custom_objects={\"NoisyRMSprop\":noisy()})\n",
    "model = load_model('best_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/test/Inertial Signals\")\n",
    "test1 = pd.read_csv(\"body_acc_x_test.txt\", \"\\s+\", header=None)\n",
    "test2 = pd.read_csv(\"body_acc_y_test.txt\", \"\\s+\", header=None)\n",
    "test3 = pd.read_csv(\"body_acc_z_test.txt\", \"\\s+\", header=None)\n",
    "test4 = pd.read_csv(\"body_gyro_x_test.txt\", \"\\s+\", header=None)\n",
    "test5 = pd.read_csv(\"body_gyro_y_test.txt\", \"\\s+\", header=None)\n",
    "test6 = pd.read_csv(\"body_gyro_z_test.txt\", \"\\s+\", header=None)\n",
    "test7 = pd.read_csv(\"total_acc_x_test.txt\", \"\\s+\", header=None)\n",
    "test8 = pd.read_csv(\"total_acc_y_test.txt\", \"\\s+\", header=None)\n",
    "test9 = pd.read_csv(\"total_acc_z_test.txt\", \"\\s+\", header=None)\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/train/Inertial Signals\")\n",
    "train1 = pd.read_csv(\"body_acc_x_train.txt\", \"\\s+\", header=None)\n",
    "train2 = pd.read_csv(\"body_acc_y_train.txt\", \"\\s+\", header=None)\n",
    "train3 = pd.read_csv(\"body_acc_z_train.txt\", \"\\s+\", header=None)\n",
    "train4 = pd.read_csv(\"body_gyro_x_train.txt\", \"\\s+\", header=None)\n",
    "train5 = pd.read_csv(\"body_gyro_y_train.txt\", \"\\s+\", header=None)\n",
    "train6 = pd.read_csv(\"body_gyro_z_train.txt\", \"\\s+\", header=None)\n",
    "train7 = pd.read_csv(\"total_acc_x_train.txt\", \"\\s+\", header=None)\n",
    "train8 = pd.read_csv(\"total_acc_y_train.txt\", \"\\s+\", header=None)\n",
    "train9 = pd.read_csv(\"total_acc_z_train.txt\", \"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 9)\n",
      "(2947, 128, 9)\n",
      "(7352, 1)\n",
      "(2947, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.dstack((test1,test2,test3,test4,test5,test6,test7,test8,test9))\n",
    "x_train = np.dstack((train1,train2,train3,train4,train5,train6,train7,train8,train9))\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/test\")\n",
    "y_test = pd.read_csv(\"y_test.txt\", \"\\s+\", header=None)\n",
    "os.chdir(\"UCI HAR Dataset/UCI HAR Dataset/train\")\n",
    "y_train = pd.read_csv(\"y_train.txt\", \"\\s+\", header=None)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2947, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.get_dummies(y_train[0]).values\n",
    "y_test = pd.get_dummies(y_test[0]).values\n",
    "# x_train = x_train.reshape([7352,1152])\n",
    "# x_test = x_test.reshape([2947,1152])\n",
    "print(y_test.shape)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import functools\n",
    "from matplotlib import pyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import BatchNormalization, Flatten, Dense, LeakyReLU, Dropout, GaussianNoise\n",
    "from tensorflow import set_random_seed\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras_gradient_noise import add_gradient_noise\n",
    "from keras.initializers import glorot_uniform, glorot_normal, he_uniform, he_normal\n",
    "set_random_seed(1724)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(LSTM(100, input_shape=(128,9)))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, kernel_initializer=\"glorot_normal\", input_shape=(9*128,)))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(.15))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(GaussianNoise(1))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a different optimizer this time\n",
    "noisy = add_gradient_noise(Adam)\n",
    "model.compile(optimizer=\"adam\",\n",
    "# model.compile(optimizer=noisy(),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jerem.DESKTOP-GGM6Q2I\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/250\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.9632 - acc: 0.6049 - val_loss: 0.7545 - val_acc: 0.6444\n",
      "Epoch 2/250\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.4287 - acc: 0.8381 - val_loss: 0.5469 - val_acc: 0.8056\n",
      "Epoch 3/250\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2654 - acc: 0.9048 - val_loss: 0.6630 - val_acc: 0.8422\n",
      "Epoch 4/250\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.2901 - acc: 0.8916 - val_loss: 0.2534 - val_acc: 0.9009\n",
      "Epoch 5/250\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2194 - acc: 0.9248 - val_loss: 0.2186 - val_acc: 0.9114\n",
      "Epoch 6/250\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1933 - acc: 0.9286 - val_loss: 0.2367 - val_acc: 0.9108\n",
      "Epoch 7/250\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.1789 - acc: 0.9327 - val_loss: 0.3819 - val_acc: 0.8446\n",
      "Epoch 8/250\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.1935 - acc: 0.9309 - val_loss: 0.3141 - val_acc: 0.9182\n",
      "Epoch 9/250\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1463 - acc: 0.9425 - val_loss: 0.3155 - val_acc: 0.8907\n",
      "Epoch 10/250\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1814 - acc: 0.9325 - val_loss: 0.2208 - val_acc: 0.9128\n",
      "Epoch 11/250\n",
      "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1591 - acc: 0.9408 - val_loss: 0.2069 - val_acc: 0.9199\n",
      "Epoch 12/250\n",
      "2304/7352 [========>.....................] - ETA: 34s - loss: 0.1347 - acc: 0.9457"
     ]
    }
   ],
   "source": [
    "    history = model.fit(x_train, y_train, epochs=250, batch_size=32, validation_data = (x_test, y_test), callbacks=callbacks)\n",
    "    from keras.models import load_model\n",
    "    # model = load_model('best_model.h5', custom_objects={\"NoisyAdam\":noisy()})\n",
    "    model = load_model('best_model.h5')\n",
    "    model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
